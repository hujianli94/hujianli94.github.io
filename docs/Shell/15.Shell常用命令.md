# 15.Shell 常用命令

Linux 中有很多非常实用的工具或命令，灵活运用这些工具，可以帮助我们在 Shell 编程中化繁为简，如虎添翼。可能一个工具或命令就能让原本负责的问题快速解决，本章节我们来一起丰富我们的工具库，日常可以多积累总结，帮助我们更好的编写 Shell。

## 数据检索命令

- 行检索：grep egrep

- 字符串检索: cut tr

- 文件检索：find

### grep

负责从数据源中检索对应的字符串，行过滤。

```sh
# grep用于根据关键字进行行过滤
grep options 'keys' filename
OPTIONS:
    -i: 不区分大小写
    -v: 查找不包含指定内容的行,反向选择
    -w: 按单词搜索
    -n: 显示行号
    -A: 显示匹配行及后面多少行 -A 5
    -B: 显示匹配行及前面多少行


    -o: 打印匹配关键字
    -c: 统计匹配到的次数
    -r: 逐层遍历目录查找
    -C: 显示匹配行前后多少行
    -l：只列出匹配的文件名
    -L：列出不匹配的文件名
    -e: 使用正则匹配
    -E:使用扩展正则匹配
    ^key:以关键字开头
    key$:以关键字结尾
    ^$:匹配空行
    --color=auto ：可以将找到的关键词部分加上颜色的显示
```

centos8 中已经为大家设置了，存放在/etc/profile.d/colorgrep.sh 文件中，如若大家使用的系统中没有设置颜色输出，
可以使用以下方法来自行设置

临时设置：

```sh
# alias grep='grep --color=auto' //只针对当前终端和当前用户生效

# 永久设置：
# 1）全局（针对所有用户生效）
vim /etc/bashrc
alias grep='grep --color=auto'
source /etc/bashrc

# 2）局部（针对具体的某个用户）
vim ~/.bashrc
alias grep='grep --color=auto'

# 注意：如果希望你对环境变量的设置立刻生效，可以使用以下命令而不需要重启计算机
source ~/.bashrc
```

常用命令选项必知必会 示例：

```sh
(py38) root@hujianli722:/mnt/d/cygwin64/home/18793/shell# cat /etc/passwd >passwd
# grep -i root passwd 忽略大小写匹配包含root的行
# grep -w ftp passwd 精确匹配ftp单词
# grep -wo ftp passwd 打印匹配到的关键字ftp
# grep -n root passwd 打印匹配到root关键字的行号
# grep -ni root passwd 忽略大小写匹配统计包含关键字root的行
# grep -nic root passwd 忽略大小写匹配统计包含关键字root的行数
# grep -i ^root passwd 忽略大小写匹配以root开头的行
# grep bash$ passwd 匹配以bash结尾的行
# grep -n ^$ passwd 匹配空行并打印行号
# grep ^# /etc/vsftpd/vsftpd.conf 匹配以#号开头的行
# grep -v ^# /etc/vsftpd/vsftpd.conf 匹配不以#号开头的行
# grep -A 5 mail passwd   匹配包含mail关键字及其后5行
# grep -B 5 mail passwd   匹配包含mail关键字及其前5行
# grep -C 5 mail passwd 匹配包含mail关键字及其前后5行

## 使用正则表达式 -E 选项：
# grep -E "[1-9]+"
# 或
# egrep "[1-9]+"
```

### cut

功能：选取文件的每一行数据

```sh
常用选项：
-b 选中第几个字符
-c 选中多少个字符
-d 指定分隔符分字段，默认是空格
-f 显示选中字段
```

示例：

```sh
# 打印 b 字符：
echo "abc" |cut -b "2"
b

# 截取 abc 字符：
echo "abcdef" |cut -c 1-3
abc

# 以冒号分隔，显示第二个字段：
echo "a:b:c" |cut -d: -f2
b


## 更多示例
# cut -d: -f1 1.txt 以:冒号分割，截取第1列内容
# cut -d: -f1,6,7 1.txt 以:冒号分割，截取第1,6,7列内容
# cut -c4 1.txt 截取文件中每行第4个字符
# cut -c1-4 1.txt 截取文件中每行的1-4个字符
# cut -c4-10 1.txt
# cut -c5- 1.txt 从第5个字符开始截取后面所有字符
```

### tr

功能：替换或删除字符
格式：`Usage: tr [OPTION]... SET1 [SET2]`

```sh
# 常用选项：
# tr 'string1' 'string2' < filename
# tr options 'string1' < filename

-c 替换 SET1 没有 SET2 的字符
-d 删除 SET1 中字符
-s 删除所有重复出现字符序列，只保留第一个,压缩 SET1 中重复的字符
-t 将 SET1 用 SET2 转换，默认

# a-z 任意小写
# A-Z 任意大写
# 0-9 任意数字
```

```sh
# 替换 SET1 没有 SET2 的字符：
echo "aaabbbccc" | tr -c c 1
# 111111ccc

# 去重字符：
echo "aaacccddd" | tr -s '[a-z]'
# acd

# 删除字符：
echo "aaabbbccc" | tr -d bbb
# aaaccc


# 删除换行符：
echo -e "a\nb\nc" | tr -d '\n'
# abc

# 替换字符：
echo "aaabbbccc" | tr '[a-z]' '[A-Z]'
# AAABBBCCC


## 更多示例
# tr -d '[:/]' < 3.txt 删除文件中的:和/
# cat 3.txt |tr -d '[:/]' 删除文件中的:和/
# tr '[0-9]' '@' < 3.txt 将文件中的数字替换为@符号
# tr '[a-z]' '[A-Z]' < 3.txt 将文件中的小写字母替换成大写字母
# tr -s '[a-z]' < 3.txt 匹配小写字母并将重复的压缩为一个
# tr -s '[a-z0-9]' < 3.txt 匹配小写字母和数字并将重复的压缩为一个
```

### find

常用选项：

```sh
-name 文件名，支持(‘*’, ‘?’)
-type 文件类型，d 目录，f 常规文件等
-perm 符合权限的文件，比如 755
-atime -/+n 在 n 天以内/过去 n 天被访问过
-ctime -/+n 在 n 天以内/过去 n 天被修改过
-amin -/+n 在 n 天以内/过去 n 分钟被访问过
-cmin -/+n 在 n 天以内/过去 n 分钟被修改过
-size -/+n 文件大小小于/大于，b、k、M、G
-maxdepth levels 目录层次显示的最大深度
-regex pattern 文件名匹配正则表达式模式
-inum 通过 inode 编号查找文件
```

动作：

```sh
-detele 删除文件
-exec command {} \; 执行命令，花括号代表当前文件
-ls 列出当前文件，ls -dils 格式
-print 完整的文件名并添加一个回车换行符
-print0 打印完整的文件名并不添加一个回车换行符
-printf format 打印格式
```

其他字符：

```sh
# ！ 取反
-or/-o 逻辑或
-and 逻辑和
```

示例：

```sh
# 当前目录搜索所有文件，文件内容 包含 “140.206.111.111” 的内容
find . -type f -name "*" | xargs grep "140.206.111.111"

# 查找文件名：
find / -name "*http*"

# 查找文件名并且文件类型：
find /tmp -name core -type f -print

# 查找文件名并且文件类型删除：
find /tmp -name core -type f -delete

# 查找当前目录常规文件并查看文件类型：
find . -type f -exec file '{}' \;


# 当前目录及子目录下查找所有以.txt和.pdf结尾的文件
find . \( -name "*.txt" -o -name "*.pdf" \)
# 或
find . -name "*.txt" -o -name "*.pdf"


# 查找文件权限是 664：
find . -perm 664

# 查找大于 1024k 的文件：
find . -size -1024k

# 搜索大于10KB的文件
find . -type f -size +10k

# 当磁盘使用率达到 100% 时，首先需要释放空间以防止系统崩溃。以下是一些在 Linux 系统上快速查找并删除大于 2GB 的文件的方法：
# 使用 find 命令：
# 这会在根目录 / 下查找所有大于 2GB 的文件，并以人类可读的方式显示文件大小。你可以根据需要修改根目录路径。
sudo find / -type f -size +2G -exec ls -lh {} + 2>/dev/null



# 查找 3 天内修改的文件：
find /bin -ctime -3


# 查找 3 分钟前修改的文件：
find /bin -cmin +3


# 排除多个类型的文件：
find . ! -name "*.sql" ! -name "*.txt"
# 或条件查找多个类型的文件：
find . -name '*.sh' -o -name '*.bak'
find . -regex ".*\.sh\|.*\.bak"
find . -regex ".*\.\(sh\|bak\)"

# 并且条件查找文件：
find . -name "*.sql" -a -size +1024k

# 只显示第一级目录：
find /etc -type d -maxdepth 1

# 通过 inode 编号删除文件：
rm `find . -inum 671915`

find . -inum 8651577 -exec rm -i {} \;


# 找出当前目录下所有root的文件，并把所有权更改为用户tom
find .-type f -user root -exec chown tom {} \;

# 将30天前的.log文件移动到old目录中
find . -type f -mtime +30 -name "*.log" -exec cp {} old \;


# 统计代码行数
find . -name "*.java"|xargs cat|grep -v ^$|wc -l # 代码行数统计, 排除空行


# 例如，要搜索在过去 7 天内修改的具有特定扩展名的所有文件，请使用以下命令：
find . -name "*.txt" -type f -mtime -7

# 例如，要更改具有特定扩展名的所有文件的权限，请使用以下命令：
find . -name "*.txt" -type f -exec chmod 644 {} \;
```

- print： find 命令将匹配的文件输出到标准输出；

- exec： find 命令对匹配的文件执行该参数所给出的 shell 命令。相应命令的形式为 `'command' {} \;`，注意 `{}` 和 `\；`之间的空格；

- ok： 和 - exec 的作用相同，只不过以一种更为安全的模式来执行该参数所给出的 shell 命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行；

**选项说明**：

```shell
- -name   filename               #查找名为 filename 的文件
- -perm                          #按执行权限来查找
- -user    username              #按文件属主来查找
- -group groupname          	 #按组来查找
- -mtime   -n +n                 #按文件更改时间来查找文件，-n 指 n 天以内，+n 指 n 天以前
- -atime    -n +n                #按文件访问时间来查 GIN: 0px">
- -ctime    -n +n                #按文件创建时间来查找文件，-n 指 n 天以内，+n 指 n 天以前
- -type    b/d/c/p/l/f           #查是块设备、目录、字符设备、管道、符号链接、普通文件
- -size      n [c]               #查长度为 n 块 [或 n 字节] 的文件
- -depth                         #使查找在进入子目录前先行查找完本目录
- -prune　　                      #通常和 -path 一起使用，用于将特定目录排除在搜索条件之外。过滤条件写在其他条件前面。
```

在此我们对命令支持的选项全部展开详解，根据日常经验结合实际案例列举最常用的选项进行说明：

**实例**:

- 在当前目录寻找文件名称以`.txt`结尾的文件并打印出来

```shell
[root@master ~]# find   ~   -name   "*.txt"   -print
/root/kubesphere-all-advanced-2.0.2/scripts/os/requirements.txt
/root/kubesphere-all-advanced-2.0.2/kubesphere/roles/storages/NFS-Server/files/nfs-server-provisioner/templates/NOTES.txt
/root/kubesphere-all-advanced-2.0.2/kubesphere/roles/ks-devops/jenkins/files/jenkins/jenkins-update-center/templates/NOTES.txt
/root/kubesphere-all-advanced-2.0.2/kubesphere/roles/ks-devops/harbor/files/harbor/harbor/templates/NOTES.txt
/root/kubesphere-all-advanced-2.0.2/kubesphere/roles/metrics-server/files/metrics-server/templates/NOTES.txt
/root/kubesphere-all-advanced-2.0.2/kubesphere/roles/openpitrix/files/openpitrix/kubernetes/password.txt
```

- 查找/usr/bin 目录下大于 10M 的文件

```shell
[root@master ~]# find /usr/bin -size +10000k -exec ls -ld {} \;
-rwxr-xr-x. 1 root root 13606800 Jul 10  2018 /usr/bin/ceph-dencoder
-rwxr-xr-x. 1 root root 15863688 Jul 10  2018 /usr/bin/ceph-objectstore-tool
-rwxr-xr-x. 1 root root 15589080 Jul 10  2018 /usr/bin/ceph-osd
-rwxr-xr-x. 1 root root 33073928 Feb 10  2019 /usr/bin/docker
-rwxr-xr-x. 1 root root 38088856 Feb 10  2019 /usr/bin/docker-containerd
-rwxr-xr-x. 1 root root 68608416 Feb 10  2019 /usr/bin/dockerd
-rwxr-xr-x. 1 root root 20895160 Feb 10  2019 /usr/bin/docker-containerd-ctr
-rwxr-xr-x. 1 root root 10785264 Jul 10  2018 /usr/bin/ceph-mon
```

- 查找当前目录下权限为 777 的文件

```shell
[root@master ~]# find . -perm 777 -print
./.helm/repository/cache/local-index.yaml
./kubesphere-all-v2.1.0/k8s/extra_playbooks/inventory
./kubesphere-all-v2.1.0/k8s/extra_playbooks/roles
./kubesphere-all-v2.1.0/k8s/contrib/terraform/openstack/hosts
```

## 数据处理命令

- 数据排序：sort

- 数据去重: uniq

- 文本数据合并: paste

- 数据输出: tee

- 数据处理: xargs

- 打印序列化数字: seq

### sort

功能：排序文本，默认对整列有效

将文件的每一行作为一个单位，从首字符向后，依次按 ASCII 码值进行比较，最后将他们按升序输出。

```sh
# 语法：
# sort [options] [filename]

# 常用选项：
-f 忽略字母大小写
-M 根据月份比较，比如 JAN、DEC
-h 根据易读的单位大小比较，比如 2K、1G
-g 按照常规数值排序
-n 根据字符串数值比较
-k 位置 1,位置 2 根据关键字排序，在从第位置 1 开始，位置 2 结束
-t 指定分隔符
-u 去重重复行
-r 倒序排序
-o 将结果写入文件
-b 忽略前导空格
-R 随机排序，每次运行的结果均不同
```

在此我们不全部展开起所有选项，只根据日常经验结合实际案例列举最常用的选项进行说明。

示例：

```sh
# 随机数字排序：
seq 5 |shuf |sort

# 随机字母排序：
printf "%c\n" {a..f} |shuf |sort

# 倒序排序：
seq 5 |shuf |sort -r

# 分隔后的字段排序：
cat /etc/passwd |sort -t : -k 3 -n

# 去重重复行：
echo -e "1\n1\n2\n3\n3" |sort -u

# 大小单位排序：
du -h |sort -k 1 -h -r

# 分隔后第一个字段的第二个字符排序：
echo -e "fa:1\neb:2\ncc:3" |sort -t : -k 1.2

# tab 作为分隔符：
sort -t $"\t"

# file 文件内容：
zhangsan 6 100
lisi 8 80
wangwu 7 90
zhaoliu 9 70

# 对 file 文件的第二列正序排序，再次基础再对第三列倒序排序（多列排序）：
sort -k 2,2 -n -k 3,3 -nr file
sort -k 2 -n -k 3 -nr file
zhaoliu 9 70
lisi 8 80
wangwu 7 90
zhangsan 6 100


# 对两个文件同时排序：
sort file1 file2


## 更多示例
# sort -n -t: -k3 1.txt 按照用户的uid进行升序排列
# sort -nr -t: -k3 1.txt 按照用户的uid进行降序排列
# sort -n 2.txt 按照数字排序
# sort -nu 2.txt 按照数字排序并且去重
# sort -nr 2.txt
# sort -nru 2.txt
# sort -nru 2.txt
# sort -n 2.txt -o 3.txt 按照数字排序并将结果重定向到文件
# sort -R 2.txt
# sort -u 2.txt
```

**实例**：

- 对/etc/passwd 中以 uid 从大到小排序

```shell
[root@10-234-1-235 ~]# sort -t: -k3 -n -r /etc/passwd
saslauth:x:499:76:Saslauthd user:/var/empty/saslauth:/sbin/nologin
gitlab-www:x:498:497::/var/opt/gitlab/nginx:/bin/false
git:x:497:496::/var/opt/gitlab:/bin/sh
gitlab-redis:x:496:495::/var/opt/gitlab/redis:/bin/false
gitlab-psql:x:495:494::/var/opt/gitlab/postgresql:/bin/sh
gitlab-prometheus:x:494:493::/var/opt/gitlab/prometheus:/bin/sh
mongod:x:493:492:mongod:/var/lib/mongo:/bin/false
nobody:x:99:99:Nobody:/:/sbin/nologin
postfix:x:89:89::/var/spool/postfix:/sbin/nologin
dbus:x:81:81:System message bus:/:/sbin/nologin
sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin
vcsa:x:69:69:virtual console memory owner:/dev:/sbin/nologin
apache:x:48:48:Apache:/var/www:/sbin/nologin
ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
gopher:x:13:30:gopher:/var/gopher:/sbin/nologin
games:x:12:100:games:/usr/games:/sbin/nologin
operator:x:11:0:operator:/root:/sbin/nologin
uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin
mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
halt:x:7:0:halt:/sbin:/sbin/halt
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
sync:x:5:0:sync:/sbin:/bin/sync
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
bin:x:1:1:bin:/bin:/sbin/nologin
root:x:0:0:root:/root:/bin/bash
```

通过上例可以看到，利用`-t`选项指定/etc/passwd 文件中，以`:`作为列进行分割，指定 uid 的列为`k3`，-n 以数字进行排序，`-r`为倒序排序输出。

### uniq

去除连续的重复行 对于一些重复输出的行进行去重。

应用技巧：去重前先使用 sort 排序

语法：`uniq [OPTION]... [INPUT [OUTPUT]]`

```sh
# 选项说明：
-i 忽略大小写
-c 打印出现的次数
-d 只打印重复行
-u 只打印不重复行
-D 只打印重复行，并且把所有重复行打印出来
-f N 比较时跳过前 N 列
-s N 比较时跳过前 N 个字符
-w N 对每行第 N 个字符以后内容不做比较
```

```sh
# 测试文本如下：
# cat file
abc
cde
xyz
cde
xyz
abd

# 去重复行：
# sort file |uniq
abc
abd
cde
xyz

# 打印每行重复次数：
# sort file |uniq -c
1 abc
1 abd
2 cde
2 xyz

# 打印不重复行：
# sort file |uniq -u
abc
abd

# 打印重复行：
# sort file |uniq -d
cde
xyz

# 打印重复行并统计出现次数：
# sort file |uniq -d -c
2 cde
2 xyz

# 根据前几个字符去重：
# sort file |uniq -w 2
abc
cde
xyz

## 更多示例
# uniq 2.txt
# uniq -d 2.txt
# uniq -dc 2.txt
```

实例：

- 对/etc/passwd 中以`:`，对最后一列求出现的次数

```shell
[root@master ~]# awk -F":" '{print $NF}' /etc/passwd
/bin/bash
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/bin/sync
/sbin/shutdown
/sbin/halt
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/bin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
/sbin/nologin
[root@master ~]# awk -F":" '{print $NF}' /etc/passwd |sort |uniq -c |sort -nr
     22 /sbin/nologin
      1 /sbin/shutdown
      1 /sbin/halt
      1 /bin/sync
      1 /bin/nologin
      1 /bin/bash
```

先利用 awk 打印出最后一列内容，之后利用 sort 来进行排序，将相同的字符规在一起输出，最后对相同的行进行去重，得出每种不同类型 shell 出现的次数，最后对数学从大到小排序。

### paste

paste 工具用于合并文件行输出到屏幕，不会改动源文件

```sh
# 常用选项：

-d：自定义间隔符，默认是tab,只接受一个字符
-s：将每个文件中的所有内容按照一行输出，文件中的行与行以TAB间隔。
```

```sh
[root@zutuanxue shell01]# cat a.txt
hello
[root@zutuanxue  shell01]# cat b.txt
hello world
888
999
[root@zutuanxue  shell01]# paste a.txt b.txt
hello   hello world
        888
        999
[root@zutuanxue  shell01]# paste b.txt a.txt
hello world     hello
888
999

[root@zutuanxue shell01]# paste -d'@' b.txt a.txt
hello world@hello
888@
999@

[root@zutuanxue shell01]# paste -s b.txt a.txt
hello world     888     999
hello
```

### tee

功能：从标准输入读取写到标准输出和文件

```sh
# 常用选项：
-a 追加到文件
```

示例：

打印并追加到文件：

```sh
echo 123 |tee -a a.log
```

### xargs

功能：从标准输入执行命令

````sh
# 常用选项：
-a file 从指定文件读取数据作为标准输入
-0 处理包含空格的文件名,print0
-E flag flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。
-d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符。
-d delimiter 分隔符，默认是空格分隔显示
-i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。
-I 标准输入的结果以指定的名字代替
-t 表示先打印命令，然后再执行。
-p 交互式提示是否执行命令
-r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。
-n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。
--show-limits 查看系统命令行长度限制
```

示例：

```sh
# 删除/tmp 下名字是 core 的文件：
find /tmp -name core -type f -print | xargs /bin/rm -f
find /tmp -name core -type f -print0 | xargs -0 /bin/rm -f

# 列转行（去除换行符 ）：
cut -d: -f1 < /etc/passwd | sort | xargs echo

# 行转列：
echo "1 2 3 4 5" |xargs -n1

# 最长两列显示：
echo "1 2 3 4 5" |xargs -n2

# 创建未来十天时间：
seq 1 10 |xargs -i date -d "{} days " +%Y-%m-%d

# 复制多个目录：
echo dir1 dir2 |xargs -n1 cp a.txt

# 清空所有日志：
find ./ -name "*.log" |xargs -i tee {} # echo ""> {} 这样不行，>把命令中断了

# rm 在删除大量的文件时，会提示参数过长，那么可以使用 xargs 删除：
ls |xargs rm –rf

# 或分配删除 rm [a-n]* -rf # getconf ARG_MAX 获取系统最大参数限制
````

- 删除日志文件

```bash
ls *.log |xargs rm -rf {}
```

- 查找/home/data 下权限为 644 的文件修改权限为 600

```bash
find /home/data -perm 644 | xargs chmod 600
```

- 查找 jpg 文件并打包

```bash
find / -name *.jpg -type f -print | xargs tar -cvzf images.tar.gz
```

- 使用 -n 进行多行输出

```shell
cat test.txt | xargs -n3

a b c
d e f
g h i
j k l
m n o
p q r
s t u
v w x
y z
```

- 使用 -d 分割输入

-d 选项 可以自定义一个定界符：

```shell
echo "nameXnameXnameXname" | xargs -dX

name name name name
```

结合 -n 选项 使用：

```shell
echo "nameXnameXnameXname" | xargs -dX -n2

name name
name name
```

复制所有图片文件到 /data/images 目录下：

```shell
ls *.jpg | xargs -n1 -I cp {} /data/images
```

!!! tip "结合 find 命令使用"

**xargs 结合 find 使用**

用 rm 删除太多的文件时候，可能得到一个错误信息：`/bin/rm Argument list too long.` 用 xargs 去避免这个问题：

```shell
find . -type f -name "*.log" -print0 | xargs -0 rm -f
```

xargs -0 将 `\0` 作为定界符。

统计一个源代码目录中所有 php 文件的行数：

```shell
find . -type f -name "*.php" -print0 | xargs -0 wc -l
```

使用 -p 选项确认执行的命令

-p 选项会在执行每一个命令时弹出确认，当你需要非常准确的确认每一次操作时可以使用 -p 参数，
比如，查找当前目录下 .log 文件，每一次删除都需要确认：

```shell
find . -maxdepth 1 -name "*.log" | xargs -p -I{} rm {}
```

执行多个命令

使用 -I 选项可以让 xargs 执行多个命令

```shell
cat foo.txt
one
two
three

cat foo.txt | xargs -I % sh -c 'echo %; mkdir %'
one
two
three

ls
one two three
```

**xargs 其他应用**

假如你有一个文件包含了很多你希望下载的 URL，你能够使用 xargs 下载所有链接：

```shell
cat url-list.txt | xargs wget -c
```

### seq

功能：打印序列化数字,以指定增量从首数开始打印数字到尾数

```sh
# 常用选项：
-f 使用 printf 样式格式
-s 指定换行符，默认是\n
-w 等宽，用 0 填充
```

示例：

```sh
# 数字序列：
seq 3
1
2
3

# 带 0 的数字序列：
seq -w 03
01
02
03

# 范围数字序列：
seq 2 5
2
3
4
5

# 步长序列：
seq 1 2 5 # 2 是步长
1
3
5

# 以冒号分隔序列：
seq -s "+" 5
1+2+3+4+5

# 等宽并在数字前面加字符串：
seq -f "str%02g" 3 # %g 是默认数字位数，02 是数字不足 2 位时用 0 填充。
str01
str02
str03


bash$ seq 5
1
2
3
4
5


bash$ seq -s : 5
1:2:3:4:5
```

## 其他

### eval

eval 命令会读取其参数，将这些参数视为 shell 命令，然后执行这些命令。它的主要用途是处理变量和命令替换，尤其是在需要动态构建命令字符串时。

功能：执行参数作为 shell 命令

```sh
cmd="ls -l"
eval $cmd  # 等同于执行 'ls -l'
```

示例：

```sh
for i in $@; do
  eval $i
done
echo ---
echo $a
echo $b

# bash test.sh a=1 b=2
---
1
2
```

### exec

exec 命令用于执行指定的命令，并用该命令替换当前的 shell 进程。

这意味着一旦 exec 命令执行完毕，当前的 shell 进程就会结束，不会返回到原来的 shell。

```sh
exec ls -l  # 执行 'ls -l' 并替换当前的 shell 进程
echo "This will not be executed"  # 这行代码不会执行，因为 shell 已经被替换了
```

exec 和 eval 主要区别

进程替换:

- exec 替换当前的 shell 进程。
- eval 不替换 shell 进程，而是在当前 shell 中执行命令。

命令解析:

- eval 需要解析其参数，然后再执行。
- exec 直接执行其参数指定的命令，不需要额外的解析。

返回:

- exec 不会返回到调用它的 shell，除非指定了进程 ID。
- eval 执行完毕后，控制权返回到调用它的 shell。

用途:

- eval 常用于动态构建和执行命令。
- exec 常用于在不创建新进程的情况下替换当前 shell 进程，例如在脚本中启动守护进程。

### date

在我们编写 Shell 的时候经常遇到需要记录日志的情况，在记录日志的时候需要打上时间戳，以便后期查看那个时间节点运行执行的操作，此时就需要用到 date 命令

**简介**：date 可以用来显示或设定系统的日期与时间。

**选项**：

```shell
-d<字符串>：显示字符串所指的日期与时间。字符串前后必须加上双引号；
-s<字符串>：根据字符串来设置日期与时间。字符串前后必须加上双引号；
-u：显示GMT；
```

时间格式：

```shell
%Y -- 年份
%m -- 月份
%d -- 当月第几天
%t -- Tab 跳格
%H -- 小时，24 小时格式 (0~23)
%I -- 小时，12 小时格式 (0~12)
%M -- 分钟 (00~59)
%S -- 秒 (00~59)
%j -- 今年中的第几天
%Z -- 以字符串形式输出当前时区
%z -- 以数字形式输出当前时区
%F --  文件时间格式 same as % Y-% m-% d
%T -- 24 小时制时间表示 (hh:mm:ss)
```

- 实例

计算一个命令执行所需要的耗时

```shell
#!/bin/bash
start=$(date +%s)
echo "$(date +%F" "%T) 开始执行命令"
sleep 5
echo "$(date +%F" "%T) 执行命令完成"
end=$(date +%s)
difference=$(( end - start ))
echo "执行命令总耗时:$difference seconds."

[root@master ~]# bash time.sh
2020-04-19 10:19:58 开始执行命令
2020-04-19 10:20:03 执行命令完成
执行命令总耗时:5 seconds.
```

### lsof

功能：列出打开的文件

```sh
# 常用选项：
# -i [i] 监听的网络地址，如果没有指定，默认列出所有。
# [i]来自[46][protocol][@hostname|hostaddr][:service|port]

-U 列出 Unix 域 socket 文件
-p 指定 PID
-u 指定用户名或 UID 所有打开的文件
+D 递归搜索
```

示例：

```sh
# 列出所有打开的文件：
lsof

# 查看哪个进程占用文件：
lsof /etc/passwd

# 列出所有打开的监听地址和 unix 域 socket 文件：
lsof -i -U

# 列出 80 端口监听的进程：
lsof -i:80

# 列出端口 1-1024 之间的所有进程：
lsof -i:1-1024

# 列出所有 TCP 网络连接：
lsof -i tcp

# 列出所有 UDP 网络连接：
lsof -i udp

# 根据文件描述符列出打开的文件：
lsof -d 1

# 列出某个目录被打开的文件：
lsof +D /var/log

# 列出进程 ID 打开的文件：
lsof -p 5373

# 打开所有登录用户名 abc 或 user id 1234，或 PID 123 或 PID 456：
lsof -p 123,456 -u 123,abc

# 列出 COMMAND 列中包含字符串 sshd：
lsof -c sshd
```

### shuf

功能：生成随机序列

```sh
# 常用选项：

-i 输出数字范围
-o 结果写入文件
```

示例：

输出范围随机数：

```sh
# seq 5 |shuf
2
1
5
4
3
# shuf -i 5-10
8
10
7
9
6
5
```

### nohup

功能：运行程序，忽略挂起信号

示例：

后台运行程序，终端关闭不影响：

```sh
nohup bash test.sh &>test.log &
```

### iconv

功能：将文件内容字符集转成其他字符集

```sh
# 常用选项：

-l 列出所有已知的字符集
-f 原始文本编码
-t 输出编码
-o 输出到文件
-s 关闭警告
```

示例：

```sh
# 将文件内容转换 UTF8：
iconv -f gbk -t utf8 old.txt -o new.txt

# 将 csv 文件转换 GBK：
iconv -f utf8 -t gbk old.txt -o new.txt

# 解决邮件乱码：
echo $(echo "content" | iconv -f utf8 -t gbk) | mail -s "$(echo "title" | iconv -f utf8 -t gbk)" example@mail.com
```

### curl

功能：发送数据到 URL，类似于 HTTP 客户端

```sh
# 常用选项：

-k, --insecure 允许 HTTPS 连接网站
-C, --continue-at 断点续传
-b, --cookie STRING/FILE 从文件中读取 cookie
-c, --cookie-jar 把 cookie 保存到文件
-d, --data 使用 POST 方式发送数据
--data-urlencode POST 的数据 URL 编码
-F, --form 指定 POST 数据的表单
-D, --dump-header 保存头信息到文件
--ftp-pasv 指定 FTP 连接模式 PASV/EPSV
-P, --ftp-port 指定 FTP 端口
-L, --location 遵循 URL 重定向，默认不处理
-l, --list-only 指列出 FTP 目录名
-H, --header 自定义头信息发送给服务器
-I, --head 查看 HTTP 头信息
-o, --output FILE 输出到文件
-#, --progress-bar 显示 bar 进度条
-x, --proxy [PROTOCOL://]HOST[:PORT] 使用代理
-U, --proxy-user USER[:PASSWORD] 代理用户名和密码
-e, --referer 指定引用地址 referer
-O, --remote-name 使用远程服务器上名字写到本地
--connect-timeout 连接超时时间，单位秒
--retry NUM 连接重试次数
--retry-delay 两次重试间隔等待时间
-s, --silent 静默模式，不输出任何内容
-Y, --speed-limit 限制下载速率
-u, --user USER[:PASSWORD] 指定 http 和 ftp 用户名和密码
-T, --upload-file 上传文件
-A, --user-agent 指定客户端信息
```

示例：

```sh
# 下载页面：
curl -o badu.html http://www.baidu.com

# 不输出下载信息：
curl -s -o baidu.html http://www.baidu.com

# 伪装客户端，指定 user-agent 和 referer 下载：
curl -A "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36" -e "baike.baidu.com" http://127.0.0.1

# 模拟用户登录，并保存 cookies 到文件：
curl -c ./cookies.txt -F NAME=user -F PWD=123 http://www.example.com/login.html

# 使用 cookie 访问：
curl -b cookies.txt http://www.baidu.com

# 访问 HTTP 认证页面：
curl -u user:pass http://www.example.com

# FTP 上传文件：
curl -T filename ftp://user:pass@ip/a.txt
curl ftp://ip -u user:pass-T filename

# FTP 下载文件：
curl -O ftp://user:pass@ip/a.txt
curl ftp://ip/filename -u user:pass -o filename

# FTP 下载多个文件：
curl ftp://ip/img/[1,3,5].jpg

# 查看 HTTP 头信息：
curl -I http://www.baidu.com
```

## 实例

### 需求

我们经常在 Linux 系统操作操作文件，俗话说常在河边走，哪有不湿鞋，一不小心删除重要文件是非常危险的。我们可以利用 Shell 脚本来制作一个类似于 Windows 下的回收站，配合定时任务，定期清理这个回收站中的内容，从而达到缓冲及规避危险操作。

### 思路

- 通过 alias rm 来将删除的文件，移动文件到一个回收站目录;
- 定期的在系统磁盘允许可控的使用率情况下，对回收站目录下的文件进行删除。

### 实现

```bash
#!/bin/bash
# function:自定义rm命令，每天晚上定时清理

# 指定变量
CMD_SCRIPTS=$HOME/.rm_scripts.sh
TRASH_DIR=$HOME/.TRASH_DIR
CRON_FILE=/var/spool/cron/root
BASHRC=$HOME/.bashrc

[ ! -d ${TRASH_DIR} ] && mkdir -p ${TRASH_DIR}
cat > $CMD_SCRIPTS <<EOF
PARA_CNT=\$#
TRASH_DIR=$TRASH_DIR

for i in \$*; do
     DATE=\$(date +%F%T)
     fileName=\$(basename \$i)
     mv \$i \$TRASH_DIR/\$fileName.\$DATE
done
EOF

sed -i "s@$(grep 'alias rm=' $BASHRC)@alias rm='bash ${CMD_SCRIPTS}'@g" $BASHRC
source $HOME/.bashrc

# 制作定时清理任务
echo "0 0 * * * rm -rf $TRASH_DIR/*" >> $CRON_FILE
echo "删除目录:$TRASH_DIR"
echo "删除脚本:$CMD_SCRIPTS"
echo "请执行:source $BASHRC 来加载文件或退出当前shell重新登录"
```

对防治误删除脚本进行系统测试。

```shell
[root@10-234-1-235 ~]# bash custom_rm.sh
删除目录:/root/.TRASH_DIR
删除脚本:/root/.rm_scripts.sh
请执行:source /root/.bashrc 来加载文件或退出当前shell重新登录
[root@10-234-1-235 ~]# rm testdir/
[root@10-234-1-235 ~]# rm wget-log
[root@10-234-1-235 ~]# ls -la .TRASH_DIR/
total 16
drwxr-xr-x.  3 root root 4096 Apr 18 20:11 .
dr-xr-x---. 13 root root 4096 Apr 18 20:11 ..
drwxr-xr-x.  2 root root 4096 Apr 18 20:10 testdir.2020-04-1820:11:37
-rw-r--r--.  1 root root    0 Jan  9 21:59 wget-log.2020-04-1820:11:40

# 查看定时任务
[root@10-234-1-235 ~]# crontab -l
0 0 * * * rm -rf /root/.TRASH_DIR/*
```

## 小结

Shell 编程就是利用工具加数据结构流程控制实现一组操作，所以掌握更多常用的工具或命令非常利于我们编写 Shell 脚本，平时可以多尝试利用各种命令或工具，并在 Shell 中熟练运用它们，勤练并反思总结，归纳整理，日积月累就会形成自己强大的工具库。
