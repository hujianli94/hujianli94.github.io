# 14.并发编程


## 多进程

### 多进程实现

```python
from multiprocessing import Process 
import os
 
def foo(name): 
    print(f'name: {name}') 
    print(f'parent process id: {os.getppid()}') 
    print(f'sub process id: {os.getpid()}') 
    
if __name__ == '__main__': 
    print(f'parent process id：{os.getpid()}') 
    p = Process(target=foo, args=('bob',)) 
    p.start() 
    p.join() 
# 输出 => 
# parent process id: 18676 
# name: bob 
# parent process id: 18676 
# sub process id: 9856
```


```python
from multiprocessing import Process 
def foo(num): 
    print(num) 
 
if __name__ == '__main__': 
    mp = [] 
    for i in range(5): 
        p = Process(target=foo, args=(i,)) 
        mp.append(p)
        p.start() 
        # p.join() # 错误，会阻塞主进程进入下一次循环
        
    for p in mp: 
        p.join() # 正确 
```


```python
from multiprocessing import Process 
import os
 
class Foo(Process): 
    def __init__(self, name): 
        super().__init__() 
        self.name = name 
    def run(self): 
        print(f'name: {self.name}') 
        print(f'sub process: {os.getpid()}')
         
if __name__ == '__main__': 
    print(f'parent process: {os.getpid()}') 
    p = Foo('bob') 
    p.start() 
# 输出 => 
# parent process: 48424 
# name: bob 
# sub process: 38724
```
```python
from multiprocessing import Pool 
def foo(num): 
    print(num)
     
if __name__ == '__main__': 
    with Pool(5) as p: 
        p.map(foo, range(100))
```

### 子进程对象成员

```python
from multiprocessing import Process
 
def foo(x): 
    print(x)
     
if __name__ == '__main__': 
    p = Process(name='demo', target=foo, args=(1,)) 
    # 设置为守护进程，默认为 False 
    p.daemon = True 
    # 启动子进程
    p.start() 
    # 输出子进程名称
    print(p.name) 
    # 输出子进程 id 
    print(p.pid) 
    # 判断子进程是否存活
    print(p.is_alive()) 
    # 终止子进程
    p.kill() 
    # 终止子进程
    p.terminate() 
    # 输出子进程退出码
    print(p.exitcode) 
    # 关闭 Process 对象，释放其占用的资源
    p.close()
```

### 进程间通信

```python
from multiprocessing import Queue 
# 定义一个最大长度为 3 的队列
q = Queue(3) 
# 通过 put 方法添加成员
q.put(1) 
q.put(2) 
q.put(3) 
# 判断队列是否已满
print(q.full()) # => True 
# 获取队列当前大小
print(q.qsize()) # => 3 
# 通过 get 方法获取成员
print(q.get()) # => 1 
print(q.get()) # => 2 
print(q.get()) # => 3 
# 判断队列是否已空
print(q.empty()) # => True
```
```python
from multiprocessing import Process, Queue
 
def foo(q): 
    val = q.get() 
    while val: 
        print(val) 
        val = q.get() 
 
if __name__ == '__main__': 
    q = Queue() 
    p = Process(target=foo, args=(q,)) 
    p.start() 
    for val in [1, '0', False, 1.1]: 
        q.put(val) 
    p.join()
```

### 进程锁
```python
from multiprocessing import Process, Lock 

def buy(i, lock): 
    # 加锁
    lock.acquire() 
    with open('product', 'r') as fr: 
        num = int(fr.read()) 
        
    if num > 0: 
        num -= 1 
        print(f'子进程{i}抢购成功！') 
    else: 
        print(f'子进程{i}抢购失败！') 
        
    with open('product', 'w') as fw: 
        fw.write(str(num)) 
    # 解锁
    lock.release() 
 
if __name__ == '__main__': 
    # 创建锁
    lock = Lock() 
    for i in range(10): 
        p = Process(target=buy, args=(i, lock)) 
        p.start()
```

对于既需要申请又需要释放的场景，使用上下文管理器是最合适的，而多进程的锁对象也实现了上下文管理器的接口，所以上面的抢购函数代码可以修改为如下内容：

```python
def buy(i, lock): 
    with lock: 
        with open('product', 'r') as fr: 
            num = int(fr.read()) 
            
        if num > 0: 
            num -= 1 
            print(f'子进程{i}抢购成功！') 
        else: 
            print(f'子进程{i}抢购失败！') 
            
        with open('product', 'w') as fw: 
            fw.write(str(num))
```


## 多线程


### 多线程实现

```python
from threading import Thread
 
def foo(name): 
    print(f'线程{name}')
     
if __name__ == '__main__': 
    for i in range(5): 
        t = Thread(target=foo, args=(i,)) 
        t.start()
```


```python
from threading import Thread
 
class Foo(Thread): 
    def __init__(self, name):
        super().__init__() 
        self.name = name
         
    def run(self): 
        print(f'线程{self.name}')
  
if __name__ == '__main__': 
    ts = [] 
    for i in range(5): 
        t = Foo(i) 
        t.start() 
        ts.append(t)
```


```python
import time 
from threading import Thread 

class Foo(Thread): 
    def __init__(self, name): 
        super().__init__() 
        self.name = name 
        self.is_stop = False
     
    def run(self): 
        while not self.is_stop: 
            print(f'线程{self.name}') 
            time.sleep(1)
             
    def stop(self): 
        self.is_stop = True 
 
if __name__ == '__main__': 
    t = Foo(1) 
    t.start() 
    t.stop()
```


```python
import time 
from threading import Thread
 
def foo(num): 
    time.sleep(1) 
    print(f'子线程{num}执行') 
    
if __name__ == '__main__': 
    print(f'主线程开始')
    t = Thread(target=foo, args=(1,)) 
    t.start() 
    print(f'子线程 1 阻塞') 
    t.join() # 阻塞主线程
    print(f'子线程 1 是否存活: {t.is_alive()}') 
    t2 = Thread(target=foo, args=(2,)) 
    t2.daemon = True # 设置为守护线程
    t2.start() 
    print(f'主线程结束') 
# 输出 => 
# 主线程开始
# 子线程 1 阻塞
# 子线程 1 执行
# 子线程 1 是否存活: False 
# 主线程结束 
```

### 线程间通信

```python
import threading
 
num = 0 

def producer(): 
    global num 
    print(f"生产前数量 : {num}") 
    for i in range(3): 
        num += 1 
    print(f"生产后数量 : {num}") 
def consumer(): 
    global num 
    print(f"消费前数量 : {num}") 
    for i in range(num): 
        num -= 1 
    print(f"消费后数量 : {num}")
  
if __name__ == '__main__': 
    t1 = threading.Thread(target=producer) 
    t1.start() 
    t1.join() 
    t2 = threading.Thread(target=consumer) 
    t2.start()
# 输出 => 
# 生产前数量 : 0 
# 生产后数量 : 3 
# 消费前数量 : 3 
# 消费后数量 : 0 
```

### 线程锁

```python
from threading import Thread, Lock
 
num = 3 
lock = Lock() 
def buy(i): 
    global num 
    with lock: 
        if num > 0: 
            num -= 1 
            print(f'子线程{i}抢购成功') 
        else: 
            print(f'子线程{i}抢购失败')
     
if __name__ == '__main__': 
    for i in range(10): 
        t = Thread(target=buy, args=(i,)) 
        t.start()
```



### GIL机制

```python
from threading import Thread, Lock
 
num = 0 
lock = Lock() 
def inc(total): 
    global num 
    while total: 
        num += 1 
        total -= 1
  
if __name__ == '__main__': 
    ts = [] 
    for i in range(5): 
        t = Thread(target=inc, args=(100000,)) 
        t.start() 
        ts.append(t) 
        
    [t.join() for t in ts] 
    print(f'num 值为：{num}')
```



## 协程

协程，又称微线程，是一种协作式的执行机制。

从结构上来讲，一个进程可以包含多个线程，而一个线程又可以包含多个协程。

多个线程之间共享的是进程的资源，而多个协程之间除了共享进程资源，还会共享线程的执行栈权限。

协程之间的运行方式是协作式的，即一个线程内同一时间只有一个协程在执行，且在协程执行过程中不会被其他协程所中断，只有当前协程主动挂起后，其他协程才有可能获得执行权限。

因此协程之间的执行是可以有顺序的，最原始的协程模式可以通过yield保留字来实现，具体示例代码如下：

```python
def ask(): 
    for i in range(1, 4): 
        print(f'问题{i}') 
        yield i 
    yield None
     
def answer(): 
    ask1 = ask() 
    i = ask1.send(None) 
    while i: 
        print(f'回答{i}') 
        i = ask1.send(i)
  
if __name__ == '__main__': 
    answer() 
# 输出 => 
# 问题 1 
# 回答 1 
# 问题 2 
# 回答 2 
# 问题 3 
# 回答 3
```

示例中的ask函数既是生成器，也是模拟协程，因为协程的特性可以通过生成器的方式来实现，即一个可以挂起和恢复的函数对象。

但是之前并没有所谓的协程对象，所以生成器只能说是协程的一种模拟形式。



> 说明：实际上yield方式实现的协程仅仅是Python的一种语法糖，即Python虚拟机在指令集层面并没有支持协程；而yield方式之所以能实现协程，本质上是因为生成器机制。

为了能更好地支持协程机制，Python 3.5提供了原生协程的支持，即可以在Python中直接定义一个协程对象，而不再是模拟协程的生成器对象。

方法是引入 async 和 await 保留字，具体原生协程定义的示例代码如下：


```python
import asyncio
 
async def say(delay): 
    await asyncio.sleep(delay) 
print(say(1)) 
# 输出 => <coroutine object say at 0x00E6CE88>
```


示例中的async def用于显式地定义一个协程函数，通过say(1)语句调用协程函数会返回一个协程对象；

await则类似于yield from，用于返回另外一个协程对象。


以上述问答场景为例，通过原生协程方式实现的具体示例如下：

```python
import asyncio
 
total = 4
 
async def ask(): 
    global total 
    for i in range(1, total): 
        print(f'问题{i}') 
        await asyncio.sleep(1)
  
async def answer(): 
    global total 
    for i in range(1, total): 
        print(f'回答{i}') 
        await asyncio.sleep(1)
  
if __name__ == '__main__': 
    # 创建协程对象
    ask1 = ask() 
    answer1 = answer() 
    # 创建事件循环
    loop = asyncio.get_event_loop() 
    # 创建任务
    ask_task = asyncio.ensure_future(ask1) 
    answer_task = asyncio.ensure_future(answer1) 
    # 启动协程
    loop.run_until_complete(ask_task) 
    loop.run_until_complete(answer_task) 
# 输出 => 
# 问题 1 
# 回答 1 
# 问题 2 
# 回答 2 
# 问题 3 
# 回答 3
```



除了使用Python官方的协程实现，还有第三方的协程库可以选择，如 gevent、greenlet、eventlet 等。这里以 gevent 为例演示协程并发抢购的场景，具体示例代码如下：

```python
import random 
import gevent
 
num = 3 
def buy(i): 
    global num 
    gevent.sleep(random.random()) 
    if num > 0: 
        num -= 1 
        print(f'协程{i}抢购成功') 
    else: 
        print(f'协程{i}抢购失败')
     
if __name__ == '__main__': 
    cl = [gevent.spawn(buy, i) for i in range(10)] 
    [c.join() for c in cl]
```
示例中通过gevent.sleep模拟抢购时的不同速度，如果不加这条语句，协程会按照顺序执行，那么永远是前3个协程抢购成功。


示例中也没有使用到锁，因为协程之间是协作式的关系，只有当前协程执行完指定任务并挂起后，其他协程才会被唤醒并执行任务，所以协程在执行任务代码的时候是一个相对的“原子”操作。

需要注意的是，gevent实现并发场景的前提是任务本身是非阻塞的，否则即使使用了gevent，也无法达到并发的目的。

实际编程中需要实现非阻塞的大部分场景都是I/O任务，如磁盘读写、网络访问等。


gevent库中提供了 monkey patch—— 一个用于把阻塞场景替换为非阻塞场景的补丁程序。

使用monkey patch可以把Python标准库中大部分的阻塞式系统调用替换为协助式的，因此在使用gevent实现协程时，通常在文件的顶部引入gevent.monkey模块，并

执行其下的 patch_all 方法来完成打补丁操作。

具体的示例代码如下：

```python
import gevent 
from gevent import monkey
 
monkey.patch_all()
 
def downloader(url): 
    print(url) 
    # TODO：执行具体的网络下载
    
if __name__ == '__main__': 
    urls = ("http://abc.com", "http://123.cn") 
    cl = [gevent.spawn(downloader, url) for url in urls] 
    [c.join() for c in cl]
```


示例中的第二、三行代码就是用来打monkey patch补丁的。

当Python执行完这两句之后，其标准库中的TCP网络模块就会被打上补丁，无论示例中的 downloader 函数通过哪个 http 库下载网页，都会使用到打完补丁后的非阻塞模块，所以就支持了协程的并发场景。


> 说明: 一般情况下，如果不是底层库的异步编程，不建议普通编程人员通过原生协程来开发代码；
> 对于普通的上层业务，建议直接使用第三方的协程库来实现，因为第三方库已经提供了更友好的API和更低的使用成本。


## 异步

```python
import asyncio 
import time
 
async def say(delay, what): 
    await asyncio.sleep(delay) 
    print(what) 
    
async def main(): 
    print(f"started at {time.strftime('%X')}") 
    await say (1, 'hello') 
    await say (2, 'world') 
    print(f"finished at {time.strftime('%X')}") 
    
if __name__ == '__main__': 
    loop = asyncio.get_event_loop() 
    loop.run_until_complete(main())
```



```python
async def main(): 
    print(f"started at {time.strftime('%X')}") 
    t1 = asyncio.create_task(say_after(1, 'hello')) 
    t2 = asyncio.create_task(say_after(2, 'hello')) 
    await t1 
    await t2 
    print(f"finished at {time.strftime('%X')}")
```
```python
async def say(delay, what): 
    time.sleep(delay) 
    await asyncio.sleep(0) 
    print(what)
```