# 3.生产环境下的 Shell 脚本

## 1.生产环境下的备份类脚本

### 1.1 版本控制软件 SVN 的代码库的备份脚本

```shell
#!/bin/sh
SVNDIR=/data/svn
SVNADMIN=/usr/bin/svnadmin
DATE=`date +%Y-%m-%d`
OLDDATE=`date +%Y-%m-%d -d '30 days'`
BACKDIR=/data/backup/svn-backup

[ -d ${BACKDIR} ] || mkdir -p ${BACKDIR}
LogFile=${BACKDIR}/svnbak.log
[ -f ${LogFile} ] || touch ${LogFile}
mkdir ${BACKDIR}/${DATE}


for PROJECT in myproject official analysis mypharma
do
  cd $SVNDIR
  $SVNADMIN hotcopy $PROJECT  $BACKDIR/$DATE/$PROJECT --clean-logs
  cd $BACKDIR/$DATE
  tar zcvf ${PROJECT}_svn_${DATE}.tar.gz $PROJECT  > /dev/null
  rm -rf $PROJECT
sleep 2
done

HOST=192.168.2.112
FTP_USERNAME=svn
FTP_PASSWORD=svn101

cd ${BACKDIR}/${DATE}

ftp -i -n -v << !
open ${HOST}
user ${FTP_USERNAME} ${FTP_PASSWORD}
bin
cd ${OLDDATE}
mdelete *
cd ..
rmdir ${OLDDATE}
mkdir ${DATE}
cd ${DATE}
mput *
bye
!
```

### 1.2 Mysql 数据库备份至 S3 文件系统

这里首先为大家介绍下亚马逊的分布式文件系统 S3,S3 为开发人员提供了一个高度扩展(Scalability)、高持久性(Durability)和高可用(Availability)的分布式数据存储服务。

它是一个完全针对互联网的数据存储服务，应用程序通过一个简单的 Wb 服务接口就可以 通过互联网在任何时候访问 S3 上的数据。当然存放在 S3 上的数据可以进行访问控制以保障数据的安全性。

这里所说的访问 S3 包括读、写、删除等多种操作。

在脚本的最后，采用 SES S3 命令中的 cp 可将 MySQL 上传至 s3:/example-shar 这个 bucket 上面（关于 S3 的更多详细资料请参考官方文档 htp:/aws.amazon.com/cn/s3/),

脚本内容如下所示（此脚本已在 Amazon Linux AMI x8664 下测试通过)：

```shell
#!/bin/bash
#
# Filename:backupdatabase.sh
# Description: backup cms database and remove backup data before 7 days
# crontab
# 55 23 * * * /bin/sh /yundisk/cms/crontab/backupdatabase.sh >> /yundisk/cms/crontab/backupdatabase.log 2>&1

DATE=`date +%Y-%m-%d`
OLDDATE=`date +%Y-%m-%d -d '-7 days'`

#MYSQL=/usr/local/mysql/bin/mysql
#MYSQLDUMP=/usr/local/mysql/bin/mysqldump
#MYSQLADMIN=/usr/local/mysql/bin/mysqladmin

BACKDIR=/yundisk/cms/database
[ -d ${BACKDIR} ] || mkdir -p ${BACKDIR}
[ -d ${BACKDIR}/${DATE} ] || mkdir ${BACKDIR}/${DATE}
[ ! -d ${BACKDIR}/${OLDDATE} ] || rm -rf ${BACKDIR}/${OLDDATE}

mysqldump --default-character-set=utf8 --no-autocommit --quick --hex-blob --single-transaction -uroot  cms_production  | gzip > ${BACKDIR}/${DATE}/cms-backup-${DATE}.sql.gz
echo "Database cms_production and bbs has been backup successful"
/bin/sleep 5

aws s3 cp ${BACKDIR}/${DATE}/* s3://example-share/cms/databackup/
```

### 1.3 mysq 备份脚本

全量备份，增量备份需手动开启后在开启删除开关

```shell
#!/bin/bash
# @author:kevin.xiang
# create -e
# 0 0 * * 0 bash /mysql
##########################
DATA=`date +%Y%m%d%H-%T`
BIN_DIR="/usr/bin/"
BACKUP_DIR="/backup/"
BACKUP_NAME="mysqlbackup"
LOG_DIR="/var/log/mariadb/"
DB_IP="localhost"
DB_ROOT="root"
DB_PASSWD="xiangsikai"
# Binary log deletion.  0 on | 1 off
Flag=1

#-- Full amount of backup
function backup_all() {
  sudo ${BIN_DIR}mysqldump -h${DB_IP} -u${DB_ROOT} -p${DB_PASSWD} --all-databases  > ${BACKUP_DIR}${BACKUP_NAME}_${DATA}.sql
  if [ $? == 0  ];then
    sudo ${BIN_DIR}gzip ${BACKUP_DIR}${BACKUP_NAME}_${DATA}.sql >/dev/null 2>&1
    echo "${DATA} full backup successful !!!">> ${LOG_DIR}backup.log
  else
    echo "${DATA} full backup failure !!!" >> ${LOG_DIR}backup.log
  fi
}

#-- Incremental of backup
function backup_incremental() {
if [ ${Flag} == 0 ];then
sudo mysql -u${DB_ROOT} -p${DB_PASSWD} -h${DB_IP} << EOF >/dev/null 2>&1
reset master;
flush privileges;
EOF
echo "${DATA} Clean binary file !!!" >> ${LOG_DIR}backup.log
fi
}

#-- Run backup
file_num=`find ${BACKUP_DIR} -name "*.sql.gz" | ${BIN_DIR}wc -l`
if [ ${file_num} -ge 3 ];then
  old_file=`${BIN_DIR}ls -lrt ${BACKUP_DIR}${BACKUP_NAME}* | ${BIN_DIR}awk 'NR==1' | ${BIN_DIR}awk '{print $9}'`
  sudo ${BIN_DIR}rm -rf ${old_file} >/dev/null 2>&1
  if [ $? == 0   ];then
    echo "${DATA} Clean ${old_file} file successfully !!!" >> ${LOG_DIR}backup.log
  else
    echo "${DATA} Clean ${old_file} file failure !!!" >> ${LOG_DIR}backup.log
  fi
  backup_all
  backup_incremental
else
  backup_all
  backup_incremental
fi
```

## 2.生产环境下的统计类脚本

统计工作是一直是 Shell 的强项，对于海量日志，我们需要引入 ElasticSearch（Kibana)等大数据开源组件，但对于一般的系统日志或应用日志我们完全可以通过 Shell 命令，如 awk 和 sed 来完成工作。

除此之外，其他方面的统计工作，Shell 完成起来也很得心应手。

### 2.1 统计设备资产明细脚本

下面的脚本是我们统计 DC 机房设备的详细信息，输出结果较为详细，我们比较关注的地方是机器有几块 SSD、有几块万兆网卡、是否符合高配标准、能否适配负载高的平台，

事实上，我们还可以使用 Python 或 Golang 封装此 Shell 脚本，以后端 API 的形式提供更好的数据展示结构，例如 JSON ,脚本内容如下所示：

```shell
#!/bin/bash

#####get cpu info#####
cpu_num=`cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l`
cpu_sum=`cat /proc/cpuinfo |grep processor |wc -l`
cpu_hz=`cat /proc/cpuinfo |grep 'model name' |uniq -c |awk '{print $NF}'`

#####get mem info#####
mem_m=0
for i in `dmidecode -t memory |grep Size: |grep -v "No Module Installed" |awk '{print $2}'`
do
	mem_m=`expr $mem_m + $i`
done
mem_sum=`echo $mem_m / 1024 | bc`

#####get nic info#####
qian_num=`lspci |grep Ethernet |egrep -v '10-Gigabit|10 Gigabit' |wc -l`
wan_num=`lspci |grep Ethernet |egrep  '10-Gigabit|10 Gigabit' |wc -l`

#####get disk num#####
B=`date +%s`
ssd_num=0=
sata_num=0
for i in `lsblk |grep "disk"|awk '{print $1}'|egrep -v "ram"|sort`;
do
    code=`cat /sys/block/$i/queue/rotational`
    if [ "$code" = "0" ];then
       ssd_num=`expr $ssd_num + 1` && echo $i >>/tmp/$B.ssd
    else
       sata_num=`expr $sata_num + 1` && echo $i >>/tmp/$B.sata
    fi
done

#####get disk sum#####
C=`date +%N`
ssd_sum=0
sata_sum=0
if [ -f /tmp/$B.ssd ];then
    for n in `cat /tmp/$B.ssd`;do
    	fdisk -l /dev/$n >>/tmp/$C.ssd 2>&1
     	for x in `grep "Disk /dev" /tmp/$C.ssd |awk '{print $3}'`;do
        	u=`echo $x / 1|bc`
     	done
     ssd_sum=`expr $ssd_sum + $u + 1`
  	done
fi

for m in `cat /tmp/$B.sata`;do
   fdisk -l /dev/$m >>/tmp/$C.sata 2>&1
   for y in `grep "Disk /dev" /tmp/$C.sata |awk '{print $3}'`;do
      v=`echo $y / 1|bc`
   done
   sata_sum=`expr $sata_sum + $v + 1`
done

#####show dev info#####
echo -n "$ip `hostname` $plat $pop $prov "
echo -n "CPU(物理核数,逻辑核数,频率): $cpu_num $cpu_sum $cpu_hz "
echo -n "内存(GB): $mem_sum "
echo -n "网卡数量(千兆,万兆): $qian_num $wan_num "
echo "SSD数量: ${ssd_num} SSD容量: ${ssd_sum}GB SATA数量: ${sata_num} SATA容量 ${sata_sum}GB "
```

### 2.2 统计重要业务程序是否正常运行

统计重要业务程序是否正常运行的需求比较简单，主要是统计（或监测）业务进程 rsync\_.redis.py 的数量是否为 1（即正常运行），有没有发生崩溃的情况。

另外，建议将类似于 rsync_redis.py 的重要业务进程交由 Superviored 守护进程托管。

脚本内容如下所示（此脚本已在 Amazon Linux AMI x86_64 下测试通过)：

```shell
#!/bin/bash
sync_redis_status=`ps aux | grep sync_redis.py | grep -v grep | wc -l `
if [ ${sync_redis_status} != 1 ]; then
    echo "Critical! sync_redis is Died"
    exit 2
else
    echo "OK! sync_redis is Alive"
    exit 0
fi
```

### 2.3 统计机器的 IP 连接数

统计机器的 IP 连接数的需求其实比较简单，先统计 IP 连接数，如果 ip_conns 的值小于 15 000 则显示为正常，介于 15 000~20 000 之间为警告，如果超过 20 000 则报警，脚
本内容如下所示（此脚本已在 Amazon Linux AMI x86_64 下测试通过）：

```shell
#!/bin/bash
#脚本的$1和$2报警阀值可以根据业务的实际情况调整。
#$1 = 15000，$2 = 20000
ip_conns=`netstat -an | grep tcp | grep EST | wc -l`
messages=`netstat -ant | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'|tr -s '\n' ',' | sed -r 's/(.*),/\1\n/g' `

if [ $ip_conns -lt $1 ]
then
	echo "$messages,OK -connect counts is $ip_conns"
    exit 0
fi
if [ $ip_conns -gt $1 -a $ip_conns -lt $2 ]
then
    echo "$messages,Warning -connect counts is $ip_conns"
    exit 1
fi
if [ $ip_conns -gt $2 ]
then
    echo "$messages,Critical -connect counts is $ip_conns"
    exit 2
fi

```

## 3.生产环境下的监控类脚本

在生产环境下，服务器的稳定情况将会直接影响公司的生意和信誉，可见其有多重要。

所以，我们需要即时掌握服务器的状态，我们一般会在机房部署 Nagios、Zabbix 或者自己 公司独立研发的监控系统来进行实时监控，然后用 Shell、Perl 或 Python 等脚本语言根据业 务需求开发监控插件，实时监控线上业务。

### 3.1 在 Nginx 负载均衡器上监控 Nginx 进程的脚本

由于笔者公司电子商务业务网站前端的负载均衡机制用到了 Nginx+keepalived 架构，
而 keepalived 无法进行 Nginx 服务的实时切换，所以又用了一个监控脚本`nginx_pid.sh`,每 隔 5 秒钟就监控一次 Nginx 的运行状态（也可以由 Superviored 守护进程托管)，如果发现
有问题就关闭本机的 keepalived 程序，让 VIP 切换到从 Nginx 负载均衡器上。

在对线上环 境进行操作的时候，人为地重启主 Master 的 Nginx 机器，从 Nginx 机器将在很短的时间内接管 VIP 地址，即网站的实际内网地址（此内网地址能通过防火墙映射为公网 P),这
又进一步证实了此脚本的有效性，脚本内容如下（此脚本已在 CentOS6.8x86_64 下测试 通过)：

```shell
#!/bin/bash
while :
do
 nginxpid=`ps -C nginx --no-header | wc -l`
 if [ $nginxpid -eq 0 ];then
    ulimit -SHn 65535
    /usr/local/nginx/sbin/nginx
    sleep 5
   if [ $nginxpid -eq 0 ];then
     /etc/init.d/keepalived stop
   fi
 fi
 sleep 5
done
```

### 3.2 系统文件数打开监控脚本

这个脚本比较方便，可用来查看 Ngix 进程下的最大文件打开数，脚本代码如下（此脚本已在`CentOS6.4|6.8 x86_x64、Amazon Linux AMI x86_64`下测试通过)：

```shell
#!/bin/bash
for pid in `ps aux |grep nginx |grep -v grep|awk '{print $2}'`
do
cat /proc/${pid}/limits | grep 'Max open files'
done
```

### 3.3 监控机器 CPU 利用率脚本

线上的 bidder 业务机器，在业务繁忙的高峰期会出现 CPU 利用率超过 99.99% (sys%+user%)的情况，从而导致出现后面的流量完全进不来的情况， 但此时机器系统负载及 Ngix+Lua 进程都是完全正常的，均能对外提供服务。

所以需要开发一个 CPU 利用率脚本，在超过自定义阈值时报警，以方便运维人员批量添加 bidder 机器应对峰值，AWS EC2 实例机器是可以以小时(现在已经优化到了秒)来计费的，大家在这里需要注意 系统负载 和 CPU 利用率之间的区别。

脚本内容如下所示（脚本已在 Amazon Linux AMI x86_64 下测试通过)：

```shell
#!/bin/bash
# CPU Utilization Statistics plugin for Nagios
#
# USAGE     :   ./check_cpu_utili.sh [-w <user,system,iowait>] [-c <user,system,iowait>] ( [ -i <intervals in second> ] [ -n <report number> ])
#
# Exemple: ./check_cpu_utili.sh
#          ./check_cpu_utili.sh -w 70,40,30 -c 90,60,40
#          ./check_cpu_utili.sh -w 70,40,30 -c 90,60,40 -i 3 -n 5
# Paths to commands used in this script.  These may have to be modified to match your system setup.
IOSTAT="/usr/bin/iostat"

# Nagios return codes
STATE_OK=0
STATE_WARNING=1
STATE_CRITICAL=2
STATE_UNKNOWN=3

# Plugin parameters value if not define
LIST_WARNING_THRESHOLD="70,40,30"
LIST_CRITICAL_THRESHOLD="90,60,40"
INTERVAL_SEC=1
NUM_REPORT=1
# Plugin variable description
PROGNAME=$(basename $0)

if [ ! -x $IOSTAT ]; then
    echo "UNKNOWN: iostat not found or is not executable by the nagios user."
    exit $STATE_UNKNOWN
fi

print_usage() {
        echo ""
        echo "$PROGNAME $RELEASE - CPU Utilization check script for Nagios"
        echo ""
        echo "Usage: check_cpu_utili.sh -w -c (-i -n)"
        echo ""
        echo "  -w  Warning threshold in % for warn_user,warn_system,warn_iowait CPU (default : 70,40,30)"
        echo "  Exit with WARNING status if cpu exceeds warn_n"
        echo "  -c  Critical threshold in % for crit_user,crit_system,crit_iowait CPU (default : 90,60,40)"
        echo "  Exit with CRITICAL status if cpu exceeds crit_n"
        echo "  -i  Interval in seconds for iostat (default : 1)"
        echo "  -n  Number report for iostat (default : 3)"
        echo "  -h  Show this page"
        echo ""
    echo "Usage: $PROGNAME"
    echo "Usage: $PROGNAME --help"
    echo ""
    exit 0
}

print_help() {
    print_usage
        echo ""
        echo "This plugin will check cpu utilization (user,system,CPU_Iowait in %)"
        echo ""
    exit 0
}

# Parse parameters
while [ $# -gt 0 ]; do
    case "$1" in
        -h | --help)
            print_help
            exit $STATE_OK
            ;;
        -v | --version)
                print_release
                exit $STATE_OK
                ;;
        -w | --warning)
                shift
                LIST_WARNING_THRESHOLD=$1
                ;;
        -c | --critical)
               shift
                LIST_CRITICAL_THRESHOLD=$1
                ;;
        -i | --interval)
               shift
               INTERVAL_SEC=$1
                ;;
        -n | --number)
               shift
               NUM_REPORT=$1
                ;;
        *)  echo "Unknown argument: $1"
            print_usage
            exit $STATE_UNKNOWN
            ;;
        esac
shift
done

# List to Table for warning threshold (compatibility with
TAB_WARNING_THRESHOLD=(`echo $LIST_WARNING_THRESHOLD | sed 's/,/ /g'`)
if [ "${#TAB_WARNING_THRESHOLD[@]}" -ne "3" ]; then
  echo "ERROR : Bad count parameter in Warning Threshold"
  exit $STATE_WARNING
else
USER_WARNING_THRESHOLD=`echo ${TAB_WARNING_THRESHOLD[0]}`
SYSTEM_WARNING_THRESHOLD=`echo ${TAB_WARNING_THRESHOLD[1]}`
IOWAIT_WARNING_THRESHOLD=`echo ${TAB_WARNING_THRESHOLD[2]}`
fi

# List to Table for critical threshold
TAB_CRITICAL_THRESHOLD=(`echo $LIST_CRITICAL_THRESHOLD | sed 's/,/ /g'`)
if [ "${#TAB_CRITICAL_THRESHOLD[@]}" -ne "3" ]; then
  echo "ERROR : Bad count parameter in CRITICAL Threshold"
  exit $STATE_WARNING
else
USER_CRITICAL_THRESHOLD=`echo ${TAB_CRITICAL_THRESHOLD[0]}`
SYSTEM_CRITICAL_THRESHOLD=`echo ${TAB_CRITICAL_THRESHOLD[1]}`
IOWAIT_CRITICAL_THRESHOLD=`echo ${TAB_CRITICAL_THRESHOLD[2]}`
fi

if [ ${TAB_WARNING_THRESHOLD[0]} -ge ${TAB_CRITICAL_THRESHOLD[0]} -o ${TAB_WARNING_THRESHOLD[1]} -ge ${TAB_CRITICAL_THRESHOLD[1]} -o ${TAB_WARNING_THRESHOLD[2]} -ge ${TAB_CRITICAL_THRESHOLD[2]} ]; then
  echo "ERROR : Critical CPU Threshold lower as Warning CPU Threshold "
  exit $STATE_WARNING
fi

CPU_REPORT=`iostat -c $INTERVAL_SEC $NUM_REPORT | sed -e 's/,/./g' | tr -s ' ' ';' | sed '/^$/d' | tail -1`
CPU_REPORT_SECTIONS=`echo ${CPU_REPORT} | grep ';' -o | wc -l`
CPU_USER=`echo $CPU_REPORT | cut -d ";" -f 2`
CPU_SYSTEM=`echo $CPU_REPORT | cut -d ";" -f 4`
CPU_IOWAIT=`echo $CPU_REPORT | cut -d ";" -f 5`
CPU_STEAL=`echo $CPU_REPORT | cut -d ";" -f 6`
CPU_IDLE=`echo $CPU_REPORT | cut -d ";" -f 7`
NAGIOS_STATUS="user=${CPU_USER}%,system=${CPU_SYSTEM}%,iowait=${CPU_IOWAIT}%,idle=${CPU_IDLE}%"
NAGIOS_DATA="CpuUser=${CPU_USER};${TAB_WARNING_THRESHOLD[0]};${TAB_CRITICAL_THRESHOLD[0]};0"

CPU_USER_MAJOR=`echo $CPU_USER| cut -d "." -f 1`
CPU_SYSTEM_MAJOR=`echo $CPU_SYSTEM | cut -d "." -f 1`
CPU_IOWAIT_MAJOR=`echo $CPU_IOWAIT | cut -d "." -f 1`
CPU_IDLE_MAJOR=`echo $CPU_IDLE | cut -d "." -f 1`



# Return
if [ ${CPU_USER_MAJOR} -ge $USER_CRITICAL_THRESHOLD ]; then
        echo "CPU STATISTICS OK:${NAGIOS_STATUS} | CPU_USER=${CPU_USER}%;70;90;0;100"
        exit $STATE_CRITICAL
    elif [ ${CPU_SYSTEM_MAJOR} -ge $SYSTEM_CRITICAL_THRESHOLD ]; then
        echo "CPU STATISTICS OK:${NAGIOS_STATUS} | CPU_USER=${CPU_USER}%;70;90;0;100"
        exit $STATE_CRITICAL
    elif [ ${CPU_IOWAIT_MAJOR} -ge $IOWAIT_CRITICAL_THRESHOLD ]; then
        echo "CPU STATISTICS OK:${NAGIOS_STATUS} | CPU_USER=${CPU_USER}%;70;90;0;100"
        exit $STATE_CRITICAL
    elif [ ${CPU_USER_MAJOR} -ge $USER_WARNING_THRESHOLD ] && [ ${CPU_USER_MAJOR} -lt $USER_CRITICAL_THRESHOLD ]; then
        echo "CPU STATISTICS OK:${NAGIOS_STATUS} | CPU_USER=${CPU_USER}%;70;90;0;100"
        exit $STATE_WARNING
      elif [ ${CPU_SYSTEM_MAJOR} -ge $SYSTEM_WARNING_THRESHOLD ] && [ ${CPU_SYSTEM_MAJOR} -lt $SYSTEM_CRITICAL_THRESHOLD ]; then
        echo "CPU STATISTICS OK:${NAGIOS_STATUS} | CPU_USER=${CPU_USER}%;70;90;0;100"
        exit $STATE_WARNING
      elif  [ ${CPU_IOWAIT_MAJOR} -ge $IOWAIT_WARNING_THRESHOLD ] && [ ${CPU_IOWAIT_MAJOR} -lt $IOWAIT_CRITICAL_THRESHOLD ]; then
        echo "CPU STATISTICS OK:${NAGIOS_STATUS} | CPU_USER=${CPU_USER}%;70;90;0;100"
        exit $STATE_WARNING
else

        echo "CPU STATISTICS OK:${NAGIOS_STATUS} | CPU_USER=${CPU_USER}%;70;90;0;100"
        exit $STATE_OK
fi
```

## 4.生产环境下运维开发类脚本

### 4.1 系统初始化脚本

系统初始化脚本用于新装 Linux 的相关配置工作，

比如禁掉 iptables 和 SELinux 及 IPv6、优化系统内核、停掉一些没必要启动的系统服务等。

我们将系统初始化脚本应用于公司内部的运维开发机器的批量部署（比如用 Ansible 来下发）上。

事实上，复杂的系统业务初始化 initial 脚本由于涉及了多条产品线和多个业务平台，因此远比这里列出的开发环境下的初始化脚本复杂得多，而且其代码量也极大，基本上都是 6000 ～ 7000 行的 Shell 脚本，各功能模块以函数的形式进行封装。

下面的脚本只是涉及一些基础部分，希望大家注意这点。脚本代码如下所示（此脚本已在 CentOS 6.8 x86_x64 下测试通过）：

```shell
#!/bin/bash

#添加epel外部yum扩展源
cd /usr/local/src
wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm
rpm -ivh epel-release-6-8.noarch.rpm

#安装gcc基础库文件以及sysstat工具
yum -y install gcc gcc-c++ vim-enhanced unzip unrar sysstat

#配置ntpdate自动对时
yum -y install ntp
echo "01 01 * * * /usr/sbin/ntpdate ntp.api.bz    >> /dev/null 2>&1" >> /etc/crontab
ntpdate ntp.api.bz
service crond restart

#配置文件的ulimit值
ulimit -SHn 65535
echo "ulimit -SHn 65535" >> /etc/rc.local
cat >> /etc/security/limits.conf << EOF
*                     soft     nofile             65535
*                     hard     nofile             65535
EOF

#基础系统内核优化
cat >> /etc/sysctl.conf << EOF
fs.file-max=419430
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_syn_retries = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 1
net.ipv4.tcp_keepalive_time = 1200
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.tcp_max_tw_buckets = 36000
net.ipv4.route.gc_timeout = 100
net.ipv4.tcp_syn_retries = 1
net.ipv4.tcp_synack_retries = 1
net.core.somaxconn = 16384
net.core.netdev_max_backlog = 16384
net.ipv4.tcp_max_orphans = 16384
EOF
/sbin/sysctl -p

#禁用control-alt-delete组合键以防止误操作
sed -i 's@ca::ctrlaltdel:/sbin/shutdown -t3 -r now@#ca::ctrlaltdel:/sbin/shutdown -t3 -r now@' /etc/inittab

#关闭SELinux
sed -i 's@SELINUX=enforcing@SELINUX=disabled@' /etc/selinux/config

#关闭iptables
service iptables stop
chkconfig iptables off

#ssh服务配置优化,请至少保持机器中至少有一个具有sudo权限的用户，下面的配置会禁止root远程登录
sed -i 's@#PermitRootLogin yes@PermitRootLogin no@' /etc/ssh/sshd_config #禁止root远程登录
sed -i 's@#PermitEmptyPasswords no@PermitEmptyPasswords no@' /etc/ssh/sshd_config #禁止空密码登录
sed -i 's@#UseDNS yes@UseDNS no@' /etc/ssh/sshd_config /etc/ssh/sshd_config
service sshd restart

#禁用IPv6地址
echo "alias net-pf-10 off" >> /etc/modprobe.d/dist.conf
echo "alias ipv6 off" >> /etc/modprobe.d/dist.conf
chkconfig ip6tables off

#vim基础语法优化
echo "syntax on" >> /root/.vimrc
echo "set nohlsearch" >> /root/.vimrc

#精简开机自启动服务，安装最小化服务的机器初始可以只保留crond，network，rsyslog，sshd这四个服务。
for i in `chkconfig --list|grep 3:on|awk '{print $1}'`;do chkconfig --level 3 $i off;done
for CURSRV  in crond rsyslog sshd network;do chkconfig --level 3 $CURSRV on;done

#重启服务器
reboot
```

### 4.2 控制 shell 多进程数量的脚本

下面的 `run.py` 是爬虫程序，经测试，在机器上运行 8 个 `run.py` 进程是机器性能最好的时候，该进程数量既能充分发挥机器的性能又不会导致机器响度速度过慢。

而且有时为了避免并发进程数过多导致机器卡死，需要**限制并发的数量**。下面的脚本可以实现这个需求，其代码如下所示：

```shell
#!/usr/bin/env bash
#usage:xxx
#scripts_name:${NAME}.sh
# author：xiaojian

CE_HOME="/data/ContentEnginne"
LOG_PATH="/data/logs"

# 控制爬虫数量为8
MAX_SPIDER_COUNT=8

count=`ps -ef|grep -v grep|grep run.py|wc -l`
try_time=0

cd $CE_HOME

# 限制并发的数量
while [ $count -lt $MAX_SPIDER_COUNT -a $try_time -lt $MAX_SPIDER_COUNT ]; do
    let try_time +=1
    python run.py >> ${LOG_PATH}/spider.log 2>&1 &
    count=`ps -ef|grep -v grep|grep run.py|wc -l`
done
```

### 4.3 调用 Ansible 来分发多条线路的配置

Ansible 的`hosts`文件内容如下,举例 IP，真实 IP 已被隐藏

```
[yd]
1.1.1.1
2.2.2.2

[wt]
3.3.3.3
4.4.4.4

[dx]
5.5.5.5
6.6.6.6
```

`publishconf.sh`部分内容如下

```shell
#!/bin/bash

#如果hosts文件不存在，就调用touch命令建立；另外，这里要增加一个逻辑判断，即如果已经有人在发布平台了，第二个运维人员发布的时候，一定要强制退出，等待前面的发布人员发布结束。
if [ ! -f "$hosts" ]
then
    touch "$hosts"
else
    echo "此平台已经有运维小伙伴在发布，请耐心等待！"
    exit
fi

#如果出现中止进程的情况，捕捉异常信号，清理临时文件。
trap "echo '程序被中止，开始清理临时文件';rm -rf $hosts;exit" 1 2 3
#进入public_conf目录，通过git pull获取gitlab上最新的相关文件配置

cd /data/conf /public_conf/
git pull origin master:master

#配置文件这里也是通过内部的GitLab管理，这里没简化操作，主要是防止执行git pull origin master或git pull的时候，此时可能会存在着多分支的情况会导致运行报错
if [ $? == 0 ];then
    echo "当前配置文件为最新版本，可以发布！"
else
    echo "当前配置文件不是最新的，请检查后再发布"
    exit
fi

#此为发布单平台多IP的逻辑，$#判断参数个数，这里的逻辑判断为参数大于或等于3时就是单平台多IP发布。
if [ $# >=3 ];then
  shift 1
  这里通过shift命令往左偏移一个位置参数，从而获取全部的IP。
  echo "此次需要更新的机器IP为：$@"
  for flat in $@
  do
  echo "此次需要更新的机器IP为：$flat"
  platform=`awk '/\[/{a=$0}/'"$flat"'/{print a}' $hosts | head -n1`
	#通过这段awk命令组和来获取当前的机器ip属于哪条线路，比如是移动还是网通或者电信，后续有相应的措施。


  if  [[ $platform =~ "yd" ]];then
    /usr/local/bin/ansible -i $hosts $flat -m shell -a "/home/fastcache_conf/publish_fastcache.sh ${public_conf}_yd"
    elif  [[ $platform =~ "wt" ]];then
    /usr/local/bin/ansible -i $hosts $flat -m shell -a "/home/fastcache_conf/publish_fastcache.sh ${public_conf}_wt"
    else
    /usr/local/bin/ansible -i $hosts $flat -m shell -a "/home/fastcache_conf/publish_fastcache.sh ${public_conf}_dx"
  fi
  done
fi

#程序正常运行后，也要清理此临时文件，方便下次任务发布
rm -rf $hosts
trap "rm -rf $hosts" exit
```

### 4.4 手动建立软 RAID 级别需求

```shell
#!/bin/bash
function rg_mkfs_interac() {
    read -p "请输入您要做的RAID级别，可选择项为0|1|5|10:" raid
    read -p "请输入哪些磁盘需要并进RAID，磁盘之间请用空格格开，例如sdb sdc等" mydev
    echo $raid
    echo $mydev
    # create md0
        rg_info "Create RAID..."
        mdadm -Ss
        yes | mdadm -C /dev/md0 --level=$raid --auto=yes $mydev >/dev/null
        mdadm -D /dev/md0 >/dev/null || rg_info 58 "Create RAID /dev/md0 failed."
            # public
            partprobe /dev/$DISK_SYS 2>/dev/null
            sleep 3
            # mkfs
            for i in {${DISK_SYS}4,md0}; do
                echo -n "$MKFS /dev/$i... "
                if $MKFS /dev/$i &>/dev/null; then
                echo OK
                else
                echo failed && rg_info 55 "mkfs $i failed"
                fi
            done
            rg_info "Create cache direcotry..." && mkdir -p /cache/{cache,logs}
            echo -e "/dev/${DISK_SYS}4 \t\t/cache/logs \t\t$FS \tdefaults \t0 0" >>/etc/fstab
            echo -e "/dev/md0 \t\t/cache/cache \t\t$FS \t$MOUNT_OPTS \t0 0" >>/etc/fstab
        echo "--"
#save mdadm.conf
        if (mdadm -Ds 2>/dev/null |grep -q .); then
            [ -f /etc/mdadm.conf ] && rg_info "Backup old mdadm.conf..." && /bin/cp /etc/mdadm.conf /etc/mdadm.conf.bak
            rg_info "Save RAID configration (mdadm.conf)..."
                if [ "$VER6" == 'yes' ]; then
                    mdadm -Ds |sed 's!/dev/md[^ ]*:\([0-9]\)!/dev/md\1!; s!metadata[^ ]* !!; s/$/ auto=yes/' >/etc/mdadm.conf
                else
                    mdadm -Ds |sed 's/$/ auto=yes/' >/etc/mdadm.conf
                fi
        fi
#mount all
        fgrep -q /cache /etc/fstab || rg_info 48 "Internal error: f_mkfs has BUG!"
        rg_info "挂载所有分区..."
        if mount -a; then
            rg_info "创建mkpart锁..."
            echo "$VERSION" >$MKFS_LOCK 2>/dev/null && chattr +i $MKFS_LOCK
            ret=0
        else
            rg_info 49 "mount -a 出错"
        fi
        return $ret
}
```

### 4.5 重载或更新机器路由配置

参考了 Git 的思想，配置文件分成 3 种：

分别对应 Git 的工作区、Git 本地版本库和 Git 远程版本库。对应的动作和思路很明确：

reload 和 updata 动作都会进行差异对比，然后根据需求获取真正有用的 rules 配置文件。

这里只列举了`updata_rules()`函数,`reload_rules()`函数的设计思路与此类似。
其内容如下所示：

```shell
#!/bin/bash
function update_rules() {
#使用是内部SVN服务器，所以这里帐号和密码明文，没有考虑太多安全带来的问题
svn co svn://192.168.10.68/route_auto /tmp/route_auto --username=testyum --password=oTIil31pw --force --no-auth-cache

if [ $? -eq 0 ]; then
    echo "[INFO]: 获取最新 rules 成功,检测下载的 rules 库文件是否为空..."
    if !(test -s $LOCAL_TMP_RULES); then
        echo "获取到的最新 rules 库文件为空,请检查远端 rules 库文件!!"
        exit 1
    else
    cp -rf $LOCAL_TMP_RULES $RULES_ENV_FILE
    cp -rf $LOCAL_TMP_RULES $TMPFILES
    echo "获取到的最新 rules 库文件非空,程序继续..."
    fi

    echo "[INFO]: 将最新 rules 库文件与本地 rules 库文件比对是否有差异..."
    if ! (diff $RULES_ENV_FILE $LOCAL_TMP_RULES &>/dev/null); then
        echo "有差异 rules,加载最新 rules 库配置..."
        . $LOCAL_TMP_RULES
        cp -rf $LOCAL_TMP_RULES $RULES_ENV_FILE
    else
        echo "无差异 rules,加载本地 rules 库配置..."
        . $RULES_ENV_FILE
    fi
fi
}
```

### 4.6 容器镜像相关

#### 备份所有 docker 镜像

```shell
mkdir -p images && cd images
for image in `docker images | grep -v REPOSITORY | awk '{print $1":"$2}'`; do
    echo "saving the image of ${image}"
    docker save ${image} >  ${image////-}.tar
    echo -e "finished saving the image of \033[32m ${image} \033[0m"
done
```

#### 批量加载镜像

```shell
for image in `ls *.tar`; do
    echo "loading the image of ${image}"
    docker load < ${image}
    echo -e "finished loading the image of \033[32m ${image} \033[0m"
done
```

#### Python 脚本方式批量导出/导入镜像

批量导出，运行后所有 tar 包都在当前目录下

```python
# encoding: utf-8

import re
import os
import subprocess

if __name__ == "__main__":
    p = subprocess.Popen('docker images', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    for line in p.stdout.readlines():

        # 此处的正则表达式是为了匹配镜像名以kolla为开头的镜像
        # 实际使用中根据需要自行调整
        m = re.match(r'(^kolla[^\s]*\s*)\s([^\s]*\s)', line)

        if not m:
            continue

        # 镜像名
        iname = m.group(1).strip()
        # tag
        itag = m.group(2).strip()
        # tar包的名字
        if iname.find('/'):
            tarname = iname.split('/')[0] + '_' + iname.split('/')[-1]  + '_' + itag + '.tar'
        else:
            tarname = iname + '_' + itag + '.tar'
        print tarname
        ifull = iname + ':' + itag
        #save
        cmd = 'docker save -o ' + tarname + ' ' + ifull
        print os.system(cmd)

    retval = p.wait()
```

批量导入，同理导入当前目录下的所有的 tar 包

```python
import  os

images = os.listdir(os.getcwd())
for imagename in images:
    if imagename.endswith('.tar'):
        print(imagename)
        os.system('docker load -i %s'%imagename)
```

#### shell 脚本方式批量导出/导入镜像

导出

```sh
#!/bin/bash
docker images > images.txt
awk '{print $1}' images.txt > images_cut.txt
sed -i '1d' images_cut.txt
while read LINE
do
docker save $LINE > ${LINE//\//_}.train.tar
echo ok
done < images_cut.txt
echo finish
```

导入

```sh
#!/bin/bash
while read LINE;do
  docker  load -i $LINE
  echo ok
done < tarname.txt
echo finish
```

#### 如何备份系统中的所有镜像

backup_image.sh

```sh
#!/usr/bin/env bash
#usage:xxx
#scripts_name:${NAME}.sh
# author：xiaojian

# 备份镜像列表
docker images |awk 'NR>1{print $1":"$2}'|sort > images.list

# 导出所有镜像为当前目录下文件
while read img; do
    echo $img
    file="${img//\//-}"
    sudo docker save $img > $file.tar
done < images.list
```

将本地镜像导入为 docker 镜像

```sh
#!/usr/bin/env bash
#usage:xxx
#scripts_name:${NAME}.sh
# author：xiaojian
while read img; do
    echo $img
    file="${img//\//-}"
    sudo docker load < $file.tar
done < images.list
```

#### 批量删除指定 repository 所有镜像工具

```sh
#!/bin/sh
# Writed by yijian on 2020/8/31
# 批量删除指定 repository 所有镜像工具
# 运行时需要指定一个参数：
# 1）参数1：必选参数，repository 名，即“docker images”的第一列值

function usage() {
  echo "Remove all images with the given repository."
  echo "Usage: `basename $0` repository"
  echo "Example1: `basename $0` \"<none>\""
  echo "Example2: `basename $0` \"redis\""
}

# 参数检查
if test $# -ne 1; then
  usage
  exit 1
fi

repository="$1"
images=(`docker images|awk -v repository=$repository '{ if ($1==repository) print $3 }'`)
for ((i=0; i<${#images[@]}; ++i))
do
  image="${images[$i]}"
  echo "[$i] docker rmi \"$image\""
  docker rmi "$image"
done
```

### 4.7 安装 LVM、NFS

```shell
#基本配置
# hostname cinder1
# IP 192.168.58.24
# hostnamectl set-hostname cinder1
#hosts设置

##############
#添加硬盘……
#fdisk快速分区,新建2个30G分区
echo -e 'n\np\n1\n\n+30G\nw' | fdisk /dev/sdb
echo -e 'n\np\n2\n\n+30G\nw' | fdisk /dev/sdb
#格式化
mkfs.ext4 /dev/sdb1
mkfs.ext4 /dev/sdb2

mkdir -p /data
mount -t ext4 /dev/sdb1 /data
df -h|grep /dev/sdb1
#开机挂载磁盘
echo "mount -t ext4 /dev/sdb1 /data" >>/etc/rc.d/rc.local
tail -1 /etc/rc.d/rc.local
chmod +x /etc/rc.d/rc.local

##############
#安装配置LVM，作为后端存储使用
yum install -y lvm2
systemctl enable lvm2-lvmetad.service
systemctl start lvm2-lvmetad.service
#创建LVM物理卷pv与卷组vg
pvcreate /dev/sdb2
vgcreate cinder_lvm01 /dev/sdb2
vgdisplay #查看vg

##############
#安装配置NFS服务，作为后端存储使用
yum install nfs-utils rpcbind -y
mkdir -p /data/{cinder_nfs1,cinder_nfs2}
chown cinder:cinder /data/cinder_nfs1
chmod 777 /data/cinder_nfs1
#echo "/data/cinder_nfs1 *(rw,no_root_squash,sync)">/etc/exports
echo "/data/cinder_nfs1 *(rw,root_squash,sync,anonuid=165,anongid=165)">/etc/exports
exportfs -r
systemctl enable rpcbind nfs-server
systemctl restart rpcbind nfs-server
showmount -e localhost

#配置LVM过滤，只接收上面配置的lvm设备/dev/sdb2
#在devices {  }部分添加 filter = [ "a/sdb2/", "r/.*/"]
sed -i '141a filter = [ "a/sdb2/", "r/.*/"]' /etc/lvm/lvm.conf  #在141行后添加

#NFS
echo '192.168.58.24:/data/cinder_nfs1'>/etc/cinder/nfs_shares
chmod 640 /etc/cinder/nfs_shares
chown root:cinder /etc/cinder/nfs_shares
```

### 4.8 一些 shell 脚本中常用的函数

#### tar 进度条

避免 tar 解压文件的时候污染终端，建议使用进度条的方式展示解压过程

```shell
untar() {
  file_size=$(stat -c '%s' $1)
  block_size=$(expr $file_size / 51200); block_size=$(expr $block_size + 1)
  tar_info="Untar $1 progress:"
  tar --blocking-factor=$block_size --checkpoint=1 --checkpoint-action=ttyout="${tar_info} %u%  \r" -xpf $1 -C $2
}
```

#### 正则匹配 IP

```shell
# regular match ip
match_ip() {
    local INPUT_IPS=$*
    local IPS=""
    if ! echo ${INPUT_IPS} | egrep --only-matching -E '([[:digit:]]{1,3}\.){3}[[:digit:]]{1,3}-[[:digit:]]{1,3}' > /dev/null; then
        IPS="$(echo ${INPUT_IPS} | egrep --only-matching -E '([[:digit:]]{1,3}\.){3}[[:digit:]]{1,3}' | tr '\n' ' ')"
    else
        ip_prefix="$(echo ${INPUT_IPS} | egrep --only-matching -E '([[:digit:]]{1,3}\.){3}[[:digit:]]{1,3}-[[:digit:]]{1,3}' | cut -d '.' -f1-3)"
        ip_suffix="$(echo ${INPUT_IPS} | egrep --only-matching -E '([[:digit:]]{1,3}\.){3}[[:digit:]]{1,3}-[[:digit:]]{1,3}' | cut -d '.' -f4 | tr '-' ' ')"
        for suffix in $(seq ${ip_suffix}); do IPS="${IPS} ${ip_prefix}.${suffix}"; done
    fi
    echo ${IPS} | egrep --only-matching -E '([[:digit:]]{1,3}\.){3}[[:digit:]]{1,3}' | tr '\n' ' '
}
```

#### 函数输出帮助信息

```shell
#!/bin/bash
#功能描述(Description):使用函数输出帮助信息.

function print_usage() {
    cat << EOF
Usage: --help | -h
  Print help information for script.
Usage: --memory | -m
  Monitor memory information.
Usage: --network | -n
  Monitor network interface information.
EOF
}

case $1 in
--memory|-m)
    free;;
--network|-n)
    ip -s link;;
--help|-h)
    print_usage;;
*)
    print_usage;;
esac
```

#### 进度条

eg

```shell
#!/bin/bash
#功能描述(Description):为拷贝文件设计一个进度条效果.

#防止提前执行Ctrl+C后无法结束进度条.
trap 'kill $!' INT

#定义函数:实现无限显示不换行的#符号.
bar(){
    while :
    do
        echo -n '#'
        sleep 0.3
    done
}

#调用函数,屏幕显示#进度,直到拷贝结束kill杀死进度函数.
#$!变量保存的是最后一个后台进程的进程号.
bar &
cp -r $1 $2
kill $!
echo "拷贝结束!"
```

eg

```shell
#!/bin/bash
#功能描述(Description):为拷贝文件设计一个进度条效果.

#防止提前执行Ctrl+C后无法结束进度条.
trap 'kill $!' INT

#定义函数:实现无限显示不换行的背景色块.
bar(){
    while :
    do
        echo -ne '\033[42m \033[0m'
        sleep 0.3
    done
}

#调用函数,屏幕显示色块进度,直到拷贝结束kill杀死进度函数.
#$!变量保存的是最后一个后台进程的进程号.
bar &
cp -r $1 $2
kill $!
echo "拷贝结束!"
```

eg

```shell
#!/bin/bash
#功能描述(Description):为拷贝文件设计一个进度条效果.

#防止提前执行Ctrl+C后无法结束进度条.
trap 'kill $!' INT

#定义函数:在宽度为50的范围内输出进度条,#和空格占用48个宽度,竖线占用2个宽度.
#1个#组合47个空格=48,2个#组合46个空格=48,3个#组合45个空格=48,依此类推.
#输出完成后不换号将光标切换至行首,准备下一次进度条的显示.
bar(){
    while :
    do
        pound=""
        for ((i=47;i>=1;i--))
        do
            pound+=#
            printf "|%s%${i}s|\r" "$pound"
            sleep 0.2
        done
    done
}

#调用函数,显示进度符号,直到拷贝结束kill杀死进度函数.
#$!变量保存的是最后一个后台进程的进程号.
bar &
cp -r $1 $2
kill $!
echo "拷贝结束!"
```

eg

```shell
#!/bin/bash
#功能描述(Description):为拷贝文件设计一个进度条效果.

#防止提前执行Ctrl+C后无法结束进度条.
trap 'kill $!' INT

#定义变量,存储指针的四个符号.
rotate='|/-\'

#定义函数:实现动态指针进度条.
bar() {
#回车到下一行打印一个空格,第一次打印指针符号时会把这个空格删除.
#这里的空格主要目的是换行.
    printf ' '
    while :
    do
#删除前一个字符后,仅打印rotate变量中的第一个字符.
#没循环一次就将rotate中四个字符的位置调整一次.
        printf "\b%.1s" "$rotate"
        rotate=${rotate#?}${rotate%???}
        sleep 0.2
    done
}

bar &
cp -r $1 $2
kill $!
echo "拷贝结束!"
```

eg

```shell
#!/bin/bash
#功能描述(Description):为拷贝文件设计一个进度条效果.

#防止提前执行Ctrl+C后无法结束进度条.
trap 'kill $!' INT

#定义变量,存储源与目标的容量大小,目标初始大小为0.
src=$(du -s $1 | cut -f1)
dst=0

#定义函数:实时对比源文件与目标文件的大小,计算拷贝进度.
bar() {
    while :
    do
        size=$(echo "scale=2;$dst/$src*100" | bc)
        echo -en "\r|$size%|"
        [ -f $2 ] && dst=$(du -s $2 | cut -f1)
        [ -d $2 ] && dst=$(du -s $2/$1 | cut -f1)
        sleep 0.3
    done
}

bar $1 $2 &
cp -r $1 $2
kill $!
echo "拷贝结束!"
```

## 5.运维脚本工具库

基于 shell,python,运维脚本工具库,收集和编写各类运维常用工具脚本。

- https://github.com/RecentProgress/devops_scripts
