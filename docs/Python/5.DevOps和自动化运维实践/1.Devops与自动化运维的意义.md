# 1.Devops 与自动化运维的意义

## 1.1 为什么企业需要自动化运维?

总结一下自动化运维可能带来的好处？

- 消除无效率： 运维工作的手动工作，如果可以实现自动化，将显著提升效率水平
- 减少错误：使用自动化运维工具来完成常规操作可以将错误率大大降低
- 最大化员工使用：避免雇佣更多的员工来应对工作量增加的需求，同样一批人有自动化运维，就有更大的能量创造价值。
- 提高满意度水平: 自动化运维工具帮助 IT 运维，可以为内部员工和外部客户提供高水平支持，更好地拥抱 SLA。
- 降低成本：系统中断、人为错误、重复工作，会导致不菲的费用和代价，而自动化运维几乎可以将这些成本完全消除。

> 注意
> 服务品质协议（service-level agreement, SLA)是服务提供者与客户之间的一个正式合同，用于保证可计量的网络性能达到其所定义的品质。

## 1.2 Web 编程相关体系知识点

### 1.2.1 为什么要前后端分离?

对于传统的一体式 Web 架构，大家会发现，业务逻辑处理单独分离出来了，交由后端统一处理，如果从软件开发的层面上来理解，则前端与后端分别处理如下内容。

> 前端：负责 View 和 Controller 层。

> 后端：只负责 Model 层，进行业务处理和数据处理等。

（1）前后职责分离

前端倾向于呈现，着重处理用户体验相关的问题；后端则倾向于处理业务逻辑、数据处理和持久化等相关的问题。在设计清晰的情况下，后端只需要以数据为中心对业务处理算法负责，并按约定为前端提供 API；而前端则使用这些接口对用户体验负责即可。

（2）前后技术分离

前端可以不用了解后端技术，也不必关心后端具体的实现技术，只需要会 HTML、CSS、JavaScript 就能入手；而后端只需要关心后端的开发技术，这样就省去了学习前端技术的麻烦，连 Web 框架的学习研究都只需要关注 Web API 即可，而不用去关注基于页面视图的 MVC 技术（并不是说不需要 MVC 技术，Web API 的数据结构呈现也是 View），不用考虑特别复杂的数据组织和呈现。

（3）前后分离带来了用户体验和业务处理解耦

前端可以根据用户不同时期的体验需求迅速改版，对后端毫无影响。同理，后端进行的业务逻辑升级，数据持久方案变更，只要不影响到接口，前端也可以毫不知情。当然如果是需求变更引起了接口变化，那么前后端又需要在一起进行信息同步了。

（4）前后分离，可以分别归约两端的设计

后端只提供 API 服务，而不必考虑页面呈现的问题。实现 SOA 架构的 API 可以服务于各种前端，而不仅仅是 Web 前端，可以做到一套服务，各端使用。

> 注意
> 自动化运维的开发工作很多都会涉及 API 的封装，所以其更偏后端开发一些。

### 1.2.2 什么是 RESTful?

什么是 REST？

REST（Representational State Transfer）这个概念首次出现是在 2000 年 RoyThomas Fielding（他是 HTTP 规范的主要编写者之一）的博士论文中，它指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful 的。

要理解什么是 REST，我们需要理解如下的几个概念。REST 是"表现层状态转化"，它省略了主语。其实 "表现层" 指的是 "资源" 的 "表现层"。

那么什么是资源（Resources）呢？就是我们平常上网访问的一张图片、一个文档、一个视频等。这些资源我们通过 URI 来定位，也就是一个 URI 表示一个资源。

（1）表现层（Representation）

资源是做一个具体的实体信息，其可以有很多种展现方式。而把实体展现出来就是表现层，例如一个 txt 文本信息，可以输出成 html、json、xml 等格式，一个图片可以通过 jpg、png 等方式展现，这个就是表现层的意思。URI 确定一个资源，但是如何确定它的具体表现形式呢？应该在 HTTP 请求的头信息中用 Accept 和 Content-Type 字段进行指定，这两个字段才是对“表现层”的描述。

（2）状态转化（State Transfer）

访问一个网站，就代表了客户端和服务器的一个互动过程。这个过程肯定会涉及数据和状态的变化。而 HTTP 是无状态的，那么这些状态肯定会保存在服务器端，所以如果客户端想要通知服务器端改变数据和状态的变化，则肯定是需要通过某种方式来通知它。客户端能通知服务器端的手段，只能是 HTTP。

具体来说，就是 HTTP 里面，有几个操作方式的动词。

HTTP 动词具体包括如下几个。

- GET：从服务器端取出资源（一项或多项）。
- POST：在服务器端新建一个资源。
- PUT：在服务器端更新资源（客户端提供改变后的完整资源）。
- PATCH：在服务器端更新资源（客户端提供改变的属性）。
- DELETE：从服务器端删除资源。
- HEAD：获取资源的元数据。
- OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。

RESTful 用一句话可以总结为 URL 定位资源，用 HTTP 动词描述操作。符合 REST 原则的架构方式即称之为 RESTful。

综合上面的解释，我们下面来总结一下什么是 RESTful 架构。

每一个 URI 代表一种资源。

在客户端和服务器之间传递这种资源的某种表现层。

客户端通过 HTTP 动词，对服务器端资源进行操作，实现"表现层状态转化"。

（3）HTTP 状态码对于 HTTP 状态码，大家应该已经很熟了，即服务器向用户返回的状态码和提示信息，常见的 HTTP 状态码如表:

| 状态码 | HTTP 方法                              | 说明                                                                       |
| ------ | -------------------------------------- | -------------------------------------------------------------------------- |
|        |                                        |                                                                            |
|        |                                        |                                                                            |
| 2xx    | 请求成功                               |                                                                            |
| 200    | OK - [GET]                             | 服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。               |
| 201    | CREATED- [POST/PUT/PATCH]              | 用户新建或修改数据成功。                                                   |
| 202    | Accepted - [*]                         | 表示一个请求已经进入后台排队(异步任务)                                     |
| 204    | NO CONTENT - [DELETE]                  | 用户删除数据成功。                                                         |
|        |                                        |                                                                            |
|        |                                        |                                                                            |
| 3xx    | 重定向                                 |                                                                            |
| 301    | NO CONTENT -                           | 永久重定向                                                                 |
| 302    | NO CONTENT -                           | 临时重定向                                                                 |
|        |                                        |                                                                            |
|        |                                        |                                                                            |
| 4xx    | 客户端错误                             |                                                                            |
| 400    | INVALID REQUEST - [POST/PUT/PATCH]     | 用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。 |
| 401    | Unauthorized - [*]                     | 表示用户没有权限（令牌、用户名、密码错误）。                               |
| 403    | Forbidden - [*]                        | 表示用户得到授权（与 401 错误相对），但是访问是被禁止的。                  |
| 404    | NOT FOUND - [*]                        | 用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。   |
| 406    | Not Acceptable - [GET]                 | 用户请求的格式不可得（比如用户请求 JSON 格式，但是只有 XML 格式）。        |
| 410    | Gone -[GET]                            | 用户请求的资源被永久删除，且不会再得到的。                                 |
| 422    | Unprocesable entity - [POST/PUT/PATCH] | 当创建一个对象时，发生一个验证错误。                                       |
|        |                                        |                                                                            |
|        |                                        |                                                                            |
| 5xx    | 客户端错误                             |                                                                            |
| 500    | INTERNAL SERVER ERROR - [*]            | 服务器发生错误，用户将无法判断发出的请求是否成功。                         |
| 501    | Not Implemented                        | 服务器不支持请求的功能，无法完成请求                                       |
| 503    | \*                                     | 服务器接收到无效请求                                                       |

### 1.2.3 Web 后台认证机制

HTTP Basic Auth

简言之， HTTP Basic Auth 简单点说就是每次请求 API 时都提供用户的 username 和 password ，是配合 RESTful API 使用的最简单的认证方式，只需提供用户名和密码即可， 但由于存在将用户名和密码暴露给第三方客户端的风险，因此在生产环境下， HTTP BasicAuth 被使用得越来越少 。 因此，在开发对外开放的 RESTful API 时，应尽量避免采用 HTTP Basic Auth 。

OAuth

OAuth(开放授权）是一个开放的授权标准，允许用户让第 三 方应用访问该用户在某－Web 服务上存储的私密的资源（如照片、视频、联系人列表），而无须将用户名和密码提供给第三方应用。

OAuth 允许用户提供一个令牌，而不是根据用户名和密码来访问他们存放在特定服务提供者处的数据 。 每一个令牌授权一个特定的第 三方系统（例如，视频编辑网站）在特定的时间段（例如，接下来的 2 个小时内 ）内访问特定的资源（例如仅仅是某一相册中的视频） 。 这样， OAuth 就使得用户可以授权第 三方网站访问他们存储在另外服务提供者处的某些特定信息，而非所有内容 。

Cookie Auth

Cookie 认证机制就是为一次请求认证在服务器端创建一个 Session 对象，同时在客户端的浏览器端创建一个 Cookie 对象； 通过客户端发送的 Cookie 对象与服务器端的 Session 对象进行匹配来实现状态管理。 默认情况下，当我们关闭浏览器的时候，Cookie 会被删除，但是可以通过修改 Cookie 的 expire time 使 Cookie 在一定时间内有效。

Token Auth

使用基于 Token 的身份验证方法时，服务器端不需要存储用户的登录记录。大概的流程如下所示 。

1). 客户端使用用户名与密码请求登录。

2). 服务器端收到请求，去验证用户名与密码

3). 验证成功后，服务器端会签发一个 Token，再把这个 Token 发送给客户端。

4). 客户端收到 Token 之后可以把它存储起来， 比如放在 Cookie 里或者 Local Storage 里。

5). 客户端每次向服务器端请求资源的时候都需要带着服务器端签发的 Token 。

6). 服务器端收到请求，然后去验证客户端请求中所携带的 Token ，如果验证成功，就向客户端返回请求的数据 。

Token Auth 的优点

Token 机制相对于 Cookie 机制来说，具有如下好处 。

支持跨域访问： Cookie 是不允许跨域访问的，这一点对 Token 机制来说是不存在的，Token 机制支持跨域访问的前提是用户认证信息通过 HTTP 头传输 。

无状态(也称服务器端可扩展行) : Token 机制在服务器端不需要存储 Session 信息，因为 Token 自身包含了所有登录用户的信息，因此只需要在客户端的 Cookie 或本地介质中存储状态信息即可 。

更适用 CDN ：可以通过内容分发网络请求你服务器端的所有资料（如 JavaScri pt 、HTML 及图片等），而你的服务器端只要提供 API 即可。

去藕 ：不需要绑定到 一个特定 的身份验证方案 。 Token 可以在任何地方生成，当你的 API 被调用的时候， 直接进行 Token 生成调用即可。

更适用于移动应用： 当我们的客户端是一个原生平台(iOS 、 Android 或 Wi ndows 8 等时， Cookie 是不被支持的（需要通过 Cookie 容器进行处理），这时采用 Token 认证机制就会简单得多。

CSRF：因为不再依赖于 Cookie，所以 Token 机制不需要考虑对 CSRF(跨站请求伪造)的防范。

性能： 一次网络往返时间（通过数据库查询 Session 信息）总比做一次 HMACSHA256 计算的 Token 验证和解析要费时得多。

不需要为登录页面做特殊处理： 如果使用的是 Protractor 做功能测试，那么我们 不再需要为登录页面做特殊处理。

基于标准化： 这个标准已经存在多个后端库（如 .NET 、 Ruby 、 Java 、 Python 和 PHP)和多家公司的支持（如 Firebase 、 Google 和 Microsoft） 。

参考文档： http://www.cnblogs.com/xiekeli/p/5607107.html

### 1.2.4 同步和异步、阻塞与非阻塞的区别

#### 同步与异步

所谓的同步，就是在发出一个“调用”时，在没有得到结果之前，该“调用”不返回； 但是一旦调用返回，就会得到返回值了。换句话来说就是“调用者”主动等待这个“调用”的结果。

而异步则正好相反，在发出“调用”之后这个“调用”就直接返回了，所以没有返回结果。

换句话说当一个异步过程发出“调用”之后，“调用者”不会立即得到结果，而是在“调用”发出之后， “被调用者”通过状态、通知来通知调用者，或通过回调函数来处理这个调用。

举例：

> 同步：
>
> 你打电话去报刊亭买报纸，你问报刊亭的老板,有抖音相关的报纸吗？
> 老板就跟你说：我去查阅一下，你在电话这边一直等着。
> 然后老板开始找报纸，找报纸的过程可能是 1 个小时，也可能是 1 天，期间你一直等待着。老板找到后告诉你找到了，让你过来买。

> 异步：
>
> 你去报刊亭买报纸，你问报刊亭的老板,有抖音相关的报纸吗？
> 老板就跟你说：你回去等我电话，我找到了就打你电话，就挂了电话，给了你一个通知，
> 老板找到后主动给你打电话，让你带钱过来拿报纸。

#### 阻塞与非阻塞

阻塞与非阻塞关注的是程序在等待调用结果（消息、返回值）时的状态。

阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才返回。

非阻塞调用是指在不能立刻得到结果之前，该调用不会阻塞当前线程。

还是上面的例子：

> 阻塞： 当你打电话到报刊亭问有没有抖音相关的报纸的时候，你会一直把自己"挂起"，知道得到有没有这本书的结果。

> 非阻塞： 你不用考虑老板有没有找到报纸，你自己先去做别的事，当然偶尔过几分钟也会来检查老板有没有返回结果，这里的阻塞与非阻塞与是否同步异步无关，也与老板回答你结果的方式无关。期间你是可以处理其他事情的。

## 1.3 从事 Devops 应该掌握的语言

- shell

- Python

- Go

#### 比较 Python 与 Go

比较 Python 与 Go，看看 Go 语言的优势在哪里：

1）部署简单：Go 语言编译生成一个静态可执行文件，除了 glibc 之外再没有其他的外部依赖，这也是部署变得异常方便：目标机器上只需要一个基础的系统和必要的管理、监控工具，完全不用操心应用所需的各种包、库的依赖关系，大大减轻了维护的负担。

2）并发性好，天生支持高并发：Goroutine 和 Channel 使得编写高并发的服务端软件变得相当容易，很多情况下完全不需要考虑锁机制以及由此带来的各种问题。

单个 Go 应用也能有效地利用多个 CPU 核，其并行执行能力很好。是 Python 不能相比的，多线程和多进程的服务编写起来并不简单，而且由于 Python 全局锁 GIL 的原因，多线程并不能有效利用多核，只能用多进程的方式进行部署，在很多场景下这并不能有效的利用计算机资源，这也是饱受 Python 爱好者诟病的地方。

3）良好的语言设计：有其他语言基础能迅速上手，有大量标准库和三方库。Go 自带完善的工具链。

4)执行性能好: Go 语言虽然不如 C 和 Java，但是比原生 Pyhton 应用还是高一个数量级的，适合编写一些瓶颈业务，内存占用也非常低。

#### Go 语言的应用场景

Go 语言的应用场景:

1.服务器编程，如果之前使用 C 或者 C++进行服务器编程，那么使用 Go 来做也很合适。例如日志处理系统、数据打包、虚拟机处理、文件系统等

2.分布式存储、数据库代理器等

3.Key-Value 存储，例如工作中常见的 etcd

4.网络编程，目前这一块应用最广，包括 Web 应用、API 应用、下载应用等

5.内存数据库、前一段时间 google 开发 groupcache 等。

6.游戏服务端的开发。

7.云平台，目前国内很多云平台都使用 Go 开发，例如国外的 CloudFoundy、Apcera 云平台和国内的青云、七牛云等。

平常的 Devops 中，除了使用 Python 之外，还可以使用 Go 语言来编写某些项目需求，或自动化运维的 API。

## 1.4 从事 DevOps 工作应该掌握的工具

#### 版本控制管理(SCM)

Github、GitLab、SubVersion，考虑到汉化和网络方面的原因，国内企业在 Github 和 GitLab 之间进行选择的时候，一般是选择 GitLab

#### 构建工具

Ant、Gradle、Maven。Maven 除了以程序构建能力为特色之外，还提供了高级项目管理工具。

#### 持续集成

Jenkins，大名鼎鼎的软件，基本上是 CI 的代名词。Jenkins 是全球最留下的持续集成工具，国内某社区曾经调研 Jenkins 在国内的使用率为 70%左右。

#### 配置管理

Ansible、Chef、Puppet、SaltStack，这些都是自动化运维工作中常见的工具。

#### 虚拟化

Xen 或 KVM、Vagrant

#### 容器

Docker 、LXC 、第三方厂商如 AWS ,这里需要注意 Docker 与 Vagrant 的区别。

#### 服务注册与发现

zookeeper 、etcd 。

#### 日志管理

大家都很熟悉的 ELK。

#### 日志收集系统

Fluentd 、Hekao。

#### 压力测试

JMeter 、Blaze Meter 、loader.io。

#### 消息中间件

ActiveMQ 、RabbitMQ 。

事实上，很多 DevOps 工具在这里尚未罗列出来,在工具的选择上，需要结合公司业务需求和技术团队情况而定，毕竟适合自己的才是最好的。

## 1.5 了解网站系统架构设计和高并发场景

_网站性能评估指标_

网站设计得好还是不好,我们可以参考吞吐量、每秒查询率（ QPS) 、响应时间(Response Time) 、并发用户数， PV 等作为辅助指标， 但它们并不能真实地反映网站的性能。

- **QPS:** 每秒响应请求数。
- **吞吐量：** 单位时间内处理的请求数量， 在互联网领域， 这个指标与 QPS 的区分并没有那么明显。
- **响应时间：** 系统对请求做出的响应时间， 例如系统处理一个 HTTP 请求需要 200ms ，那么这里的 200ms 就是系统的响应时间。
- **并发用户数：** 同时承载正常使用系统功能的用户数量。

## 1.6 细分五层解说网站架构

### 1.6.1 网页缓存层

专业的 CDN 租赁比自行部署 Squid、Varnish 更好，更专业。很多朋友喜欢尝试自建 CDN，这是一个比较吃力不讨好的活。这一层有很多优秀的开源软件能胜任这个工作，比如传统的 Squid，后起之秀 Nginx、Varnish 因为性能优异，越来越多开发者尝试在自己网站使用 Nginx 和 Varnish，作为自己的网页缓存。事实上，Nginx 已经具备 Squid 所拥有的 Web 缓存加速功能。

此外 Nginx 对多核 CPU 的利用也胜过了 Squid，现在越来越多的架构师都喜欢将 Nginx 同时作为 "负载均衡器" 与 Web 缓存服务器来使用，可以根据自己网站的情况，决定究竟使用哪种软件来对自己的网站提供反向代理加速服务。

网站系统架构设计图：

![](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.86te8wygli.webp){: .zoom}

### 1.6.2 负载均衡层

我们熟悉的开源软件包括：LVS、HAProxy、Nginx，它们的性能全部都非常优异。

建议将负载均衡分成两级来处理， 一级是流量四层分发， 二级是应用层面七层转发（ 即业务层面） 。

首先我们可以通过或 HAProxy 将流量转发给二层负载均衡(一般为 Nginx), 即实现了流量的负载均衡， 此处可以使用如轮询、权重等调度算法来实现负载的转发；

然后二层负载均衡会根据请求特征再将请求分发出去。此处为什么要将负载均衡分为两层呢？

1. 第一层负载均衡应该是无状态的， 方便水平扩容。我们可以在这一层实现流量分组(内网和外网隔离、爬虫和非爬虫流量隔离) 、内容缓存、请求头过滤、故障切换(机房故障切换到其他机房)、限流、防火墙等一些通用型功能， 无状态设计， 可以水平扩容。

2. 二层 Nginx 负载均衡可以实现业务逻辑， 或者反向代理到如 Tomcat ， 这一层的 Nginx 与业务相关联， 可以实现业务的一些通用逻辑。如果可能的话， 这一层也应尽量设计成无状态， 以方便水平扩容。

### 1.6.3 Web 服务层

web 服务器层压力比较大， 大的网站现在都选择将 Nginx 作为 web 主要应用服务器，事实上， Nginx 在抗并发能力和稳定性方面确实超过了预期。另外， 集群还有一个优势， 那就是它的高扩展性， 特别是水平（ 横向） 扩展。就算网站的并发连接数有 1 0 万以上，也无非是多加 web 机器（ 廉价的 PC server 也是可行的） ， 或者通过 Nginx+lua 这种高性能的 web 应用服务器来承担压力。

在进行实际的线上维护时我们发现在高峰期间， 实际上每台 web 的并发并不算特别大， 所以网站的压力在这一层也能通过技术手段加以克服。

### 1.6.4 文件服务器层

1. 单 NFS 作为文件服务器，存在单点故障，NFS 机器出现故障时需要人为手动干预

2. NFS 分组，虽然这样可以分担压力，但是也会存在单点故障，NFS 机器出现故障时需要人为手动干

3. DRBD+Heartbeat+NFS 高可用文件服务器，维护方便，不存在单点故障问题，但是随着访问量的增大，后期一样会存在压力过大的情况
4. 采用分布式文件系统: 例如 MooseFS、MooseFS 易用、稳定，对于海量肖文杰的处理很高效，而且新版 MooseFS 解决了 Master Server 存在单点故障的问题，稳定和社区也非常成熟，国内越来越多的公司也在使用 MFS。

### 1.6.5 数据库层

数据库的压力，网站的 PV、UV、QPS 和并发连接数增加以后，数据库这块的压力就是最大的，归根结底还是磁盘的 I/O 压力大。

Oracle RAC 是很成熟的分布式方案，但是价格非常昂贵。

MySQL 面对这种数据库磁盘 I/O 压力很大的情况下，如何处理呢？

首先应在业务逻辑上将数据分离。很多读写频繁的业务数据，比如 ip list 和频繁读取的配置等信息都没有必要使用 MySQL 数据库来保存，我们完全可以利用 redis 分布式缓存来保存这些数据，这样读取速度也能得到保证，后端 MySQL 数据库的压力也可以得到缓解。

电子商务网站一般的场景包括签到、商品的订单系统等，这些在技术层面很容易实现；

另外还有一种常见的场景一秒抢红包，像这种用户在瞬间涌入产生高并发请求的场景，这个时候我们需要引入消息中间件，例如 RabbitMQ ,此时 RabbitMQ 机器数量将视实际的应用而定。

场景中的红包定时领取是一个高并发的业务，活动用户会在到点的时间大量涌入，DB(即后端的 MySQL 层，这次简写为 DB)瞬间就会受到一记暴击，支撑不住就会宕机，然后影响整个业务。

像这种不是只有查询的操作，并且会有高并发的插入或者更新数据的业务，前面提到的通用方案就会无法支撑，并发的时候都是直接击中 DB;设计这块业务的时候需要使用消息队列，可以将参与用户的信息添加到消息队列中，然后再编写一个多线程程序去消耗队列，为队列中的用户发放红包。具体流程可以参考图 1-15。

Redis+RabbitmQ+Mysql 方案较为常见

具体流程可以参考图 1-15。

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.231m6m3318.webp){: .zoom}

图 1-15 所示的方案具体如下所示：

一般习惯于使用 redis 的 List (列表)类型 → 当用户参与活动时，将用户参与信息 push 到队列中 → 然后写个多线程程序去 pop 数据，进行发放红包的业务 → 这样就可以支持高并发下的用户正常地参与活动，并且避免数据库服务器发生宕机的危险。

下面我们再来讲解一下 MySQL 数据库的优化。

数据库服务器的硬件方面可以考虑投入磁盘阵列做成 RAD10 , 如果资金充裕，可以用 SSD(固定硬盘) 来代替 SAS 硬盘。

必须合理地设计 MySQL 数据库的架构，事实上，在生产环境下，一主多从、读写分离是比较靠谱的设计方案，对于 MySQL 的负载均衡，这里推荐大家使用 LVS/DR,这是因为当从机 MySQL 节点机器超过十台时，HAProxy 的性能便会不如 LVS/DR。

如果网站的业务量过大，还可以采用分库的方法，比如将网站的业务量分成 Web、Blog、Mall 等几组，每一组均采用主从架构，这样设计的话就避免了单组数据库压力过大的情况。

最后，还应该配合公司的 MySQL DBA,在数据库参数优化、SQL 语句优化、数据切分上多下功夫，避免让 MySQL 数据库成为网站的瓶颈。

必要的时候，还要考虑分布式 SQL 解决方案，例如 Redshift 及 Hbase 等。

希望大家能够根据上文对网站进行的五层分解，结合自己网站的情况，了解每一层在网站设计中的作用和重要性，找出网站瓶颈并加以优化，将自己的网站打造成高可用、高可扩展性的网站。

此外，如果我们在业务中遇到了秒杀这种极端场景，那么我们应该如何进行处理呢？

比如说京东秒杀，就是一种定时定量秒杀，在规定的时间内，无论商品是否秒杀完毕，该场次的秒杀活动都会结束。

这种秒杀，对时间的要求不是特别严格，只要下手快点，秒中的概率还是比较大的。

**(1)业务特点** 1)瞬时并发量大：秒杀时会有大量的用户在同一时间进行抢购，瞬时并发访问量突增 10 倍，甚至 100 倍以上都有。

2)库存量少：秒杀活动商品量一般很少，这就导致了只有极少量的用户才能够成功购买。

3)业务简单：流程比较简单，一般都是下订单、扣库存、支付订单

**(2)技术难点**

1)现有业务的冲击：秒杀是营销活动中的一种，如果将其与其他营销活动应用部署在同一服务器上，那么秒杀肯定会对现有的其他活动造成冲击，极端情况下，可能会导致整个电商系统服务宕机。

2)直接下订单：下单页面是一个正常的 URL 地址，需要控制在秒杀开始前，不能下订单，只能浏览对应活动商品的信息。简单来说，需要让订单按钮失效。

3)页面流量突增：秒杀活动开始前后，会有很多用户请求对应商品的页面，这会造成后台服务器流量的突增，同时增加对应的网络带宽，需要控制商品页面的流量不会对后台服务器、DB、redis 等组件造成过大的压力。

**(3)架构设计思想**

关于架构设计思想，大家可以参考图 1-16，具体如下所示。

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.86tea799cr.webp){: .zoom}

- 限流
  由于活动的库存量一般都很少，对应的只有少部分用户才能秒杀成功。所以我们需要 限制大部分用户流量，只准许少量用户流量进入后端服务器。

- 削峰
  秒杀活动开始的那一瞬间，会有大量用户冲击进来，所以在开始的时候会有一个瞬间 流量峰值。如何把瞬间的流量峰值变得更加平缓，是能否成功设计好秒杀系统的关键因素。
  实现流量削峰填谷，一般是采用缓存和 MQ 中间件来解决。

- 异步
  秒杀其实可以当作高并发系统来处理，这个时候，可以考虑从业务上做兼容，将同步 的业务设计成异步处理的任务，以提高网站的整体可用性。

- 缓存
  秒杀系统的瓶颈主要体现在下订单、扣减库存流程中。这些流程主要会用到 OLTP 的数据库，类似于 MySQL、Oracle。由于数据库底层采用 B+ 树的储存结构，对应地我们随
  机写入与读取的效率也会相对较低。如果我们把这部分业务逻辑迁移到 redis 中，则会极大地提高并发效率。

**(4)整体架构**

如图 1-17 所示的是秒杀活动的整体架构。

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.7awwur809a.webp){: .zoom}

**(5)客户端优化**

客户端优化主要包括如下两个问题。

1.秒杀页面

秒杀活动开始前，其实就已经有很多用户访问该页面了。
如果这个页面的一些资源， 比如 CSS、JS、图片、商品详情等，都访问后端服务器甚至 DB 的话，服务肯定会出现不 可用的情况。
所以我们一般会对该页面进行整体静态化，并将静态化之后的页面分发到 CDN 边缘节点上，以起到压力分散的作用。

2.防止提前下单

防止提前下单主要是在静态化页面中加入一个 JS 文件引用，该 JS 文件包含活动是否开始的标记以及开始时动态下单页面的 URL 参数。

同时，CDN 系统是不会缓存这个 JS 文件的，CDIV 系统会一直请求后端服务，所以该 JS 文件一定要很小。

当活动快开始的时候(比如提前 0.5 小时~2 小时)，需要通过后台接口修改该 JS 文件使之生效。

**(6)API 接入层优化**

客户端优化，对于不是从事计算机行业的用户还是可以防止得住的，但是对于稍有一 定网络基础的用户就起不到作用了，因此服务器端也需要加入一些对应的控制，不能信任 01111111 客户端的任何操作。

控制一般分为如下两类。

- 限制用户维度的访问频率
  针对同一个用户(Userid 维度)，做页面级别缓存，单元时间内的请求，统一进行缓存，然后返回同一个页面。其实就这一个工作而言，如果需要深化的话，还有很多工作需要做。

- 限制商品维度的访问频率

大量请求在同一个时间段查询同一个商品时，可以做页面级别缓存，不管接下来是谁 来访问，只要是访问这个页面就直接返回。

**(7)SOA 服务层优化**

上面两层只能限制异常用户的访问，如果秒杀活动运营得比较好，很多用户都参加了， 就会造成系统压力过大甚至宕机，因此需要在后端也进行流量控制。

对于后端系统的控制，可以通过消息队列、异步处理、提高并发等方式来解决。对于超过系统水位线的请求，直接采取 "Fail-Fast(快速失败)" 原则，拒绝即可。

**(8)秒杀整体流程图**

秒杀整体流程图如图 1-18 所示。

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.8ad07xm03c.webp){: .zoom}
秒杀整体流程图

秒杀系统的核心在于层层过滤，逐渐递减瞬时访问压力，减少对数据库的最终冲击。

通过如图 1-18 所示的流程图，我们看一下压力最大的地方在哪里？

答案是 MQ 排队服务，只要 MQ 排队服务能顶住压力，后面下订单与扣减库存的压力就都可以控制得住，
根据数据库的压力，可以定制化创建订单消费者的数量，避免出现消费者数据量过多，导致数据库压力过大或者直接宕机的问题。

库存服务专门为秒杀的商品提供库存管理，实现提前锁定库存，避免出现超卖的问题。

同时，通过超时处理任务发现已抢到商品但未付款的订单，并在规定的付款时间之后处理这些订单，同时恢复订单商品对应的库存量。

这里先总结下秒杀系统的核心思想，具体如下。

核心思想：层层过滤。

- 尽量将请求拦截在上游，以降低下游的压力。
- 充分利用缓存与消息队列，提高请求处理的速度及削峰填谷的作用。

http://blog.51cto.com/13527416/2085258

http://blog.csdn.net/fayeyiwang/article/details/51234457

https://blog.thankbabe.com/posts/2016-09-14-high-concurrency-scheme/

### 1.6.6 了解数据库集群主从复制的基本原理

数据库层面上，我们一般使用 redis+MySQL 比较多，主从复制在项目或网站设计中 都是比较成熟的方案，所以了解其基本原理还是很有必要的。

#### 1.redis 的常⽤数据结构及应⽤场景

我们介绍 Redis 5 种常⽤的数据结构（string、hash、list、set、 sorted set），以及这些数据结构所适⽤的业务场景。

##### string-存储简单的数据

1. 简介

string 类型是 Redis 中最基本的数据类型，其在 Redis 中是⼆进制安全，意味着这种数据类型可以接受任何格式的⼆进制数据，例如⼀张 JPEG 格式的图⽚或者 JSON 格式的字符串。

在 Redis 中字符串类型最多 可以容纳的数据⻓度是 512MB。

2. 数据模型

string 类型是基本的 Key-Value 结构，Key 可以看作某个数据在 Redis 中的唯⼀标识，Value 是具体的数据。

下表展⽰了基本 Key-Value 数据模型：

| Key    | Value       |
| ------ | ----------- |
| "name" | "jeff"      |
| "city" | "guangzhou" |

在上表中，Key 为 “name”，对应 Value 为 “jeff”；Key 为 “city”，对应 Value 为 “Guagnzhou”。

3. 应⽤场景

由于 string 类型灵活，可以存储⼤量的数据，所以在 App 后台中， string 类型经常会⽤来缓存数据。

例如 App 中常⻅的商品分类栏，这类界⾯的特点是：访问频率⾼，数据不经常变动（可能⼏天）。

所以为了提⾼这个界⾯的访问速度，把这个界⾯的数据放在 Redis 的⼀个 Key-Value 结构中，⼀般情况下 App 后台就从这个 Key 读取数据；当这个界⾯的数据发⽣变化时，⽤新的数据覆盖这个 Key 的数据。

假设这个界⾯的数据对应的 Key 是“category”，Value 为这个界⾯的 JSON 数据，则 Redis 中对应的模型如表

| Key        | Value                                       |
| ---------- | ------------------------------------------- |
| “category” | {"常⽤分类":......，"潮流⼥装":......，...} |

当 App 端需要通过 API 获取这个界⾯的 JSON 数据时，API 请求到达 App 后台通过 Redis 获取 Key“category”对应的值，命令如下。

```shell
get category
```

⼀般来说，App 端为了在⽹络不可⽤的时候也有良好的⽤⼾体 验，会在 App 本地也缓存⼀份数据，整个流程如下图：

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.6bgthm7sdh.webp){: .zoom}
App 显⽰分类栏⽬流程图

##### hash-存储对象的数据

1. 简介

hash 类型很接近数据库模型，hash 的 Key 是个唯⼀值，Value 部分是个 hashmap 的结构。

2. 数据模型

在数据库中有这样⼀⾏⽤⼾数据，如表

| id  | name | city      |
| --- | ---- | --------- |
| 5   | jeff | guabfzhou |

如果要在 Redis 中⽤ hash 结构存储，则数据模型如图:
![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.45hevumj2u.webp){: .zoom}

在这个 hash 数据模型中，Key 是⽤⼾ id 为 5，Value 是个 hashmap， hashmap 的 field（在 Redis 称内部 hashmap 的 Key 为 field）为上表中的属
性名（name，city）,hashmap 的 Value 为啥办法表中的属性值（jeff 和 guangzhou）。

后台对 hash 数据的保存和存储，可以通过 Key （⽤⼾ id）+field（属性名）来操作。

通过 string 这种数据类型，也能实现存储 hash 数据，但是存在如下问题：

第⼀种⽤ string 表⽰的数据模型如图：
![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.5c0q4gi3wf.webp){: .zoom}

第⼀种⽅式，Key 是⽤⼾的 id 为 5，Value 是⼀个 JSON 格式的字符 串，这种⽅式的缺点是存储或获取 Value 时，把对象变为 JSON 格式或
者把 JSON 格式变为对象需要额外的性能开销。

另外如果开发者只需要 修改 Value 中的 name 值，在这种格式中，开发⼈员必须要先获得 city 值，才能把其转化为符合 Value 格式的 JSON 值，增加了没必要的性能
开销和复杂性。

第⼆种⽤ string 表⽰的数据模型如图
![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.6f0ffcfpih.webp){: .zoom}

第⼆种⽅式，有多少组⽤⼾属性就⽤多少个 Key-Value 对象，⽤⼾ id“5”加上对应的属性名来作为 Key，属性值作为 Value。

这种⽅式存取 或获取数据，虽然免去了如第⼀种⽅式 JSON/反 JSON 的开销，但是在 内存⽅⾯的开销还是⽐ hash 的⼤（在下⾯内存优化的章节会描述，通
过在 Redis 配置⽂件中优化 “hash-max-zipmap-entries” 和 “hash-max-zipmap-value”这两个参数可以让 hash 更省内存）。

3. 应⽤场景

App 后台常⻅的功能是根据⽤⼾的 id 获取⽤⼾的信息。例如，根据 ⽤⼾的 id 获取⽤⼾的昵称、头像、所在地等信息。

⼀般⽤⼾的信息是 存储在数据库中，对于这种⾼频的数据访问，不可能每次获取这些信息都读取数据库，⾃然⽽然开发⼈员会考虑到把⽤⼾的信息存储在
Redis 的 hash 中，如图:

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.7p1f6n2tu.webp){: .zoom}

⽤⼾信息的 hash 数据

获得⽤⼾ id 后需要获取⽤⼾的数据，⽤ hgetall 命令获取 id 下所有的 field 和 value，命令如下：

```shell
hgetall id
```

> 注意： 如果修改了数据库的⽤⼾数据，也要把这些数据同步更新到 Redis，⽤来防⽌ Redis 和数据库的数据不⼀致。

##### list-模拟队列操作

1. 简介

Redis 中 list 是按照插⼊顺序排序的字符串链表，可以在头部和尾部插⼊新的元素（即队列结构）。
插⼊元素时如果该 Key 不存在，Redis 会为该 Key 创建⼀个新的链表，如果链表中所有的元素都被移除，该 Key 也会从 Redis 中移除。

> 注意： 由于 list 在 Redis 中是链表结构，如果在头部或尾部插⼊新的元素，即使链表中存储了上百万的数据，性能也⾮常⾼效。
> 如果在 链表中插⼊元素，由于需要根据头部或尾部的指针遍历到链表指定的位置，Redis 的插⼊效率很低。

2. 数据模型

list 的数据模型如图:

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.8hg83elmvm.webp){: .zoom}
链表的数据模型

常⻅的操作是⽤ lpush 命令在 list 头部插⼊元素，⽤ rpop 命令在 list 尾取出数据。

3. 应⽤场景

在 App 后台中，Redis 也经常被⽤来作为消息队列，理由如下。

- 因为 App 后台中已经使⽤了 Redis，消息队列也使⽤ Redis 可以减少开发⼈员的维护成本和学习新知识的成本。
- Redis 的读写速度能达到每秒上万次，能满⾜⼤多数系统的性能要求。

App 后台常⻅的发送短信功能就需要⽤到队列，因为发送短信的速度慢，所以需要⽤到队列来实现异步操作，整个架构如图：
![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.9kfxeakzvp.webp){: .zoom}
发送短信的架构图

发送短信的过程如下。

1. 应⽤程序把短信相关的信息（包括⼿机号、内容）转换为 JSON 字符串后放⼊“发送短信消息队列”。
2. 发送短信的守护进程是个在后台不断运⾏的程序，其不断地检测“发送短信消息队列”是否为空，如果不为空，就把信息从消息队列中取出。
3. 发送短信的守护进程把短信的内容发送短信平台的接⼝。

##### set-⽆序集合

1. 简介

在 Redis 中 set 类型可以看作是没有排序、不重复的元素集合，可以在该类型上添加、删除元素或者判断某⼀元素存在等操作（这些操作的时间复杂度是 O(1)）。

set 集合中不允许出现重复的元素，换句话说，如果多次添加相同 的元素，set 中只保留⼀份。

当⽤⼾需要存储很多的数据，但⼜希望不 出现重复的数据，这个特性就⾮常有⽤。

另外 set 类型还提供多个 set 之间的聚合计算，如求 set 之间的交集、 差集或并集，这些操作是在 Redis 内部完成，效率特别⾼。

2. 数据模型
   set 类型的数据模型如图
   ![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.es9ap2u69.webp){: .zoom}
   set 的数据模型

set 类型的 Value 部分是⼀系列不重复的数据集合。

3. 应⽤场景

社交类型的 App 中，有的 App 当⽤⼾进⼊了⼀个⽤⼾的主⻚后会提⽰共同好友的信息，以⽅便⽤⼾扩展社交关系。提⽰共同好友的⻚⾯。

获取共同好友的算法如下：

把⽤⼾ a 的所有好友取出来遍历，和⽤ ⼾ b 的所有好友⼀⼀⽐较，如果相同的话就是共同好友。

上⾯描述的算法其实就是求两个集合交集。在 Redis 的 set 类型的操 作中已经包含了求交集的操作 sinter。
如果把⽤⼾ a 的好友存储在集合 a 中，把⽤⼾ b 的好友存储在集合 b 中，通过求集合 a 和集合 b 的交集，就 能获取⽤⼾ a 和⽤⼾ b 的共同好友。

##### sorted set-有序集合

1. 简介

sorted-set 类型与 set 类型⾮常相似，不允许出现重复的元素。

其主要区别是 sorted-set 中提供了⼀个分数（score）与每⼀个成员对应， Redis 根据 score 对成员进⾏排序，⽽且插⼊是有序的，即插⼊后就⾃动排序。
当 App 后台开发者需要有序且不重复的数据，选择 sorted-set 这 种数据结构就⾮常合适。

需要特别注意：sorted-set 中的成员是不允许重复，但 score 是允许重复的。

2. 数据模型

sorted-set 的数据模型如图

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.5tqrt4nlp1.webp){: .zoom}

3. 应⽤场景

sorted-set 类型适⽤于各种类型的排⾏榜。

##### redis 实现异步队列

在 Python 中实现异步队列通常需要使用内置的 Queue 模块，除此以外，还可以使用 Redis 来实现异步的队列，

Redis 实现异步队列的方式有两种，一种是`消费者-生产者模式`，另一种是`订阅者-发布者模式`。

1.消费者-生产者模式

消费者-生产者模式是指消费者与生产者共用一个队列，生产者负责将“产品”存放到队列中，消费者负责取出队列中的“产品”。

当队列存满时，生产者需要等待消费者“消费”后，才能继续“生产”。当队列为空时，消费者需要等待生产者“生产”后才能继续“消费”。
消费者-生产者的示意图如图:

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.39kxgfarfy.webp){: .zoom}

Redis 中通过 `lpush()`方法向队列中添加数据，相当于生产者；`lpop()`方法从队列中取数据，相当于消费者。

创建一个 `produce.py` 文件用来存放生产者，具体代码如下：

```python
import time
import redis

# 通过连接池管理连接
pool = redis.ConnectionPool(host='localhost', port=6379, db=1, decode_responses=True)
r = redis.Redis(connection_pool=pool)


# 生产者
def product(i):
    # 获取队列的长度（"queue"是队列名，可自由指定)
    length = r.llen("queue")
    print(length)
    # 队列从零开始，长度为3
    if length > 2:
        print("队列已满，休息一会")
        time.sleep(5)
        # 重新调用生产者方法
        product(i)
    elif length >= 0:
        # 生产者（向队列中添加信息）
        r.lpush("queue", "queue" + str(i))
        print("向队列中添加一个值")
        time.sleep(2)


# 程序主入口
if __name__ == 'main':
    for i in range(5):
        product(i)
```

创建一个 `consumer.py`文件，用来存放消费者，具体代码如下：

```python
import time
import redis
import threading

# 通过连接池管理连接
pool = redis.ConnectionPool(host='localhost', port=6379, db=1, decode_responses=True)
r = redis.Redis(connection_pool=pool)


# 消费者
def consumer():
    length = r.llen("queue")
    while length > 0:
        # 消费者（从队列中取出信息）
        data = r.lpop("queue")
        time.sleep(2)
        print(data)
        if data == None:
            print("队列无值，稍等一会")
            time.sleep(5)
            # 重新调用消费者方法
            consumer()
        length = r.llen("queue")
    else:
        print('消费者END')


# 程序主入口
if __name__ == '__main__':
    threading.Thread(target=consumer, args=()).start()
```

2.发布者-订阅者模式

发布者-订阅者模式是指所有的订阅者都监听着通道，每当发布者将信息发布到通道后，订阅者从通道中获取发布的信息，发布者-订阅者的示意图如图

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.67x7jyr7ya.webp){: .zoom}
发布者-订阅者模型

Redis 中通过`publish()`方法向通道中添加数据，相当于发布者；`subscribe()`方法用于订阅消息，相当于订阅者。

创建一个 `publisher.py` 文件用来存放发布者，具体代码如下：

```python
import redis
import time

pool = redis.ConnectionPool(host='localhost', port=6379, db=2, decode_responses=True)
r = redis.Redis(connection_pool=pool)


# 发布者
def publisher(port_list, signal):
    for i in range(len(port_list)):
        message = str(port_list[i]) + str(signal[i])
        # 向通道发布信息
        r.publish("queue", message)  # 发布消息到liao
        print('发布信息：{}'.format(message))
        time.sleep(1)


# 程序主入口
if __name__ == '__main__':
    port_list = ['1008611', '1008612', '1008613', '1008614']
    signal = ['1', '0', '1', '0']
    publisher(port_list, signal)

```

创建一个`subscriber.py`文件，用来存放订阅者，具体代码如下：

```python
import redis
import threading

pool = redis.ConnectionPool(host='localhost', port=6379, db=2, decode_responses=True)
r = redis.Redis(connection_pool=pool)


# 订阅者
def subscriber(i):
    # 创建订阅者
    sub = r.pubsub()
    # 订阅消息
    sub.subscribe('queue')
    # 监听通道：发布消息就获取
    for item in sub.listen():
        if item['type'] == 'message':
            # 输出通道名
            print('<订阅者{}>信息通道：{}'.format(i, item['channel']))
            # 输出信息
            print('<订阅者{}>信息内容：{}'.format(i, item['data']))


# 程序主入口
if __name__ == '__main__':
    for i in range(1, 3):
        threading.Thread(target=subscriber, args=(i,)).start()
```

先运行 `subscriber.py` 文件进行通道监听，再运行 `publisher.py` 文件。

##### redis 实现分布式锁

```python
import redis
import time


class RedisDistributedLock:
    """
    定义了一个 RedisDistributedLock 类，它封装了获取锁和释放锁的操作
    """
    def __init__(self, redis_conn, lock_key, expire_time=10):
        self.redis_conn = redis_conn
        self.lock_key = f"lock:{lock_key}"
        self.expire_time = expire_time
        self.identifier = None

    def acquire_lock(self):
        """
        在 acquire_lock 方法中，我们通过不断尝试设置指定的键值对来获取锁，直到成功为止。
        """
        while True:
            self.identifier = str(time.time())
            if self.redis_conn.set(self.lock_key, self.identifier, nx=True, ex=self.expire_time):
                return True
            time.sleep(0.1)

    def release_lock(self):
        """
        在 release_lock 方法中，我们首先检查当前持有锁的标识符是否与自己相符，如果是则删除该键，释放锁。
        """
        if self.redis_conn.get(self.lock_key) == self.identifier:
            self.redis_conn.delete(self.lock_key)


# 使用示例
redis_conn = redis.Redis(host='localhost', port=6379, db=0)
lock = RedisDistributedLock(redis_conn, 'my_lock', expire_time=10)

try:
    if lock.acquire_lock():
        print("Successfully acquired lock")
        # 在获得锁之后执行需要同步的代码
        print("Code that needs to be synchronized")
        time.sleep(5)
    else:
        print("Failed to acquire lock")

except Exception as e:
    print(f"An error occurred: {str(e)}")

finally:
    lock.release_lock()
```

参考文献

- http://www.yuan316.com/post/redis/

#### 2.redis 持久化

Redis 常⽤的持久化机制有下⾯两种。

- RDB
- AOF

##### RDB

RDB 是 Redis 默认的持久化⽅式，这种⽅式是按照⼀定的时间周期策略把内存的数据以快照的形式写⼊到硬盘的⼆进制⽂件。

RDB 默认的数据⽂件是`dump.rdb`，该数据⽂件能在配置⽂件中修改。

```shell
dbfilename dump.rdb #快照的⽂件名
dir /var/lib/redis/6379 #快照保存的路径
save 900 1 #当有1 个数据被改变时，900 秒刷新到硬盘⼀次
save 300 10 #当有10 个数据被改变时，300 秒刷新到硬盘⼀次
save 60 10000 #当有10000 数据被改变时，60 秒刷新到硬盘⼀次
```

RDB 持久化的过程如下。

1. 根据配置⽂件中执⾏ RDB 的时机，Redis 调⽤ fork ⽣成⼦进程，这样就有了 Redis 的⼦进程和⽗进程。
2. ⽗进程继续处理客⼾端发送的请求，⼦进程把其内存的数据写⼊到临时⽂件。由于 Linux 操作系统的特性，⽗进程和⼦进程会共享相同的内存空间，所以⼦进程的数据是和 fork 时 Redis 中内存的数据⼀样
   的。
3. ⼦进程写⼊临时⽂件完毕后，⽤临时⽂件替换 RDB 的数据⽂件，⼦进程退出。

需要注意的是，每次持久化的过程都是把 Redis 内存数据完整地写⼊到磁盘，并不是只写⼊修改的数 据，因此，如果 Redis 内存数据量⼤，那么就会造成频繁的写⼊操作，可能会严重影响性能。

由于 RDB 的⽅式是每隔⼀段时间才把内存数据持久化，如果 Redis 意外退出会丢失最后⼀次持久化后 的所有数据。为了防⽌这个问题，可以采⽤下⾯介绍的另外⼀种持久化⽅式—AOF。

##### AOF

使⽤ AOF 的持久化⽅式，Redis 会把每个写⼊命令通过 write 函数追加到持久化⽂件中（默认⽂件是 Appendonly.aof），当 Redis 重启的时候会通过执⾏持久化⽂件的写命令重建内存数据。
由于 Linux 会把对⽂件的写⼊数据通过 buffer 缓冲（全⾯了解系统资源情况——top”），因此 Linux 可能不是⽴即写⼊到⽂件，有丢失数据的⻛险。

在 Redis 的配置⽂件中，可以通过相应的配置选项告诉 Redis 需要通过 fsync 函数强制 Linux 写⼊到磁盘的时机。

下⾯是 Redis 配置⽂件中有关 AOF 持久化的主要参数。

```shell
Appendonly no #是否开启AOF 的持久化⽅式
Appendfilename "Appendonly.aof" #AOF ⽂件的名称，默认为Appendonly.aof
# Appendfsync always #每次收到写命令就⽴即强制写⼊到磁盘，能保证完全持久化，但速度也最慢，不
Appendfsync everysec #每秒钟强制写⼊磁盘⼀次，在性能和持久化⽅⾯做了很好的折中，推荐
# Appendfsync no #完全依赖Linux，性能最好，但持久化没保证
```

⽤ AOF 的持久化⽅式慢慢会出现⼀个问题：

AOF ⽂件会变得越来越⼤。例如，有⼀个写命令“set n um
1”，然后执⾏了 100 次写命令“incr num”，这时 num 的值为 101，这 100 次“incr”操作都会记录到持久化⽂件， 但重建内存数据时，实际只需要执⾏“set nu m 101”就可以了，⽆须先执⾏“set num 1”再执⾏ 100 次“incr num”。

为了压缩 AOF ⽂件，Redis 提供了 bgrewriteaof 命令，Redis 收到这个命令后会以类似创建 RDB ⽂件的⽅式将内存数据以命令的形式保存到临时⽂件中，最后替换原⽂件。

下⾯是 Redis 配置⽂件中有关 bgrewriteaof 命令的主要参数。

```shell
no-Appendfsync-on-rewrite yes #在⽇志重写时，不进⾏命令追加，⽽将其放在缓冲区中
auto-aof-rewrite-percentage 100 #当前AOF ⽂件⼤⼩是上次⽇志重写的AOF ⽂件⼤⼩的⼆倍时，⾃动启动新的⽇志
auto-aof-rewrite-min-size 64mb #当前AOF ⽂件重写的最少值
```

当"auto-aof-rewrite-percentage"和"auto-aof-rewrite-min-size"这两个条件都满⾜时,才会触发 bgrewriteaof 命令。

执⾏ bgrewriteaof 命令过程如下。

1. Redis 调⽤ fork ⽣成⼦进程，这样就有了 Redis 的⼦进程和⽗进程。
2. ⽗进程继续处理客⼾端发送的请求，⼦进程把内存数据以命令的形式写⼊到临时⽂件。由于 Linux 操作系统的特性，⽗进程和⼦进程会共享相同的内存空间，所以⼦进程的数据是和 fork 时 Redis 中内存的数
   据⼀致的。
3. 在⼦进程写临时⽂件的过程中，⽗进程把收到的写命令缓存起来。
4. ⼦进程写⼊临时⽂件完毕，⼦进程通知⽗进程，⽗进程把缓存中的写⼊命令追加到临时⽂件。
5. 临时⽂件替换 AOF ⽂件，⽗进程继续把新增的写命令追加到 AOF ⽂件，⼦进程退出。

#### 3.redis 主从复制

下面我们首先来看下 redis 的主从复制。

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.pf33v3v71.webp){: .zoom}

redis 主从复制的原理图

redis 主从复制的具体流程:

1）若启动一个 Slave 机器进程，则它会向 Master 机器发送一个“synccommand”命令，请求同步连接。

2）无论是第一次连接还是重新连接，Master 机器都会启动一个后台进程，将数据快照保存到数据文件中（执行 rdb 操作），同时 Master 还会记录修改数据的所有命令并缓存在数据文件中。

3）后台进程完成缓存操作之后，Maste 机器就会向 Slave 机器发送数据文件，Slave 端机器将数据文件保存到硬盘上，然后将其加载到内存中，接着 Master 机器就会将修改数据的所有操作一并发送给 Slave 端机器。若 Slave 出现故障导致宕机，则恢复正常后会自动重新连接。

4）Master 机器收到 Slave 端机器的连接后，将其完整的数据文件发送给 Slave 端机器，如果 Mater 同时收到多个 Slave 发来的同步请求，则 Master 会在后台启动一个进程以保存数据文件，然后将其发送给所有的 Slave 端机器，确保所有的 Slave 端机器都正常。

**支持断点续传吗？**

从 redis 2.8 开始，如果在主从复制过程中遭遇连接断开，则重新连接之后可以从中断处继续进行复制，而不必重新同步。

**断点续传的工作原理具体如下:**

主服务器端为复制流维护一个内存缓冲区（in-memory backlog）。主从服务器都维护一个复制偏移量（replication offset）和 master run id。当连接断开时，从服务器会重新连接上主服务器，然后请求继续复制，假如主从服务器的两个 master run id 相同，并且指定的偏移量在内存缓冲区中还有效，则复制就会从上次中断的点开始继续。如果其中一个条件不满足，就会进行完全重新同步（在 2.8 版本之前就是直接进行完全重新同步）。

因为主运行 id 不保存在磁盘中，因此如果从服务器重启了的话就只能进行完全同步了。对于部分重新同步这个新特性，redis 2.8 版本内部使用 PSYNC 命令，旧版本的实现中使用的是 SYNC 命令。redis2.8 版本可以检测出它所连接的服务器是否支持 PSYNC 命令，若不支持则使用 SYNC 命令。

redis 主从复制的效果是很不错的，在很多跨机房的业务中其稳定性也很不错。另外，如果业务需要采用 redis 集群的话，则生产环境下不建议使用 redis-cluster，建议采用 codis、zookeeper 来保证各节点之间的数据一致性。

#### 4.MySQL 数据库主从 Replication 同步

MySQL 数据库的主从 Replication 同步（又称为主从复制）是一个很成熟的架构，笔者的许多电商平台线上环境采用的都是这种方案。

优点：

1）在业务繁忙阶段，我们可以在从服务器上执行查询工作（即我们常说的读写分离），降低主服务器的压力。

2）在从服务器上进行备份，以避免备份期间影响主服务器服务。

3）当主服务器出现问题时，可以迅速切换到从服务器，这样就不会影响线上环境了。

4）数据分布。由于 MySQL 复制并不需要很大的带宽，因此可以在不同的数据中心实现数据的复制。

![image](https://cdn.jsdelivr.net/gh/hujianli94/picx-images-hosting@master/image.6m3navn9rg.webp){: .zoom}
MySQL 数据库主从复制原理图

原理

主从复制是 MySQL 数据库提供的一种高可用、高性能的解决方案，其原理其实并不复杂，它并不是完全的实时，其实际上是一种异步的实时过程，如果由于网络的原因而导致延迟比较严重，这时候就需要考虑将其延迟时间作为报警系统的选项参数了，主从复制同步的具体工作步骤如下。

1）主服务器将数据更新记录到二进制日志中。

2）从服务器会开启两个线程，即 I/O 线程和 SQL 线程。

3）从服务器将主服务器的二进制日志（Binary log）复制到自己的中继日志（Relay log）中，这个是由从服务器的 I/O 线程来负责的。

4）从服务器执行中继日志，将其更新应用到自己的数据库上，这个是由从服务器的 SQL 线程来负责的。

MySQL 主从 Replication 复制非常快，加上我们一般是将其同时置于同一机房的同一交换机之上，因此网络方面的影响非常小，小数据量的改变几乎感觉不到延迟（但还是属于异步同步），通常在 Master 端发生改动以后，Slave 端也会立即改动，非常方便；不过，MySQL 的 Replication 也有其弊端，如果 Master 端进行误操作，Slave 也会进行误操作，这样就会非常麻烦。所以，如果是作为备份机使用，我们应该采取延时 Replication 的方法，通常是延迟一天，这种工作的具体需求大家可以自行研究。

另外，对于跨机房的 MySQL 主从复制，如果是数据量比较大的情况，那将是一件非常具有挑战性的工作，大家可以关注下阿里巴巴的开源项目 otter。

我们在很多业务场景中都遇到过在不改动代码的前提下实施 MySQL 读写分离的操作，这个时候我们可以考虑使用开源的数据库中间件 Mycat，它不仅能实现此需求，还能支持分库分表，自带强大的 Web 监控，大家在有此业务需求时可以考虑下它。

## 1.7 Linux 服务器的安全防护

### 1.7.1 DDoS 攻击和运营商劫持

一般网站防御 DDoS 攻击的方法：

一般会通过前端 LVS 切量的方式来转移 DDoS 流量，从而减少 DDoS 攻击所带来的损失。

### 1.7.2 运营商劫持

运营商劫持分为 DNS 劫持和 HTTP 劫持两种。

运营商劫持的常见操作：

❑ 向正常网站加入额外的广告，包括网页内浮层或弹出广告窗口。

❑ 针对一些广告联盟或带推广链接的网站，加入推广尾巴。

1. DNS 劫持

一般而言，用户上网的 DNS 服务器都是运营商分配的，所以，在这个节点上，运营商可以为所欲为。

例如，访问http://jiankang.qq.com/index.html，正常DNS应该返回腾讯的IP，而遭到DNS劫持后，其会返回一个运营商的中间服务器IP。访问该服务器会一致性地返回302，使用户浏览器跳转到预处理好的带广告的网页，在该网页中再通过iframe打开用户原来访问的地址。这种情况在小ISP运营商处比较常见，这种情况比较难以处理，尤其是托管了DNS服务的，一般的做法是更改我们DNS设备的常规服务端口，比如将常规的53改成5353。最直接有效的措施是直接进行投诉处理，一般情况下，运营商是会处理的（投诉到工信部，这也是ISP运营商最不愿意看到的）。

解决办法：投诉

2. HTTP 劫持

在运营商的路由器节点上，设置协议检测，一旦发现是 HTTP 请求，而且是 HTTP 类型请求，则进行拦截处理。

后续做法往往分为两种，第一种是类似 DNS 劫持返回 302 让用户浏览器跳转到另外的地址，另外一种做法是在服务器返回的 HTML 数据中插入 JS 或 DOM 节点（广告）。

从用户的角度出发，这些劫持的表现具体如下。

❑ 网址无辜跳转，多了推广尾巴。

❑ 页面出现额外的广告（IFRAM 模式或者直接同页面插入了 DOM 节点）。

解决方法：最根本解决办法是使用 HTTPS，不过这将会涉及很多业务的修改，成本很高。

### 1.7.3 Linux 服务器基础防护篇

从以下几个方面着手：

1）首先要保证自己的 Linux 服务器的密码绝对安全，笔者一般将 root 密码设置为 28 位以上，而且某些重要的服务器只有几个人知道 root 密码，这将根据公司管理层的权限来进行设置，如果有系统管理员级别的相关人员离职，那么一定要更改 root 密码。现在我们的做法一般是禁止 root 远程登录，只分配一个具有 sudo 权限的用户。服务器的账号管理一定要严格，服务器上除了 root 账号之外，系统用户越少越好，如果非要添加用户来作为应用程序的执行者，那么请将他的登录 Shell 设为 nologin，即此用户是没有权利登录服务器的。

建议使用：堡垒机作为入口，因为可以审计人员操作。

2）防止 SSH 暴力破解是一个老生常谈的问题，解决这问题的方法有许多种：有的朋友喜欢用 iptables 的 recent 模块来限制单位时间内 SSH 的连接数，有的则用 DenyHost 防 SSH 暴力破解工具，尽可能地采用部署服务器密钥登录的方式，这样就算是对外开放 SSH 端口，暴力破解也完全没有用武之地。

建议：修改 SSH 端口，设置 ssh 登录超时时间、登录次数等。

3）分析系统的日志文件，寻找入侵者曾经试图入侵系统的蛛丝马迹。last 命令是另外一个可以用来查找非授权用户登录事件的工具。

4）建议不定期使用 grep error /var/log/messages 检查自己的服务器是否存在硬件损坏的情况。

5）建议不定期使用 Chkrootkit 应用程序对 rootkit 的踪迹和特征进行查找，从它的报告中我们可以分析服务器是否已经感染木马。

6）推荐使用 Tiprwire 开源软件来检查文件系统的完整性，并做好相应的日志分析工作。

7）停掉一些系统不必要的服务，强化内核。多关注一下服务器的内核漏洞，现在 Linux 的很多攻击都是针对内核的，因此应尽量保证内核版本是最新的。

### 1.7.4 Linux 服务器高级防护篇

我们还可以设计代码级别的 WAF 软件防火墙，主要是通过 ngx_lua 模块来实现的，由于 LUA 语言的性能是接近于 C 的，而且 ngx_lua 模块本身就是基于为 Nginx 开发的高性能的模块，所以性能方面表现良好。其可以实现如下功能的安全防护，具体如下。

❑ 支持 IP 白名单和黑名单功能，直接拒绝黑名单的 IP 访问。

❑ 支持 URL 白名单，对不需要过滤的 URL 进行定义。

❑ 支持 User-Agent 的过滤，匹配自定义规则中的条目，然后进行处理，返回 403。

❑ 支持 CC 攻击防护，若单个 URL 指定时间内的访问次数，超过了设定值，则直接返回 403。

❑ 支持 Cookie 过滤，匹配自定义规则中的条目，然后进行处理，返回 403。

❑ 支持 URL 过滤，匹配自定义规则中的条目，如果用户请求的 URL 包含了这些，则返回 403。

❑ 支持 URL 参数过滤，原理同上。

❑ 支持日志记录，将所有拒绝的操作记录到日志中去。

#### WAF 的特点

❑ 异常检测协议：Web 应用防火墙会对 HTTP 的请求进行异常检测，拒绝不符合 HTTP 标准的请求。并且，其可以只允许 HTTP 的部分选项通过，从而减少攻击的影响范围。甚至，一些 Web 应用防火墙还可以严格限定 HTTP 中那些过于松散或未被完全制定的选项。

❑ 增强的输入验证：增强输入验证，可以有效防止网页篡改、信息泄露、木马植入等恶意的网络入侵行为，从而减小 Web 服务器被攻击的可能性。

❑ 及时补丁：修补 Web 安全漏洞，是 Web 应用开发者最为头痛的问题，没人知道下一秒会出现什么样的漏洞，会为 Web 应用带来什么样的危害。WAF 可以为我们做这项工作了—只要有全面的漏洞信息，WAF 就能在不到一个小时的时间内屏蔽掉这个漏洞。当然，这种屏蔽漏洞的方式并不是非常完美的，并且没有安装对应的补丁其本身就是一种安全威胁，但我们在没有选择的情况下，任何保护措施都比没有保护措施更好。

❑ 基于规则的保护和基于异常的保护：基于规则的保护可以提供各种 Web 应用的安全规则，WAF 生产商会维护这个规则库，并时时为其更新。用户可以按照这些规则对应用进行全方面检测。还有一些产品可以基于合法应用数据建立模型，并以此为依

❑ 状态管理：WAF 能够判断用户是否第一次访问，并且将请求重定向到默认登录页面并记录事件。通过检测用户的整个操作行为，我们可以更容易地识别出攻击行为。状态管理模式还能检测出异常事件（比如登录失败），并且在达到极限值时进行处理。这对暴力攻击的识别和响应是十分有利的。

❑ 其他防护技术：WAF 还具有一些安全增强的功能，可以用来解决 Web 程序员过分信任输入数据所带来的问题。比如，隐藏表单域保护、抗入侵规避技术、响应监视和信息泄露保护。

#### WAF 与网络防火墙的区别

网络防火墙作为访问控制设备，主要工作在 OSI 模型的三、四层，基于 IP 报文进行检测。只对端口做限制，对 TCP 做封堵。

其产品设计无须理解 HTTP 会话，这也就决定了其无法理解 Web 应用程序语言，如 HTML、SQL 等。因此，它不可能对 HTTP 通信进行输入验证或攻击规则分析。针对 Web 网站的恶意攻击，绝大部分都将封装为 HTTP 请求，从 80 或 443 端口顺利通过防火墙检测。

一些定位比较综合、提供功能比较丰富的防火墙，也具备一定程度的应用层防御能力，如果能够根据 TCP 会话异常性及攻击特征阻止网络层
