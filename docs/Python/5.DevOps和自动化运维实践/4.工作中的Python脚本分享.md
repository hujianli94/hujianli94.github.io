# 4.工作中的 Python 脚本分享

## 1.多线程爬取图片的例子（centos6.8 x86_64 下通过）

```python
# !/usr/bin/env python
# -*- coding:UTF-8 -*-
import re
import os
import urllib
import threading
import time
import Queue


def getHtml(url):
    html_page = urllib.urlopen(url).read()
    return html_page


# 提取网页中图片的URL
def getUrl(html):
    pattern = r'src="(.+?\.jpg)" pic_ext'  # 正则表达式匹配图片
    imgre = re.compile(pattern)
    imglist = re.findall(imgre, html)
    # re.findall(pattern,string)在string中寻找所有匹配成功的字符串，以列表形式返回值
    return imglist


class getImg(threading.Thread):
    def __init__(self, queue):
        # 进程间通过队列通信，所以每个进程需要用到同一个队列初始化
        threading.Thread.__init__(self)
        self.queue = queue
        self.start()  # 启动线程

    # 使用队列实现进程间通信
    def run(self):
        global count
        while (True):
            imgurl = self.queue.get()
            print self.getName()
            # urllib.urlretrieve(url,filname) 将url的内容提取出来，并存入filename中
            urllib.urlretrieve(imgurl, '/root/python/images/%s.jpg' % count)
            print "%s.jpg done" % count
            count += 1
            if self.queue.empty():
                break
            self.queue.task_done()
            # 当使用者线程调用 task_done() 以表示检索了该项目、并完成了所有的工作时，那么未完成的任务的总数就会减少。


def main():
    global count
    url = "http://tieba.baidu.com/p/2460150866"  # 爬虫程序要抓取内容的网页地址
    html = getHtml(url)
    imglist = getUrl(html)
    threads = []
    count = 0
    queue = Queue.Queue()

    # 将所有任务加入队列
    for i in range(len(imglist)):
        queue.put(imglist[i])

    # 多线程爬取图片
    for i in range(8):
        thread = getImg(queue)
        threads.append(thread)

    # 合并进程，当子进程结束时，主进程才可以执行
    for thread in threads:
        thread.join()


if __name__ == '__main__':
    if not os.path.exists("/root/python/images"):
        os.makedirs("/root/python/images")
    main()
    print "多线程爬取图片任务已完成！"
```

## 2.利用 Python 脚本发送工作邮件

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
import smtplib
from email.mime.text import MIMEText
import string
import os

mail_host = "mail.example.com.cn"
mail_subject = "hostname名字不规则的机器列表"
# mail_reciver = ["yuhc@example.com.cn"]
mail_reciver = ["devops@example.com.cn", "admin@example.com.cn", "sa@example.com.cn"]
# mail_cc=["wangmiao@example.com.cn","nocdev@example.com"]
# mail_reliver以列表的形式存在，如果是单个收件地址，建议也以方式，即mail_reciver = ["yuhc@example.com.cn"]
mail_from = "yhc@example.com.cn"
text = open('/data/report/hostname_report.txt', 'r')
# body = string.join((text.read().strip()), "\r\n")
body = "ALL:\r\n" + "        你好，下面是我们全网内hostname名字不规范的列表，已经依次列出，麻烦将其改正并修正至 CMDB 系统，谢谢，列表如下所示：\r\n" + "\r\n" + text.read() + "\r\n" + "-------" + "\r\n" + "运维开发 | 余洪春"
text.close()

# body = str(body)
msg = MIMEText(body, format, 'utf-8')
msg['Subject'] = mail_subject
msg['From'] = mail_from
msg['To'] = ",".join(mail_reciver)
# msg['Cc'] = ",".join(mail_cc)
# 以下两行代码加上前面的MIMEText中的'utf-8'都是为了解决邮件正文乱码问题.
msg["Accept-Language"] = "zh-CN"
msg["Accept-Charset"] = "ISO-8859-1,utf-8"

# 发送邮件至相关人员
try:
    server = smtplib.SMTP()
    server.connect(mail_host, '25')
    # 注意这里用到了starttls
    server.starttls()
    server.login("yhc@example.com.cn", "yhc123456")
    server.sendmail(mail_from, mail_reciver, msg.as_string())

    server.quit()
except Exception, e:
    print "发送邮件失败" + str(e)
```

## 3.监测 IP 地址是否占用

```python
#!/usr/bin/env python
from threading import Thread
import subprocess
from Queue import Queue

num_threads = 8
list = []
for host in range(1,254):
    ip = "192.168.185." + str(host)
    list.append(ip)

q=Queue()
def pingme(i,queue):
    while True:
        ip=queue.get()
        print 'Thread %s pinging %s' %(i,ip)
        ret=subprocess.call('ping -c 1 %s' % ip,shell=True,stdout=open('/dev/null','w'),stderr=subprocess.STDOUT)
        if ret==0:
            print '%s is alive!' %ip
        elif ret==1:
            print '%s is down...'%ip
        queue.task_done()

#start num_threads threads
for i in range(num_threads):
    t=Thread(target=pingme,args=(i,q))
    t.setDaemon(True)
    t.start()

for ip in list:
    q.put(ip)
print 'main thread waiting...'
q.join();
print 'Done'
```

## 4.监测 redis 是否正常运行

```python
#!/usr/bin/env python
import redis
import sys

STATUS_OK = 0
STATUS_WARNING = 1
STATUS_CRITICAL = 2

HOST = sys.argv[1]
PORT = int(sys.argv[2])
WARNING = float(sys.argv[3])
CRITICAL = float(sys.argv[4])

def connect_redis(host, port):
    r = redis.Redis(host, port, socket_timeout = 5, socket_connect_timeout = 5)
    return r

def main():
    r = connect_redis(HOST, PORT)
    try:
        r.ping()
    except:
        print(HOST,PORT,'down')
        sys.exit(STATUS_CRITICAL)

    redis_info = r.info()
    used_mem = redis_info['used_memory']/1024/1024/1024.0
    used_mem_human = redis_info['used_memory_human']

    if WARNING <= used_mem < CRITICAL:
        print(HOST,PORT,'use memory warning',used_mem_human)
        sys.exit(STATUS_WARNING)
    elif used_mem >= CRITICAL:
        print(HOST,PORT,'use memory critical',used_mem_human)
        sys.exit(STATUS_CRITICAL)
    else:
        print(HOST,PORT,'use memory ok',used_mem_human)
        sys.exit(STATUS_OK)

if __name__ == '__main__':
    main()
```

## 5.调用有道词典的 API 翻译英文

```python
#!/usr/bin/env python
#-*- encoding=utf-8 -*-
import urllib
import json
url='http://fanyi.youdao.com/translate?smartresult=dict&smartresult=rule&smartresult=ugc&sessionFrom=dict2.index'

#建立一个字典
data = {}
data['i'] = '胡建力是帅哥'
data['from'] = 'AUTO'
data['to'] = 'AUTO'
data['smartresult'] = 'dict'
data['client'] = 'fanyideskwe'
data['salt'] = '1506219252440'
data['sign'] = '0b8cd8f9b8b14'
data['doctype'] = 'json'
data['version'] = '2.1'
data['keyfrom'] = 'fanyi.web'
data['action'] = 'FY_BY_CLICK'
data['typoResult'] = 'true'

#在这里还不能直接将data作为参数，需要进行一下数据的解析才可以
#encode是将Unicode的编码转换成utf-8编码
#data=urllib.urlencode(data).encode('utf-8')
#另一种写法，urlencode将字典转换成url参数
data = urllib.urlencode(data)
response=urllib.urlopen(url,data)

#decode作用是将其他形式的编码转换成python使用的Unicode编码
#html=response.read().decode('utf-8')
#另一种写法
html = response.read()
target=json.loads(html)
print(target['translateResult'][0][0]['tgt'])
```

## 6.Python 常用运维脚本

### 6.1 Python 检测 ip 存活状态

```python
#!/usr/bin/env python
# -*- coding:utf8 -*-
# auther; 18793
# Date：2019/6/19 23:18
# filename: python判断主机是否活跃.py
import subprocess
import threading
from time import sleep


def is_reacheable(ip):
    result = subprocess.call(["ping", "-c", "1", ip])
    if result != 0:
        print("{0} is not alive".format(ip))
    else:
        print("{0} is alive".format(ip))


def main():
    # 读取ip地址信息文件，一行一行的读取
    with open("ips.txt") as f:
        lines = f.readlines()
        threads = []
        for line in lines:
            thr = threading.Thread(target=is_reacheable, args=(line,))
            thr.start()
            sleep(1)

            # 将读取的信息加入到列表中，多进程启动
            threads.append(thr)
        for thr in threads:
            thr.join()


if __name__ == '__main__':
    main()
```

### 6.2 Python 实现⾃动化的服务恢复

```python
#!/usr/bin/env python
import requests
import subprocess
import time


def check_web_service(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            return True
        else:
            return False
    except requests.ConnectionError:
        return False


def restart_service(service_name):
    try:
        subprocess.run(["systemctl", "restart", service_name], check=True)
    except subprocess.CalledProcessError:
        print(f"⽆法重新启动服务: {service_name}")


if __name__ == "__main__":
    web_service_url = "http://example.com"
    service_name = "webserver.service"

    while True:
        if not check_web_service(web_service_url):
            print("检测到Web服务故障，尝试重新启动...")
            restart_service(service_name)
    else:
        print("Web服务正常运⾏")
        time.sleep(60)  # 60秒后再次检查
```

### 6.3 查询 SSL 证书的到期时间

```python
import subprocess
from datetime import datetime

def check_ssl_certificate(hostname):
    try:
        command = f"openssl s_client -servername {hostname} -connect {hostname}:443 -showcerts"
        output = subprocess.run(command, shell=True, capture_output=True, text=True).stdout.strip()

        cert_info = ""
        for line in output.split("\n"):
            if "-----BEGIN CERTIFICATE-----" in line:
                cert_info += line + "\n"
            elif "-----END CERTIFICATE-----" in line:
                cert_info += line + "\n"

        command = f"openssl x509 -noout -issuer -subject -dates -serial"
        output = subprocess.run(command, input=cert_info.encode(), shell=True, capture_output=True, text=True).stdout.strip()

        issuer = output.split("issuer=")[1].split("\n")[0]
        subject = output.split("subject=")[1].split("\n")[0]
        expiration_date = output.split("notAfter=")[1].split("\n")[0]
        expiration_date = datetime.strptime(expiration_date, "%b %d %H:%M:%S %Y %Z")
        current_date = datetime.now()
        days_left = (expiration_date - current_date).days
        serial_number = output.split("serial=")[1].split("\n")[0]

        certificate_info = {
            "主机名": hostname,
            "颁发机构": issuer,
            "证书主题": subject,
            "到期日期": expiration_date.strftime("%Y-%m-%d %H:%M:%S"),
            "剩余天数": days_left,
            "证书序列号": serial_number
        }

        return certificate_info
    except subprocess.CalledProcessError:
        return "错误：无法获取SSL证书信息"

def main():
    hosts = [
        "example.com",
        "google.com",
        "facebook.com"
    ]

    for host in hosts:
        certificate_info = check_ssl_certificate(host)
        if isinstance(certificate_info, dict):
            print(f"主机名：{host}")
            for key, value in certificate_info.items():
                print(f"{key}：{value}")
            print()
        else:
            print(certificate_info)

if __name__ == "__main__":
    main()
```

### 6.4 Python 脚本实现数据库自动化备份

```python
import datetime
import os
import subprocess

# 数据库备份目录
BACKUP_DIR = '/path/to/backup'
# 备份文件保留周期（天）
RETENTION_PERIOD = 7

# 备份数据库
def backup_database():
    current_time = datetime.datetime.now()
    backup_file = f"backup_{current_time.strftime('%Y%m%d%H%M%S')}.sql"
    backup_path = os.path.join(BACKUP_DIR, backup_file)

    # 使用 subprocess 模块执行数据库备份命令
    backup_command = [
        'mysqldump',
        '-u',
        'username',
        '-p',
        'password',
        '--all-databases'
    ]
    with open(backup_path, 'w') as backup_file:
        subprocess.run(backup_command, stdout=backup_file)

    print(f"数据库备份已完成，备份文件保存为: {backup_path}")

# 清理过期备份文件
def cleanup_backup():
    current_time = datetime.datetime.now()
    cutoff_time = current_time - datetime.timedelta(days=RETENTION_PERIOD)

    for file in os.listdir(BACKUP_DIR):
        file_path = os.path.join(BACKUP_DIR, file)
        if os.path.isfile(file_path):
            file_time = datetime.datetime.fromtimestamp(os.path.getmtime(file_path))
            if file_time < cutoff_time:
                os.remove(file_path)
                print(f"过期备份文件已删除: {file_path}")

# 恢复数据库
def restore_database(backup_file, restore_time):
    backup_path = os.path.join(BACKUP_DIR, backup_file)

    # 使用 subprocess 模块执行数据库恢复命令
    restore_command = [
        'mysql',
        '-u',
        'username',
        '-p',
        'password'
    ]
    with open(backup_path, 'r') as backup_file:
        subprocess.run(restore_command, stdin=backup_file)

    print(f"数据库已成功恢复到时间点: {restore_time}")

# 主函数
def main():
    # 执行数据库备份
    backup_database()

    # 清理过期备份文件
    cleanup_backup()

    # 恢复数据库到指定时间点
    restore_database('backup_20220101120000.sql', '2022-01-01 12:00:00')

if __name__ == '__main__':
    main()
```

### 6.5 Linux 系统日志巡检

```python
import paramiko
import json
import logging
import concurrent.futures

# 配置文件路径
CONFIG_FILE = 'devices.json'

# 日志配置
LOG_FILE = 'automation.log'
LOG_LEVEL = logging.INFO

# 连接超时时间（秒）
CONNECT_TIMEOUT = 10

# 配置日志
logging.basicConfig(filename=LOG_FILE, level=LOG_LEVEL)

# 读取设备信息配置文件
def read_config():
    try:
        with open(CONFIG_FILE, 'r') as file:
            config = json.load(file)
            return config
    except FileNotFoundError:
        logging.error(f'配置文件 {CONFIG_FILE} 未找到')
    except json.JSONDecodeError:
        logging.error(f'配置文件 {CONFIG_FILE} 解析错误')

    return None

# 连接设备
def connect_device(device):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

    try:
        client.connect(
            hostname=device['host'],
            username=device['username'],
            key_filename=device['key_filename'],
            timeout=CONNECT_TIMEOUT
        )
        return client
    except paramiko.AuthenticationException:
        logging.error(f"无法连接设备 {device['host']}: 身份验证失败")
    except paramiko.SSHException as e:
        logging.error(f"无法连接设备 {device['host']}: {str(e)}")
    except Exception as e:
        logging.error(f"无法连接设备 {device['host']}: {str(e)}")

    return None

# 执行命令
def execute_command(client, command):
    try:
        stdin, stdout, stderr = client.exec_command(command, timeout=CONNECT_TIMEOUT)
        output = stdout.read().decode('utf-8')
        error = stderr.read().decode('utf-8')
        client.close()

        if error:
            logging.error(f"命令执行出错: {error}")
            return None

        return output.strip()
    except Exception as e:
        logging.error(f"命令执行出错: {str(e)}")
        return None

# 检查设备状态
def check_device_status(device):
    client = connect_device(device)

    if client:
        output = execute_command(client, 'show interfaces')
        if output:
            logging.info(f"设备 {device['host']} 状态正常")
            logging.info(output)

# 配置设备
def configure_device(device):
    client = connect_device(device)

    if client:
        config_commands = [
            'interface eth0',
            'ip address 192.168.1.1 255.255.255.0',
            'no shutdown'
        ]

        for command in config_commands:
            execute_command(client, command)

        logging.info(f"设备 {device['host']} 配置已更新")

# 故障排除
def troubleshoot_device(device):
    client = connect_device(device)

    if client:
        output = execute_command(client, 'show logs')
        if output:
            logging.info(f"设备 {device['host']} 故障排除日志:")
            logging.info(output)

# 主函数
def main():
    config = read_config()

    if config:
        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = []
            for device in config['devices']:
                logging.info(f"正在检查设备 {device['host']} 的状态...")
                futures.append(executor.submit(check_device_status, device))

            for future in concurrent.futures.as_completed(futures):
                future.result()

        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = []
            for device in config['devices']:
                logging.info(f"正在配置设备 {device['host']}...")
                futures.append(executor.submit(configure_device, device))

            for future in concurrent.futures.as_completed(futures):
                future.result()

        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = []
            for device in config['devices']:
                logging.info(f"正在进行故障排除...")
                futures.append(executor.submit(troubleshoot_device, device))

            for future in concurrent.futures.as_completed(futures):
                future.result()

    logging.info("脚本执行完毕")


if __name__ == '__main__':
    main()
```

### 6.6 Linux 系统定时任务管理

```python
import schedule
import time
import subprocess
import logging

# 配置日志
logging.basicConfig(filename='automation.log', level=logging.INFO)

# 定义定时任务
def run_command(command, task_name):
    result = subprocess.run(command, capture_output=True, text=True)
    if result.returncode == 0:
        logging.info(f"{task_name}任务执行成功")
    else:
        logging.error(f"{task_name}任务执行失败：{result.stderr}")

def backup_data():
    command = ['backup_tool', 'backup']
    run_command(command, '数据备份')

def cleanup_logs():
    command = ['log_tool', 'cleanup']
    run_command(command, '日志清理')

# 定义定时任务调度
def schedule_tasks():
    schedule.every().day.at("01:00").do(backup_data)  # 每天凌晨1点执行数据备份
    schedule.every().monday.at("02:00").do(cleanup_logs)  # 每周一凌晨2点执行日志清理

    while True:
        schedule.run_pending()
        time.sleep(1)

# 主函数
def main():
    logging.info("自动化运维脚本已启动")
    schedule_tasks()

if __name__ == '__main__':
    main()
```

### 6.7 Linux 系统设备自动化管理

```python
import paramiko
import json
import logging

# 配置文件路径
CONFIG_FILE = 'devices.json'

# 日志配置
LOG_FILE = 'automation.log'
LOG_LEVEL = logging.INFO

# 连接超时时间（秒）
CONNECT_TIMEOUT = 10

# 配置日志
logging.basicConfig(filename=LOG_FILE, level=LOG_LEVEL)

# 读取设备信息配置文件
def read_config():
    try:
        with open(CONFIG_FILE, 'r') as file:
            config = json.load(file)
            return config
    except FileNotFoundError:
        logging.error(f'配置文件 {CONFIG_FILE} 未找到')
    except json.JSONDecodeError:
        logging.error(f'配置文件 {CONFIG_FILE} 解析错误')

    return None

# 连接设备
def connect_device(device):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

    try:
        client.connect(
            hostname=device['host'],
            username=device['username'],
            key_filename=device['key_filename'],
            timeout=CONNECT_TIMEOUT
        )
        return client
    except paramiko.AuthenticationException:
        logging.error(f"无法连接设备 {device['host']}: 身份验证失败")
    except paramiko.SSHException as e:
        logging.error(f"无法连接设备 {device['host']}: {str(e)}")
    except Exception as e:
        logging.error(f"无法连接设备 {device['host']}: {str(e)}")

    return None

# 执行命令
def execute_command(client, command):
    try:
        stdin, stdout, stderr = client.exec_command(command, timeout=CONNECT_TIMEOUT)
        output = stdout.read().decode('utf-8')
        error = stderr.read().decode('utf-8')
        client.close()

        if error:
            logging.error(f"命令执行出错: {error}")
            return None

        return output.strip()
    except Exception as e:
        logging.error(f"命令执行出错: {str(e)}")
        return None

# 检查设备状态
def check_device_status(device):
    client = connect_device(device)

    if client:
        output = execute_command(client, 'show interfaces')
        if output:
            logging.info(f"设备 {device['host']} 状态正常")
            logging.info(output)

# 配置设备
def configure_device(device):
    client = connect_device(device)

    if client:
        config_commands = [
            'interface eth0',
            'ip address 192.168.1.1 255.255.255.0',
            'no shutdown'
        ]

        for command in config_commands:
            execute_command(client, command)

        logging.info(f"设备 {device['host']} 配置已更新")

# 故障排除
def troubleshoot_device(device):
    client = connect_device(device)

    if client:
        output = execute_command(client, 'show logs')
        if output:
            logging.info(f"设备 {device['host']} 故障排除日志:")
            logging.info(output)

# 主函数
def main():
    config = read_config()

    if config:
        for device in config['devices']:
            logging.info(f"正在检查设备 {device['host']} 的状态...")
            check_device_status(device)

            logging.info(f"正在配置设备 {device['host']}...")
            configure_device(device)

            logging.info(f"正在进行设备 {device['host']} 的故障排除...")
            troubleshoot_device(device)

    logging.info("自动化运维脚本执行完毕")

if __name__ == '__main__':
    main()
```

### 6.8 Linux 系统日志分析

```python
import paramiko
import json
import logging
import os
from concurrent.futures import ThreadPoolExecutor

# 配置文件路径
CONFIG_FILE = 'devices.json'

# 日志配置
LOG_FILE = 'automation.log'
LOG_LEVEL = logging.INFO

# 并发线程数
CONCURRENT_THREADS = 5

# 连接超时时间（秒）
CONNECT_TIMEOUT = 10

# 备份目录
BACKUP_DIR = 'backup'

# 邮件配置
SMTP_HOST = 'smtp.example.com'
SMTP_PORT = 587
SMTP_USERNAME = 'your_username'
SMTP_PASSWORD = 'your_password'
MAIL_FROM = 'from@example.com'
MAIL_TO = 'to@example.com'

# 配置日志
logging.basicConfig(filename=LOG_FILE, level=LOG_LEVEL)

# 读取设备信息配置文件
def read_config():
    try:
        with open(CONFIG_FILE, 'r') as file:
            config = json.load(file)
            return config
    except FileNotFoundError:
        logging.error(f'配置文件 {CONFIG_FILE} 未找到')
    except json.JSONDecodeError:
        logging.error(f'配置文件 {CONFIG_FILE} 解析错误')

    return None

# 创建备份目录
def create_backup_dir():
    if not os.path.exists(BACKUP_DIR):
        os.makedirs(BACKUP_DIR)
        logging.info(f'创建备份目录 {BACKUP_DIR}')

# 备份配置文件
def backup_config(device):
    client = connect_device(device)
    if client:
        config_file = device['config_file']
        backup_file = os.path.join(BACKUP_DIR, f'{device["host"]}_{config_file}')
        command = f'copy {config_file} {backup_file}'

        output = execute_command(client, command)
        if output:
            logging.info(f"设备 {device['host']} 配置文件备份成功: {backup_file}")
        else:
            logging.error(f"设备 {device['host']} 配置文件备份失败")

# 连接设备
def connect_device(device):
    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

    try:
        client.connect(
            hostname=device['host'],
            username=device['username'],
            key_filename=device['key_filename'],
            timeout=CONNECT_TIMEOUT
        )
        return client
    except paramiko.AuthenticationException:
        logging.error(f"无法连接设备 {device['host']}: 身份验证失败")
    except paramiko.SSHException as e:
        logging.error(f"无法连接设备 {device['host']}: {str(e)}")
    except Exception as e:
        logging.error(f"无法连接设备 {device['host']}: {str(e)}")

    return None

# 执行命令
def execute_command(client, command):
    try:
        stdin, stdout, stderr = client.exec_command(command, timeout=CONNECT_TIMEOUT)
        output = stdout.read().decode('utf-8')
        error = stderr.read().decode('utf-8')
        client.close()

        if error:
            logging.error(f"命令执行出错: {error}")
            return None

        return output.strip()
    except Exception as e:
        logging.error(f"命令执行出错: {str(e)}")
        return None

# 检查设备状态
def check_device_status(device):
    client = connect_device(device)

    if client:
        output = execute_command(client, 'show interfaces')
        if output:
            logging.info(f"设备 {device['host']} 状态正常")
            logging.info(output)

# 配置设备
def configure_device(device):
    client = connect_device(device)

    if client:
        config_commands = [
            'interface eth0',
            'ip address 192.168.1.1 255.255.255.0',
            'no shutdown'
        ]

        for command in config_commands:
            execute_command(client, command)

        logging.info(f"设备 {device['host']} 配置已更新")

# 故障排除
def troubleshoot_device(device):
    client = connect_device(device)

    if client:
        output = execute_command(client, 'show logs')
        if output:
            logging.info(f"设备 {device['host']} 故障排除日志:")
            logging.info(output)

# 发送邮件
def send_email(subject, message):
    import smtplib
    from email.mime.text import MIMEText

    msg = MIMEText(message)
    msg['Subject'] = subject
    msg['From'] = MAIL_FROM
    msg['To'] = MAIL_TO

    try:
        with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as server:
            server.starttls()
            server.login(SMTP_USERNAME, SMTP_PASSWORD)
            server.sendmail(MAIL_FROM, MAIL_TO, msg.as_string())
        logging.info("邮件发送成功")
    except Exception as e:
        logging.error(f"邮件发送失败: {str(e)}")

# 主函数
def main():
    config = read_config()

    if config:
        create_backup_dir()

        with ThreadPoolExecutor(max_workers=CONCURRENT_THREADS) as executor:
            for device in config['devices']:
                logging.info(f"正在备份设备 {device['host']} 的配置文件...")
                executor.submit(backup_config, device)

                logging.info(f"正在检查设备 {device['host']} 的状态...")
                executor.submit(check_device_status, device)

                logging.info(f"正在配置设备 {device['host']}...")
                executor.submit(configure_device, device)

                logging.info(f"正在对设备 {device['host']} 进行故障排除...")
                executor.submit(troubleshoot_device, device)

        send_email("自动化运维脚本执行完成", "脚本执行完成，请查看日志文件")
        logging.info("自动化运维脚本执行完成")

# 执行主函数
if __name__ == '__main__':
    main()
```

## 7.python 脚本安装 MongoDB

```python
#!/usr/bin/env python
# -*- coding:utf8 -*-
# auther; 18793
# Date：2019/6/19 22:08
# filename: deploy_mongo.py
import os
import shutil
import tarfile
import subprocess


def execute_cmd(cmd):
    """ 将执行shell命令封装成execute_cmd函数，使用时直接调用即可 """
    p = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE,
                         stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE)
    stdout, stderr = p.communicate()
    if p.returncode != 0:
        return p.returncode, stderr
    return p.returncode, stdout


def unpackage_mongo(package, package_dir):
    # 分割路径和文件名组成元祖，获取mongodb安装包解压以后的目录，如果目录存在，则删除该目录。
    unpackage_dir = os.path.splitext(package)[0]
    if os.path.exists(unpackage_dir):
        shutil.rmtree(unpackage_dir)
    # 解压目录后，重命名为mongo目录
    t = tarfile.open(package, 'r:gz')
    t.extractall(".")

    shutil.move(unpackage_dir, package_dir)


def create_datadir(data_dir):
    ''' 检测MongoDB目录是否存在,存在删除，不存在直接创建 '''
    if os.path.exists(data_dir):
        shutil.rmtree(data_dir)
    os.mkdir(data_dir)


def format_mongod_command(package_dir, data_dir, logfile):
    mongod = os.path.join(package_dir, "bin", "mongod")
    mongod_format = """{0} --fork --dbpath {1} --logpath {2}"""
    return mongod_format.format(mongod, data_dir, logfile)


def start_mongod(cmd):
    # 获取shell命令执行状态码和输出信息。
    returncode, out = execute_cmd(cmd)
    if returncode != 0:
        raise SystemExit("execute {0} error:{1}".format(cmd, out))
    else:
        print("execute command ({0}) successful".format(cmd))


def main():
    package = "mongodb-linux-x86_64-debian71-3.4.0.tgz"
    cur_dir = os.path.abspath(".")
    package_dir = os.path.join(cur_dir, "mongo")
    data_dir = os.path.join(cur_dir, "mongodata")
    logfile = os.path.join(cur_dir, "mongod.log")

    if not os.path.exists(package):
        raise SystemExit("{0} not found".format(package))

    # 解压安装包，并移动目录
    unpackage_mongo(package, package_dir)
    # 创建目标目录
    create_datadir(data_dir)
    # 启动服务
    start_mongod(format_mongod_command(package_dir, data_dir, logfile))


if __name__ == '__main__':
    main()
```

## 8.python 安装脚本

### 8.1 install_cmdb

> 来源： https://gitcode.com/open-cmdb/cmdb/blob/master/tools/install_cmdb.py

`install_cmdb.py`

```python
#!/usr/bin/env python2
# -*- coding: utf-8 -*-
import os
import subprocess
import argparse
import time

def base(cmd):
    if subprocess.call(cmd, shell=True):
        raise Exception("{} 执行失败".format(cmd))

def install_docker():
    base("sudo yum install -y yum-utils device-mapper-persistent-data lvm2")
    base("sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo")
    base("sudo yum makecache fast")
    base("sudo yum -y install docker-ce")
    if(not os.path.exists("/etc/docker")):
        base("mkdir -p /etc/docker")
    with open("/etc/docker/daemon.json", "w") as f:
        f.write('{\n    "registry-mirrors": ["https://9f4w4icn.mirror.aliyuncs.com"] \n}')
    base("sudo systemctl daemon-reload")
    base("sudo systemctl start docker")

def create_dir():
    if (not os.path.exists("/var/cmdb/db")):
        base("sudo mkdir -p /var/cmdb/db")
    if (not os.path.exists("/var/cmdb/es")):
        base("sudo mkdir -p /var/cmdb/es")

def run_db_container():
    base("sudo docker run --name cmdb-db -d -e MYSQL_ROOT_PASSWORD=cmdbcmdb -v /var/cmdb/db:/var/lib/mysql mysql:5.7.21")

def run_es_container():
    base("sudo docker run --name cmdb-es -d -v /var/cmdb/es:/usr/share/elasticsearch/data elasticsearch:5.6.8")

def init_db():
    base("sudo docker run -it --rm --link cmdb-db -e DB_HOST=cmdb-db -e ENV=PRO -e DB_PORT=3306 -e DB_USERNAME=root -e DB_PASSWORD=cmdbcmdb -e DB_NAME=cmdb mingmingtang/cmdb init-db")

def run_cmdb_container(site_url, email_host, email_port, email_username, email_password):
    base("sudo docker run -d --name cmdb --link cmdb-db --link cmdb-es -p 80:80 -e ENV=PRO -e SITE_URL={} -e DB_HOST=cmdb-db -e DB_PORT=3306 -e DB_USERNAME=root -e DB_PASSWORD=cmdbcmdb -e DB_NAME=cmdb -e ELASTICSEARCH_HOSTS=cmdb-es -e EMAIL_HOST={} -e EMAIL_PORT={} -e EMAIL_USERNAME={} -e EMAIL_PASSWORD={} mingmingtang/cmdb start".format(site_url, email_host, email_port, email_username, email_password))

def input_para(help):
    value = ""
    while(not value):
        value = raw_input(help)
    return value

if __name__ == '__main__':
    if(os.geteuid() != 0):
        raise("请以root权限运行")
    # parser = argparse.ArgumentParser()
    # parser.add_argument("--siteurl", type=str, help="E.g: http://cmdb.xxx.com, http://172.17.100.1")
    # parser.add_argument("--emailhost", type=str, help="E.g: http://cmdb.xxx.com, http://172.17.100.1")
    # parser.add_argument("--emailport", type=str, help="E.g: http://cmdb.xxx.com, http://172.17.100.1")
    # parser.add_argument("--emailusername", type=str, help="E.g: http://cmdb.xxx.com, http://172.17.100.1")
    # parser.add_argument("--emailpassword", type=str, help="E.g: http://cmdb.xxx.com, http://172.17.100.1")
    # args = parser.parse_args()
    # SITE_URL = args.SITE_URL

    site_url = input_para("请输入网站域名或IP（http://cmdb.xxx.com）：")
    email_host = input_para("网站邮箱服务器（smtp.163.com）：")
    email_port = input_para("邮箱服务器端口（25）：")
    email_username = input_para("邮箱用户名（cmdb@163.com）：")
    email_password = input_para("邮箱密码|独立授权码（P@ssw0rd）：")

    print("开始安装docker")
    install_docker()
    print("开始创建目录")
    create_dir()
    print("开始运行mysql容器")
    run_db_container()
    print("开始运行elasticsearch容器")
    run_es_container()
    print("等待数据库启动完成(10s)")
    time.sleep(10)
    print("开始初始化数据库")
    init_db()
    print("开始运行cmdb")
    run_cmdb_container(site_url, email_host, email_port, email_username, email_password)
    print("完成！")
```

### 8.2 install_cetus

`install_cetus.py`

> 来源：https://github.com/Lede-Inc/Cetus-GUI/blob/master/backend/shells/install_cetus.py

```python
#!/bin/python3
# -*- coding: utf-8 -*-

import subprocess
import sys
import os
import getopt
import socket
import shutil


def help_and_exit():
    print('''Usage:
    -h 显示帮助信息
    -t Cetus类型
    -p 服务端口
    -a 管理端口
    -b 分支
    -d Cetus目录
    ''')
    sys.exit()


def check_socket(port_list):
    for index in port_list:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        result = sock.connect_ex(('127.0.0.1', int(index)))
        sock.close()
        if not result:
            raise Exception('端口已被占用')


def create_environment(user, cetus_path):
    try:
        os.system('useradd %s' % user)
        p = subprocess.Popen('sudo yum install cmake gcc glib2-devel flex mysql-devel gperftools-libs git -y',
                             shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        p.communicate()
        path = cetus_path[:cetus_path.rfind('/')] + '/logs'
        if not os.path.exists(path):
            os.makedirs(path)
        os.system('chown -R %s:%s %s' % (user, user, path))
    except Exception as e:
        print(e)
        raise Exception('环境初始化失败')


def install_cetus(cetus_type, cetus_route, cetus_path, user):
    try:
        os.chdir(cetus_route)
        cetus_type = 'ON' if cetus_type == 'rw' else 'OFF'

        p = subprocess.Popen('mkdir build && cd build && cmake ../ -DCMAKE_BUILD_TYPE=Debug '
                             '-DCMAKE_INSTALL_PREFIX=%s -DSIMPLE_PARSER=%s && make install' % (cetus_path, cetus_type),
                             shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        p.communicate()
        os.system('chown -R %s:%s %s' % (user, user, cetus_path[:cetus_path.rfind('/')]))
    except Exception as e:
        print(e)
        raise Exception('安装失败')
    finally:
        shutil.rmtree(cetus_route, ignore_errors=True)


def main():
    try:
        opts, args = getopt.getopt(sys.argv[1:],
                                   'ht:s:a:r:p:',
                                   ['help', 'type=', 'service=', 'admin=', 'route=', 'path='])
    except getopt.GetoptError as err:
        print(err)
        help_and_exit()

    for opt, arg in opts:
        if opt in ('-h', '--help'):
            help_and_exit()
        elif opt in ('-t', '--type'):
            cetus_type = arg
        elif opt in ('-s', '--service'):
            service_port = arg
        elif opt in ('-a', '--admin'):
            admin_port = arg
        elif opt in ('-r', '--route'):
            cetus_route = arg
        elif opt in ('-p', '--path'):
            cetus_path = arg

    try:
        check_socket([service_port, admin_port])
        user = 'cetus_%s' % service_port
        create_environment(user, cetus_path)
        install_cetus(cetus_type, cetus_route, cetus_path, user)
        return 0, '安装成功'

    except Exception as e:
        print(e)
        return 1, e


if __name__ == '__main__':
    ret, msg = main()
    sys.exit(ret)
```

## 9.python 颜色打印

```python
#!/usr/bin/env python
# Date：2020/3/1 17:57
# filename: ColorPrint.py
import sys


class ColorPrint(object):
    def __init__(self, color, msg):
        self.color = color
        self.msg = msg
        self.cPrint(self.color, self.msg)

    def cPrint(self, color, msg):
        colors = {
            'black': '\033[30m%s\033[0m',
            'red': '\033[31m%s\033[0m',
            'green': '\033[32m%s\033[0m',
            'yellow': '\033[33m%s\033[0m',
            'blue': '\033[34m%s\033[0m',
            'white': '\033[37m%\033[0m'}
        if color in colors.keys():
            message = colors[color] % msg
            print(message)


if __name__ == '__main__':
    # cp = ColorPrint(sys.argv[1], sys.argv[2])
    cp = ColorPrint("red", "I am red color")
    cp2 = ColorPrint("green", "I am red green")
    cp3 = ColorPrint("yellow", "I am red yellow")
    cp4 = ColorPrint("blue", "I am red blue")
```

## 10.利用装饰器实现失败重试

```python
#!/usr/bin/env python
# Date：2020/1/8 22:34
# filename: sample04.py
import subprocess
import requests


def Retry(second):
    def decorator(func):
        def warpper(*args, **kwargs):
            att = 0  # 计数器
            while att < second:  # 按照计数器条件来循环
                print(att)
                try:
                    return func(*args, **kwargs)  # 运行请求，或者命令
                except Exception as e:
                    att += 1  # 计数器累加

        return warpper

    return decorator


@Retry(3)
def cmd_01(cmd):
    subprocess.call(cmd)


# 简单的爬虫,重试3次爬取
@Retry(3)
def get_respone(url):
    r = requests.get(url)
    return r


cmd_01("dir1")
get_respone("http://www.baidu1.com")
```

## 11.DevOps 和数据 CLI 工具

- https://github.com/HariSekhon/DevOps-Python-tools

## 12.Python 常用代码段

- https://github.com/crifan/python_common_code_snippet
- https://book.crifan.com/books/python_common_code_snippet/website/

## 12. 常用的提效小脚本

### 文件和目录管理

批量重命名文件

```python
import os
for filename in os.listdir('.'):
    os.rename(filename, filename.replace('old', 'new'))
```

查找大文件

```python
import os
for root, dirs, files in os.walk('.'):
    for name in files:
        if os.path.getsize(os.path.join(root, name)) > 1024 * 1024:  # 大于1MB
            print(os.path.join(root, name))
```

创建目录结构

```python
import os
os.makedirs('dir/subdir/subsubdir', exist_ok=True)
```

删除空目录

```python
import os
for root, dirs, files in os.walk('.', topdown=False):
    for name in dirs:
        dir_path = os.path.join(root, name)
        if not os.listdir(dir_path):
            os.rmdir(dir_path)
```

复制文件

```python
import shutil
shutil.copy('source.txt', 'destination.txt')
```

移动文件

```python
import shutil
shutil.move('source.txt', 'destination.txt')
```

读写文件内容

```python
# 读取文件内容
with open('file.txt', 'r') as file:
    content = file.read()

# 写入文件内容
with open('file.txt', 'w') as file:
    file.write('Hello, World!')

# 追加文件内容
with open('file.txt', 'a') as file:
    file.write('\nAppend this line.')
```

检查文件是否存在

```python
import os
if os.path.exists('file.txt'):
    print("File exists.")
else:
    print("File does not exist.")
```

计算文本文件中的单词数

> 描述：这个 Python 脚本读取文本文件并计算其中包含的单词数。它可以用于快速分析文本文档的内容，或者跟踪写作项目中的单词计数。

```python
# Python脚本计算文本文件中的单词数
def count_words(file_path):
    with open(file_path, 'r') as f:
        text = f.read()
        word_count = len(text.split())
    return word_count
```

查找和替换文本

> 描述：这个 Python 脚本在文件中搜索特定文本并用所需文本替换它。它可以用于批量替换某些短语或在大型文本文件中纠正错误。

```python
# Python脚本在文件中查找和替换文本
def find_replace(file_path, search_text, replace_text):
    with open(file_path, 'r') as f:
        text = f.read()
        modified_text = text.replace(search_text, replace_text)
    with open(file_path, 'w') as f:
        f.write(modified_text)
```

在目录中按扩展名排序文件

> 描述：这个 Python 脚本根据文件扩展名将目录中的文件组织到子目录中。它识别文件扩展名并将文件移动到相应的子目录。
> 这对于整理下载文件夹或组织特定项目的文件很有用。

```python
# Python脚本按扩展名在目录中对文件进行排序
import os
from shutil import move
def sort_files(directory_path):
    for filename in os.listdir(directory_path):
        if os.path.isfile(os.path.join(directory_path, filename)):
            file_extension = filename.split('.')[-1]
            destination_directory = os.path.join(directory_path, file_extension)
            if not os.path.exists(destination_directory):
                os.makedirs(destination_directory)
            move(os.path.join(directory_path, filename), os.path.join(destination_directory, filename))
```

删除空文件夹

> 描述：这个 Python 脚本搜索并删除指定目录中的空文件夹。它可以帮助你维护一个干净整洁的文件夹结构，尤其是在处理大量数据时。

```python
# Python脚本在目录中删除空文件夹
import os
def remove_empty_folders(directory_path):
    for root, dirs, files in os.walk(directory_path, topdown=False):
        for folder in dirs:
            folder_path = os.path.join(root, folder)
            if not os.listdir(folder_path):
                os.rmdir(folder_path)
```

重命名多个文件

> 描述：这个 Python 脚本允许你同时在目录中重命名多个文件。它接受旧名称和新名称作为输入，并为所有匹配指定条件的文件替换旧名称。

```python
# Python脚本在目录中重命名多个文件
import os
def rename_files(directory_path, old_name, new_name):
    for filename in os.listdir(directory_path):
        if old_name in filename:
            new_filename = filename.replace(old_name, new_name)
            os.rename(os.path.join(directory_path, filename), os.path.join(directory_path, new_filename))
```

```python
import os

def batch_rename(directory, old_ext, new_ext):
  """批量重命名文件扩展名。
    :directory: 要处理的目录路径。
    :old_ext: 要替换的旧扩展名。
    :new_ext: 要替换的新扩展名。
  """

  for filename in os.listdir(directory):
    if filename.endswith(old_ext):
      base_name = os.path.splitext(filename)[0]
      new_filename = base_name + new_ext
      old_path = os.path.join(directory, filename)
      new_path = os.path.join(directory, new_filename)
      os.rename(old_path, new_path)

# 示例用法：将当前目录下所有 ".txt" 文件重命名为 ".md" 文件
batch_rename(".", ".txt", ".md")
```

批量重命名图片

> 描述：这个 Python 脚本批量重命名目录中的图片。它为每个图片文件添加一个前缀，并按顺序编号。

```python
# Python脚本批量重命名目录中的图片
import os
def rename_images(directory_path, prefix):
    for index, filename in enumerate(os.listdir(directory_path)):
        if filename.endswith(('.jpg', '.jpeg', '.png')):
            new_filename = f"{prefix}_{index}.jpg"
            os.rename(os.path.join(directory_path, filename), os.path.join(directory_path, new_filename))
```

压缩和解压 zip 文件

```python
#!/usr/local/python3.8/bin/python3
# -*- coding:UTF-8 -*-
# pip install shutil
# https://docs.python.org/zh-cn/3/library/shutil.html

import zipfile, os
from werkzeug.utils import secure_filename

'''
基本格式：zipfile.ZipFile(filename[,mode[,compression[,allowZip64]]])
mode：可选 r,w,a 代表不同的打开文件的方式；r 只读；w 重写；a 添加
compression：指出这个 zipfile 用什么压缩方法，默认是 ZIP_STORED，另一种选择是 ZIP_DEFLATED；
allowZip64：bool型变量，当设置为True时可以创建大于 2G 的 zip 文件，默认值 True；

'''

def unzip(path, folder_abs):
    zip_file = zipfile.ZipFile(path)
    zip_list = zip_file.namelist()  # 得到压缩包里所有文件

    for f in zip_list:
        zip_file.extract(f, folder_abs)  # 循环解压文件到指定目录
    zip_file.close()  # 关闭文件，必须有，释放内存
    os.remove(path)

def savefile(f, savepath):
    basepath = os.path.dirname(__file__)
    upload_path = os.path.join(basepath, savepath, secure_filename(f.filename))
    f.save(upload_path)
    unzip(upload_path, savepath)
```

打包文件 zipfile，tarfile

```python
# !/usr/bin/env python
# -*- coding:utf-8 -*-


# pip install zipfile38，tarfile不需要安装直接导入
import tarfile, zipfile


def zipDir(dirpath, outFullName):  # dirpath：是要打包的目录, outFullName：是压缩包名字
    zip = zipfile.ZipFile(outFullName, "w", zipfile.ZIP_DEFLATED)
    for path, dirnames, filenames in os.walk(dirpath):
        fpath = path.replace(dirpath, '')
        for filename in filenames:
            zip.write(os.path.join(path, filename), os.path.join(fpath, filename))
    zip.close()


def compress_file(dirpath, tarfilename):  # tarfilename是压缩包名字，dirname是要打包的目录
    if os.path.isfile(dirpath):
        with tarfile.open(tarfilename, 'w') as tar:
            tar.add(dirpath)
    else:
        with tarfile.open(tarfilename, 'w') as tar:
            #记录当前工作目录
            cur_path = os.getcwd()
            #切换工作目录
            os.chdir(dirpath)
            for root, dirs, files in os.walk('.'):
                for single_file in files:
                    # if single_file != tarfilename:
                    filepath = os.path.join(root, single_file)
                    tar.add(filepath)
            #切换回原来工作目录
            os.chdir(cur_path)


if __name__ == '__main__':
    zipDir('D:\\game\\build', 'abc.zip')
    compress_file('test.txt', 'test.tar.gz')
    compress_file('/tmp/test', 'test.tar.gz')
```

python 逐行读取文件

```python
#!/usr/bin/python3.8
# -*- coding:UTF-8 -*-

# 使用fileinput模块
import fileinput
for line in fileinput.input("test.txt"):
    print(line, end='')

# 对一个文件对象使用for循环读每行数据
with open('test.txt','r',encoding='utf-8') as f:
    for line in f:
        print(line, end='')

# 使用readline()函数
with open('test.txt','r',encoding='utf-8') as f:
    line = f.readline()
    while line:
        print(line, end='')  # 在 Python 3中使用
        line = f.readline()

# 一次读取多行数据(f.readlines(2)：一次读取两行数据)
with open('test.txt','r',encoding='utf-8') as f:
    tag=True
    while tag:
        lines = f.readlines(2)
        if lines:
            for line in lines:
                print(line, end='')
        else:
            tag=False
```

读取文件指定行或最后几行

```python
!/usr/bin/python3.8
# -*- coding:UTF-8 -*-

import linecache


# 放入缓存防止内存过载
def get_line_count(filename):
    """
    :param filename: 文件名
    :return: 返回文件总的行数
    """
    with open(filename, 'r', encoding="utf-8") as f:
        count = 1
        while True:
            buffer = f.read(1024 * 1)
            if not buffer:
                break
            count += buffer.count('\n')
    return count


# 读取文件最后几行，方式一：使用seek()方法
def readfileline(lines, filepath, off=-50):
    """
    file.seek(offset[, whence])
    file：表示文件对象；
    whence：作为可选参数，用于指定文件指针要放置的位置，该参数的参数值有 3 个选择：0 代表文件头（默认值）、1 代表当前位置、2 代表文件尾。
    offset：表示相对于 whence 位置文件指针的偏移量，正数表示向后偏移，负数表示向前偏移。
            例如：
                当whence == 0 && offset == 3（即seek(3,0)），表示文件指针移动至距离文件开头处 3 个字符的位置；
                当whence == 1 && offset == 5（即seek(5,1)），表示文件指针向后移动，移动至距离当前位置5个字符处；
                当whence == 2 && offset == -5（即seek(-5,2)），表示文件指针向前移动，从文件末尾向前移动5个字符。
    :param lines: 要读取的行数
    :param filepath: 文件路径
    :param off: 读取的字符数
    :return:
    """
    linenumber = get_line_count(filepath)
    with open(filepath, 'rb') as f:
        while True:
            f.seek(off, 2)
            res = f.readlines()
            if len(res) > lines:
                for i in range(1, len(res)):
                    print(linenumber - lines + i, res[i].decode(), end="")
                break
            off += -50


# 读取文件最后几行，方式二：使用linecache模块
def readline(lines, filepath):
    linecache.clearcache()
    line_count = get_line_count(filepath)
    line_count = line_count - (lines - 1)
    for i in range(lines):
        last_line = linecache.getline(filepath, line_count)
        print(line_count, last_line, end="")
        line_count += 1


def readfile(start, end, filepath):
    """
    :param start: 开始行
    :param end: 结束行
    :param filepath: 文件路径
    :return:
    """
    linecache.clearcache()
    for i in range(start, end + 1):
        last_line = linecache.getline(filepath, i)
        print(i, last_line, end="")


if __name__ == '__main__':
    # 读取第10行到第20行
    readfile(10, 20, 'readtest.log')
    # 读取最后10行
    readline(10, 'readtest.log')
    # 读取最后20行
    readfileline(20, 'readtest.log')
```

### 数据处理

读取 CSV 文件

```python
import csv
with open('data.csv', 'r') as file:
    reader = csv.reader(file)
    for row in reader:
        print(row)
```

```python
import csv

def read_csv(file_path):
  """读取 CSV 文件。
  Args:
    file_path: CSV 文件路径。
  """

  with open(file_path, 'r', encoding='utf-8') as f:
    reader = csv.reader(f)
    # 跳过标题行
    next(reader)
    for row in reader:
      print(row)

# 示例用法：读取名为 "data.csv" 的 CSV 文件
read_csv("data.csv")
```

写入 CSV 文件

```python
import csv
data = [['Name', 'Age'], ['Alice', 30], ['Bob', 25]]
with open('data.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerows(data)
```

```python
import csv

def write_csv(file_path, data):
  """将数据写入 CSV 文件。
    :file_path: CSV 文件路径。
    :data: 要写入的数据，格式为列表的列表。
  """

  with open(file_path, 'w', encoding='utf-8', newline='') as f:
    writer = csv.writer(f)
    writer.writerows(data)

# 示例用法：将数据写入名为 "data.csv" 的 CSV 文件
data = [
  ["Name", "Age", "City"],
  ["Alice", 25, "New York"],
  ["Bob", 30, "London"],
]
write_csv("data.csv", data)
```

Python 格式化 JSON 数据

```python
import json

# 示例字典
data = {"name": "\u5f20\u4e09", "age": 30, "is_student": False, "courses": ["Math", "Science"],
        "address": {"city": "上海", "zip": "10001"}}

# 格式化 JSON 字符串
# indent: 指定缩进的空格数，这里设置为 4，表示每一层级缩进四个空格。
# ensure_ascii: 设置为 False 可以让输出包含非 ASCII 字符，例如中文等，避免其被转义
formatted_json = json.dumps(data, indent=4, ensure_ascii=False)
print(formatted_json)
```

读取 JSON 文件

```python
import json
with open('data.json', 'r') as file:
    data = json.load(file)
```

写入 JSON 文件

```python
import json
data = {'name': 'Alice', 'age': 30}
with open('data.json', 'w') as file:
    json.dump(data, file)
```

常见的列表操作

```python
# 过滤列表中的重复项
my_list = [1, 2, 2, 3, 4, 4, 5]
unique_list = list(set(my_list))


# 排序列表
my_list = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]
sorted_list = sorted(my_list)

# 反转列表
my_list = [1, 2, 3, 4, 5]
reversed_list = list(reversed(my_list))

# 合并多个列表
list1 = [1, 2, 3]
list2 = [4, 5, 6]
combined_list = list1 + list2

# 获取列表中的最大值
my_list = [1, 2, 3, 4, 5]
max_value = max(my_list)

# 获取列表中的最小值
my_list = [1, 2, 3, 4, 5]
min_value = min(my_list)
```

### 网络请求与爬虫

```python
# 获取网页内容
import requests
response = requests.get('https://www.example.com')
print(response.text)


# 解析 HTML 页面
from bs4 import BeautifulSoup
soup = BeautifulSoup(response.text, 'html.parser')
titles = soup.find_all('h1')
for title in titles:
    print(title.text)

#下载图片
import requests
img_data = requests.get('http://example.com/image.jpg').content
with open('image.jpg', 'wb') as handler:
    handler.write(img_data)


# 发送 HTTP POST 请求
import requests
payload = {'key1': 'value1', 'key2': 'value2'}
response = requests.post('https://httpbin.org/post', data=payload)
print(response.text)


# 处理 JSON 响应
import requests
response = requests.get('https://api.example.com/data')
data = response.json()
print(data)


# 设置超时时间
import requests
try:
    response = requests.get('https://www.example.com', timeout=5)
except requests.Timeout:
    print("The request timed out")


# 处理异常
import requests
try:
    response = requests.get('https://www.example.com')
    response.raise_for_status()
except requests.HTTPError as http_err:
    print(f"HTTP error occurred: {http_err}")
except Exception as err:
    print(f"Other error occurred: {err}")

# 使用会话保持连接
import requests
session = requests.Session()
response = session.get('https://www.example.com')
print(response.text)


# 获取响应头信息
import requests
response = requests.get('https://www.example.com')
print(response.headers)

# 设置自定义请求头
import requests
headers = {'User-Agent': 'MyApp/1.0'}
response = requests.get('https://www.example.com', headers=headers)
print(response.text)
```

批量下载图片

> 描述：这个 Python 脚本设计用于从网站批量下载图片。它假设网站提供一个返回图片 URL 数组的 JSON API。脚本然后遍历 URL 并下载图片，将它们保存到指定的目录。

```python
# Python脚本从网站批量下载图片
import requests
def download_images(url, save_directory):
    response = requests.get(url)
    if response.status_code == 200:
        images = response.json() # 假设API返回一个图片URL的JSON数组
        for index, image_url in enumerate(images):
            image_response = requests.get(image_url)
            if image_response.status_code == 200:
                with open(f"{save_directory}/image_{index}.jpg", "wb") as f:
                    f.write(image_response.content)
```

### 自动化任务

```python
# 定时执行任务
import schedule
import time
def job():
    print("I'm working...")
schedule.every(10).seconds.do(job)
while True:
    schedule.run_pending()
    time.sleep(1)


# 发送电子邮件
import smtplib
from email.mime.text import MIMEText
msg = MIMEText('Hello, this is a test email.')
msg['Subject'] = 'Test Email'
msg['From'] = 'your_email@example.com'
msg['To'] = 'recipient@example.com'
s = smtplib.SMTP('localhost')
s.send_message(msg)
s.quit()


# 运行系统命令
import subprocess
result = subprocess.run(['ls', '-l'], stdout=subprocess.PIPE)
print(result.stdout.decode('utf-8'))



# Python脚本自动检测网络连接
import os
def check_network_connection():
    response = os.system("ping -c 1 google.com")
    if response == 0:
        return True
    else:
        return False

# Python脚本自动从URL下载文件
import requests
def download_file(url, save_path):
    response = requests.get(url)
    with open(save_path, 'wb') as f:
        f.write(response.content)


# 压缩文件
import zipfile
with zipfile.ZipFile('archive.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:
    zipf.write('file.txt')

# 解压文件
import zipfile
with zipfile.ZipFile('archive.zip', 'r') as zipf:
    zipf.extractall('extracted_files')


# 监控文件变化
import time
import os
import hashlib
def get_file_hash(filename):
    hasher = hashlib.md5()
    with open(filename, 'rb') as f:
        buf = f.read()
        hasher.update(buf)
    return hasher.hexdigest()


last_hash = None
while True:
    current_hash = get_file_hash('file.txt')
    if current_hash != last_hash:
        print("File has changed!")
        last_hash = current_hash
    time.sleep(1)

# 生成随机数
import random
random_number = random.randint(1, 100)
print(random_number)


# 生成随机字符串
import random
import string
random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=12))
print(random_string)


# 生成随机密码
import random
import string
password = ''.join(random.choices(string.ascii_letters + string.digits, k=12))
print(password)


# 这个Python脚本生成指定长度的随机文本。它可以用于测试和模拟目的，甚至可以作为创意写作的随机内容来源。
# Python脚本生成随机文本
import random
import string
def generate_random_text(length):
    letters = string.ascii_letters + string.digits + string.punctuation
    random_text = ''.join(random.choice(letters) for i in range(length))
    return random_text



# 自动化文件加密
# Python脚本自动化加密文件
# 描述：这个Python脚本自动化加密文件。它使用cryptography库加密文件内容，并将加密后的数据保存回文件。
from cryptography.fernet import Fernet
def encrypt_file(file_path, key):
    cipher = Fernet(key)
    with open(file_path, 'rb') as f:
        file_data = f.read()
    encrypted_data = cipher.encrypt(file_data)
    with open(file_path, 'wb') as f:
        f.write(encrypted_data)


#  自动化文件解密
# Python脚本自动化解密文件
# 描述：这个Python脚本自动化解密文件。它使用cryptography库解密文件内容，并将解密后的数据保存回文件。
from cryptography.fernet import Fernet
def decrypt_file(file_path, key):
    cipher = Fernet(key)
    with open(file_path, 'rb') as f:
        encrypted_data = f.read()
    decrypted_data = cipher.decrypt(encrypted_data)
    with open(file_path, 'wb') as f:
        f.write(decrypted_data)



# 读取环境变量
import os
api_key = os.getenv('API_KEY')
print(api_key)
```

### 文字处理

```python
# 统计单词数
text = "This is a test. This is only a test."
word_count = len(text.split())
print(f"Word count: {word_count}")


# 替换字符串
text = "Hello, World!"
new_text = text.replace("World", "Python")
print(new_text)

# 分割字符串
text = "apple,banana,orange"
fruits = text.split(',')
print(fruits)

# 连接字符串
fruits = ['apple', 'banana', 'orange']
text = ', '.join(fruits)
print(text)

# 检查字符串是否包含子串
text = "Hello, World!"
if "World" in text:
    print("Found 'World' in the text.")


# 将字符串转换为大写
text = "hello, world!"
upper_text = text.upper()
print(upper_text)


# 将字符串转换为小写
text = "HELLO, WORLD!"
lower_text = text.lower()
print(lower_text)

# 去除字符串首尾空格
text = "   Hello, World!   "
stripped_text = text.strip()
print(stripped_text)


# 去除字符串中所有空格
text = "Hello,   World!"
no_space_text = text.replace(" ", "")
print(no_space_text)


# 格式化字符串
name = "Alice"
age = 30
formatted_text = f"Name: {name}, Age: {age}"
print(formatted_text)
```

### 创建简单的 Web 应用

```python
from flask import Flask

app = Flask(__name__)

@app.route("/")
def hello():
  return "Hello, world!"

if __name__ == "__main__":
  app.run(debug=True)
```

- https://www.imooc.com/wiki/flasklesson/flaskintro.html

### Python 代码合集

- https://github.com/geekcomputers/Python

## 参考文献

python 自动化运维：技术与最佳实践-源码-python3 版本

- https://github.com/jumploop/pyauto-ops
