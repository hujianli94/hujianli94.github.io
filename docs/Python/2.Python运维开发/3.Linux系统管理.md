# 3.Linux 系统管理

## 1.文件读写

### 1.1 Python 内置的 open 函数

在 Python 中，要对一个文件进行操作，只需要使用内置的 open 函数打开文件即可。open 函数接受文件名和打开模式作为参数，返回一个文件对象。工程师通过文件对象来操作文件，完成以后，调用文件对象的 close 方法关闭文件即可。

例如，在当前目录下有一个名为 data.txt 的文件，它的内容如下

```text
Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
```

接下来，使用 open 函数打开文件，调用文件对象的 read 方法读取文件的所有内容，完成以后，调用文件对象的 close 方法关闭文件，如下所示：

```shell
In [1]: f = open('data.txt')

In [2]: print(f.read())
Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.


In [3]: f.close()
```

表 1-1 　文件的打开模式

| 模式 | 含义                                                                                                                                                               |
| ---- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| r    | 以只读方式打开文件。如果文件不存在，抛出 FileNotFoundError 异常                                                                                                    |
| rb   | 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。                                                                                       |
| r+   | 打开一个文件用于读写。文件指针将会放在文件的开头。                                                                                                                 |
| rb+  | 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。                                                                                                     |
| w    | 打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。                                                                                 |
| wb   | 以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。                                                                     |
| w+   | 打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。                                                                                   |
| wb+  | 以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。                                                                       |
| x    | 创建一个新文件，如果文件存在，抛出 FileExistsError 异常                                                                                                            |
| a    | 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。             |
| ab   | 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 |
| a+   | 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。                                 |
| ab+  | 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。                                             |

下面的代码分别演示，打开一个不存在的文件时'w'模式与'x'模式的区别：

```shell
In [4]: f = open('data1.txt', 'w')

In [5]: f.write('hello, world')
Out[5]: 12

In [6]: f.close()

In [7]: f = open('data1.txt', 'x')
-------------------------------------------------
FileExistsError        Traceback (most recent call last)
<ipython-input-16-e24c4c04f3d8> in <module>()
----> 1 f = open('data1.txt', 'x')

FileExistsError: [Errno 17] File exists: 'data1.txt'

In [8]: f = open('data2.txt', 'x')

In [9]: f.write('hello, world')
Out[9]: 12

In [10]: f.close()
```

### 1.2 避免文件句柄泄露

为了避免打开文件后没有及时关闭，大多数编程语言中都使用 finally 关闭文件句柄。在 Python 中，也可以使用 finally 语句来保证，无论在什么情况下文件都会被关闭。如下所示：

```python
try:
    f = open('data.txt')
    print(f.read())
finally:
    f.close()
```

如果工程师在可以使用上下文管理器的情况下，使用了 finally 语句，将会被认为代码编写得不够 Pythonic。

对于文件打开、处理、再关闭的逻辑，使用上下文管理器的代码如下：

```python
with open('data.txt') as f:
    print(f.read())
```

可以看到，使用上下文管理器以后代码行数变少了。在 Python 中，如果想把代码写得简洁优美，就应该在保证可读性的前提下代码行数越少越好。

with 工作原理

1. 紧跟 with 后面的语句被求值后，返回对象的“**enter**()”方法被调用，这个方法的返回值将被赋值给 as 后面的变量；
2. 当 with 后面的代码块全部被执行完之后，将调用前面返回对象的“**exit**()”方法。

```python
class Sample:
    def __enter__(self):
        print("in __enter__")
        return "Foo"
    def __exit__(self, exc_type, exc_val, exc_tb):
        print("in __exit__")
def get_sample():
    return Sample()
with get_sample() as sample:
    print("Sample: ", sample)
```

with 语句为上下文管理器，**enter**和 **exit**两个方法实现，使用 with 操作文件会自动关闭文件句柄，无需额外进行 file.close()

自定义文件操作的类

```python
class myopen:
    def __init__(self,path,mode='r'):
        self.path = path
        self.mode = mode

    def __enter__(self):
        print('start')
        self.f = open(self.path,mode=self.mode)
        return self.f

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.f.close()
        print('exit')

with myopen('userinfo','a') as f:
    f.write('hello,world')
```

### 1.3 常见的文件操作函数

| 文件操作        | 功能描述                                                     |
| --------------- | ------------------------------------------------------------ |
| file.read       | 读取文件中的所有内容                                         |
| file.readline   | 一次读取一行                                                 |
| file.readlines  | 将文件内容存到一个列表中，列表中的每一行对应于文件中的一行。 |
| file.write      | 写字符串到文件中，并返回写入的字符数                         |
| file.writelines | 写一个字符串列表到文件中                                     |

我们使用 data.txt 文件，分别测试这三个读函数的效果：

```python

In [1]: f = open('data.txt')

In [2]: f.read()
Out[2]: 'Beautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\n'

In [3]: f.seek(0)
Out[3]: 0

In [4]: f.readline()
Out[4]: 'Beautiful is better than ugly.\n'

In [5]: f.seek(0)
Out[5]: 0

In [6]: f.readlines()
Out[6]:
['Beautiful is better than ugly.\n',
 'Explicit is better than implicit.\n',
 'Simple is better than complex.\n',
 'Complex is better than complicated.\n']
```

这里可以看到，read 函数和 readlines 函数都是一次就将所有内容读入到内存中，对于文件较小的情况不会有什么问题。

但是，如果处理的是大文件，这种使用方式会占用大量的内存，甚至有可能因为内存占用太多出现 Out-Of-Memory 错误。

依然使用 IPython 对文件对象的写入函数进行测试，并在写入完成以后使用 Linux 的 cat 命令查看文件内容：

```python
In [1]: f = open('/tmp/data.txt', 'w')

In [2]: f.write('Beautiful is better than ugly.')
Out[2]: 30

In [3]: f.writelines(['Explicit is better than implicit.', 'Simple is better than complex.'])

In [4]: ! cat /tmp/data.txt
Beautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.
```

在 Python 中，除了使用文件对象的 write 函数和 writelines 函数向文件写入数据以外，也可以使用 print 函数将输出结果输出到文件中。print 函数比 write 和 writelines 函数更加灵活，如下所示：

```python
from __future__ import print_function

with open('/tmp/data.txt', 'w') as f:
    print(1, 2, 'hello, world', sep=",", file=f)
```

### 1.4 Python 的文件是一个可迭代对象

Python 的 for 循环比大家实际看到的还要通用，它不但可以遍历如字符串、列表、元组这样的可迭代序列，还可以使用迭代器协议遍历可迭代对象。

而 Python 的文件对象实现了迭代器协议，因此，我们可以在 for 循环中遍历文件内容。

也就是说，Python 的 for 循环使用迭代器协议访问对象，只要对象实现了迭代器协议，就可以在 Python 的 for 循环中遍历该对象。

使用 for 循环遍历文件内容的代码如下：

```python
with open('data.txt') as inf:
    for line in inf:
        print(line.upper())
```

### 1.5 案例：将文件中所有单词的首字母变成大写

```python
with open('data.txt') as inf, open('out.txt', 'w') as outf:
    for line in inf:
        outf.write(" ".join([word.capitalize() for word in line.split()]))
        outf.write("\n")
```

处理完成以后，out.txt 文件的内容如下：

```text
Beautiful Is Better Than Ugly.
Explicit Is Better Than Implicit.
Simple Is Better Than Complex.
Complex Is Better Than Complicated.
```

这个例子中，也可以使用 print 函数来简化输出语句，如下所示：

```python
from __future__ import print_function

with open('data.txt') as inf, open('out.txt', 'w') as outf:
    for line in inf:
        print(*[word.capitalize() for word in line.split()], file=outf)
```

## 2.文件与文件路径管理

介绍 os 模块的子模块 os.path，os.path 模块下的函数比较常用，而且也比较简单，很适合用来作为学习 os 模块的切入点。

| 函数                                       | 说明                                                       |
| ------------------------------------------ | ---------------------------------------------------------- |
| os.popen('id').read()                      | 执行系统命令得到返回结果                                   |
| os.system()                                | 得到返回状态 返回无法截取                                  |
| os.name                                    | 返回系统平台 Linux/Unix 用户是'posix'                      |
| os.getenv()                                | 读取环境变量                                               |
| os.putenv()                                | 设置环境变量                                               |
| os.getcwd()                                | 当前工作路径                                               |
| os.stat('path/filename')                   | 获取文件/目录信息                                          |
| os.chdir()                                 | 改变当前工作目录                                           |
| os.walk('/root/')                          | 递归路径                                                   |
| os.environ['HOME']                         | 查看系统环境变量                                           |
| os.statvfs("/")                            | 获取磁盘信息                                               |
| os.path.abspath(path)                      | 返回绝对路径                                               |
| os.path.basename(path)                     | 返回文件名                                                 |
| os.path.commonprefix(list)                 | 返回 list(多个路径)中，所有 path 共有的最长的路径          |
| os.path.dirname(path)                      | 返回文件所在路径（目录）                                   |
| os.path.dirname(os.path.abspath(**file**)) | 返回文件当前工作路径                                       |
| os.path.exists(path)                       | 路径存在则返回 True,路径损坏返回 False                     |
| os.path.lexists                            | 路径存在则返回 True,路径损坏也返回 True                    |
| os.path.expanduser(path)                   | 把 path 中包含的"~"和"~user"转换成用户目录                 |
| os.path.expandvars(path)                   | 根据环境变量的值替换 path 中包含的”$name”和”${name}”       |
| os.path.getatime(path)                     | 返回最后一次进入此 path 的时间                             |
| os.path.getmtime(path)                     | 返回在此 path 下最后一次修改的时间                         |
| os.path.getctime(path)                     | 返回 path 的大小                                           |
| os.path.getsize(path)                      | 返回文件大小，如果文件不存在就返回错误                     |
| os.path.isabs(path)                        | 判断是否为绝对路径                                         |
| os.path.isfile(path)                       | 判断路径是否为文件                                         |
| os.path.isdir(path)                        | 判断路径是否为目录                                         |
| os.path.islink(path)                       | 判断路径是否为链接                                         |
| os.path.ismount(path)                      | 判断路径是否为挂载点（）                                   |
| os.path.ismount(path)                      | 判断路径是否为挂载点（）                                   |
| os.path.join(path1[, path2[, ...]])        | 把目录和文件名合成一个路径                                 |
| os.path.normcase(path)                     | 转换 path 的大小写和斜杠                                   |
| os.path.normpath(path)                     | 规范 path 字符串形式                                       |
| os.path.realpath(path)                     | 返回 path 的真实路径                                       |
| os.path.relpath(path[, start])             | 从 start 开始计算相对路径                                  |
| os.path.samefile(path1, path2)             | 判断目录或文件是否相同                                     |
| os.path.sameopenfile(fp1, fp2)             | 判断 fp1 和 fp2 是否指向同一文件                           |
| os.path.samestat(stat1, stat2)             | 判断 stat tuple stat1 和 stat2 是否指向同一个文件          |
| os.path.split(path)                        | 把路径分割成 dirname 和 basename，返回一个元组             |
| os.path.splitdrive(path)                   | 一般用在 windows 下，返回驱动器名和路径组成的元组          |
| os.path.splitext(path)                     | 分割路径，返回路径名和文件扩展名的元组                     |
| os.path.splitunc(path)                     | 把路径分割为加载点与文件                                   |
| os.path.walk(path, visit, arg)             | 遍历 path，进入每个目录都调用 visit 函数，visit 函数必须有 |

### 2.1 使用 os.path 进行路径和文件管理

前者获取当前目录，后者用来列出目录下的所有文件和文件夹

```shell
In [1]: import os

In [2]: os.getcwd()
Out[2]: '/home/lmx/t'

In [3]: os.listdir('.')
Out[3]:
['dir1',
 'dir3',
 'c.txt',
 '2.jpg',
 'a.py',
 'a.txt',
 '1.jpg',
 'b.txt',
 'dir2',
 'access.log']
```

#### 1.拆分路径

os.path 模块用来对文件和路径进行管理，显然，它会包含很多拆分路径的函数。os.path 模块中与拆分路径相关的函数有：

- split：返回一个二元组，包含文件的路径与文件名；
- dirname：返回文件的路径；

- basename：返回文件的文件名；

- splitext：返回一个除去文件扩展名的部分和扩展名的二元组。

下面的代码测试了 split、dirname、basename 和 splitext 这几个函数的功能：

```shell
In [1]: import os

In [2]: path = "/home/lmx/t/access.log"

In [3]: os.path.split(path)
Out[3]: ('/home/lmx/t', 'access.log')

In [4]: os.path.dirname(path)
Out[4]: '/home/lmx/t'

In [5]: os.path.basename(path)
Out[5]: 'access.log'

In [6]: os.path.splitext(path)
Out[6]: ('/home/lmx/t/access', '.log')
```

#### 2.构建路径

os.path 模块也包含了用以构建路径的函数。其中最常用的便是 expanduser、abspath 和 join 函数：

- expanduser：展开用户的 HOME 目录，如~、~username；

- abspath：得到文件或路径的绝对路径；

- join：根据不同的操作系统平台，使用不同的路径分隔符拼接路径。

- pardir: 返回父级目录（..）

下面的代码演示了各个函数的用法：

```shell

In [1]: import os

In [2]: os.getcwd()
Out[2]: '/home/lmx/t'

In [3]: os.path.expanduser('~')
Out[3]: '/home/lmx'

In [4]: os.path.expanduser('~mysql')
Out[4]: '/home/mysql'

In [5]: os.path.expanduser('~lmx/t')
Out[5]: '/home/lmx/t'

In [6]: os.path.abspath('.')
Out[6]: '/home/lmx/t'

In [7]: os.path.abspath('..')
Out[7]: '/home/lmx'

In [8]: os.path.abspath('../t/a.py')
Out[8]: '/home/lmx/t/a.py'

In [9]: os.path.join('~', 't', 'a.py')
Out[9]: '~/t/a.py'

In [10]: os.path.join(os.path.expanduser('~mysql'), 't', 'a.py')
Out[10]: '/home/mysql/t/a.py'
```

前面介绍 os.path 模块构建路径时，介绍了 abspath 函数，该函数用来返回一个相对路径的绝对路径。相应的，os.path 模块也存在一个函数用来检查一个路径是否为绝对路径。

```shell
In [11]: os.path.isabs('/home/lmx/t/a.py')
Out[11]: True

In [12]: os.path.isabs('.')
Out[12]: False
```

在 Python 代码中，可以使用**file**这个特殊的变量表示当前代码所在的源文件。
在编写代码时，有时需要导入当前源文件父目录下的软件包（如编写单元测试）。因此，需要用到这里的路径函数获取源文件的父目录，如下所示：

```python
#!/usr/bin/python
#-*- coding: UTF-8 -*-
from __future__ import print_function

import os

print("current directory :", os.getcwd())
path = os.path.abspath(__file__)
print("full path of current file :", path)
print("parent directory of current file :",
        os.path.abspath(os.path.join(os.path.dirname(path), os.path.pardir)))
```

输出结果如下：

```shell
current directory : /home/lmx/t
full path of current file : /home/lmx/t/a.py
parent directory of current file : /home/lmx
```

#### 3.获取文件属性

os.path 模块也包含了若干函数用来获取文件的属性，包括文件的创建时间、修改时间、文件的大小等：

- getatime：获取文件的访问时间；

- getmtime：获取文件的修改时间；

- getctime：获取文件的创建时间；

- getsize：获取文件的大小。

#### 4.判断文件类型

os.path 模块也提供了若干函数用来判断路径是否存在，以及路径所指文件的类型，这些判断类函数一般以“is”开头，并且返回一个 Boolean 型结果。

os.path 模块提供的判断类函数包括：

- exists：参数 path 所指向的路径是否存在；

- isfile：参数 path 所指向的路径存在，并且是一个文件；

- isdir：参数 path 所指向的路径存在，并且是一个文件夹；

- islink：参数 path 所指向的路径存在，并且是一个链接；

- ismount：参数 path 所指向的路径存在，并且是一个挂载点。

充分使用 os.path 模块的函数，就能够实现很多有用的系统管理功能。例如：

1）获取当前用户 home 目录下所有的文件列表：

```python
import  os
[item for item in os.listdir(os.path.expanduser('~')) if os.path.isfile(item)]
```

2）获取当前用户 home 目录下所有的目录列表：

```python
import os
[item for item in os.listdir(os.path.expanduser('～')) if os.path.isdir(item)]
```

3）获取当前用户 home 目录下所有目录的目录名到绝对路径之间的字典：

```python
import os
{item: os.path.realpath(item) for item in os.listdir(os.path.expanduser('～')) if os.path.isdir(item)}
```

4）获取当前用户 home 目录下所有文件到文件大小之间的字典：

```python
import os
{item: os.path.getsize(item) for item in os.listdir(os.path.expanduser('～')) if os.path.isfile(item)}
```

### 2.2 使用 os 模块管理文件和目录

前面已经介绍了 getcwd 函数，该函数用来获取当前目录，与之相关的是 chdir 函数，该函数用来修改当前目录。如下所示：

```shell
In [1]: import os

In [2]: os.getcwd()
Out[2]: '/home/lmx/t'

In [3]: os.chdir(os.path.expanduser('～lmx'))

In [4]: os.getcwd()
Out[4]: '/home/lmx'
```

os 模块也包含了文件和目录的操作函数，包括创建目录、删除目录、删除文件、重命名文件等。

- unlink/remove：删除 path 路径所指向的文件；

- rmdir：删除 path 路径锁指向的文件夹，该文件夹必须为空，否则会报错；

- mkdir：创建一个文件夹；

- rename：重命名文件或文件夹。

下面的代码演示了使用 os 模块进行目录和文件管理的用法：

```shell

In [5]: ls
1.jpg  2.jpg  access.log  a.py  a.txt  b.txt  c.txt  dir1/  dir2/  dir3/

In [6]: os.remove('1.jpg')

In [7]: os.unlink('2.jpg')

In [8]: os.rmdir('dir1')

In [9]: os.removedirs('dir2')

In [10]: ls
access.log  a.py  a.txt  b.txt  c.txt  dir3/

In [11]: os.mkdir('mydir')

In [12]: ls
access.log  a.py  a.txt  b.txt  c.txt  dir3/  mydir/

In [13]: os.rename('mydir', 'newdir')

In [14]: ls
access.log  a.py  a.txt  b.txt  c.txt  dir3/  newdir/
```

#### 测试文件是否存在

```shell
>>> import os
>>> os.path.exists('/etc/passwd')
True
>>> os.path.exists('/tmp/spam')


>>> # Is a regular file
>>> os.path.isfile('/etc/passwd')
True

>>> # Is a directory
>>> os.path.isdir('/etc/passwd')
False

>>> # Is a symbolic link
>>> os.path.islink('/usr/local/bin/python3')
True

>>> # Get the file linked to
>>> os.path.realpath('/usr/local/bin/python3')
'/usr/local/bin/python3.3'

```

#### 目录文件赋权

os 模块也包含了修改文件权限、判断文件权限的函数，即 chmod 和 access。chmod 用来修改文件的权限，access 用来判断文件是否具有相应的权限。在 Linux 中，权限分为读、写和执行。

因此，os 模块也提供了三个常量来表示读、写、可执行权限，即 R_OK、W_OK 和 X_OK。

下面的程序演示了 chmod 和 access 函数的用法。首先通过命令行读取文件的名称，先判断文件是否存在，如果文件不存在，则直接退出。

然后判断文件是否具有读权限，如果没有读权限，则将文件赋予所有用户都具有读、写、执行权限。如果文件存在并且已经具有读权限，读取文件内容。

```python
#!/usr/bin/python
#-*- coding: UTF-8 -*-
from __future__ import print_function
import os
import sys

def main():
    sys.argv.append("")
    filename = sys.argv[1]
    if not os.path.isfile(filename):
        raise SystemExit(filename + ' does not exists')
    elif not os.access(filename, os.R_OK):
        os.chmod(filename, 0777)
    else:
        with open(filename) as f:
            print(f.read())

if __name__ == '__main__':
    main()
```

#### 创建目录

```python

#!/usr/bin/env python
#-*- coding:utf8 -*-
import os
#os.mkdir(path=None,mode=None)
#os.mkdir("D:\\deam")        #创建目录，如果目录存在，会抛出异常

'''
if not os.path.exists("D:\\deam"):
    os.mkdir("D:\\deam")
else:
    print("该目录已经存在！！！！")
'''


#创建一个递归函数，用于创建目录
def mkdir(path):    #创建一个递归函数用于创建目录
    if not os.path.isdir(path):  #判断是否为路径
        mkdir(os.path.split(path)[0])
    else:
        return
    os.mkdir(path)      #创建目录

mkdir('D:\\deam\\test\\aaa')


#创建多级目录的函数
#os.makedirs()
"""makedirs(name [, mode=0o777][, exist_ok=False])"""
os.makedirs("D:\\deam\\test\\bbb")

```

```python
#!/usr/bin/env python
#-*- coding:utf8 -*-
import os
#获取当前的目录
print("当前目录是:{}".format(os.getcwd()))


#获取目录中的内容
print("目录中的内容有：{}".format(os.listdir()))


#创建目录
if not os.path.exists("test_hu"):
    print("开始创建目录.....test_hu")
    os.mkdir("test_hu")
else:
    print("目录中的内容有：{}".format(os.listdir()))

#删除目录
print("开始删除目录......test_hu",)
os.rmdir("test_hu")
print("目录中的内容有：{}".format(os.listdir()))

os.mkdir("test_hu")
#判断是否是目录
print("判断是否是目录？")
print(os.path.isdir("test_hu"))
print(os.path.isdir("fab.txt"))

#判断是否是文件
print("判断是否为文件?")
with open("fab1.txt","w+") as f:
    f.write("hello this is file test")
print(os.path.isfile("fab1.txt"))
print(os.path.isfile("test_hu"))
```

#### 删除目录

```python
#!/usr/bin/env python
#-*- coding:utf8 -*-
#删除目录
import os,shutil
'''
if os.path.exists("D:\deam\\test\\bbb"):
    os.rmdir("D:\deam\\test\\bbb")

if os.path.exists("D:\deam"):
    os.rmdir("D:\\deam")
'''
aaa_path = "D:\deam\\test\\aaa"
if os.path.exists(aaa_path):
    shutil.rmtree("D:\deam\\test\\aaa")
else:
    print("目录不存在！！！")

shutil.rmtree(path)
```

永久删除文件或文件夹

```python
os.rmdir(path)      # 将删除 path 处的文件夹。该文件夹必须为空，其中没有任何文件和文件夹。
os.remove()         # 删除单一文件



# 一般使用如下：
os.unlink(path)         # 将删除 path 处的文件
shutil.rmtree(path)     # 将删除 path 处的文件夹，它包含的所有文件和文件夹都会被删除,无论目录或文件夹是否为空
```

删除文件之前，最好先进行`print()`打印,防止误删除。

```python
import os
for filename in os.listdir():
    if filename.endswith('.rxt'):
        #os.unlink(filename)
        print(filename)
```

### 2.3 案例: 打印最常用的 10 条 Linux 命令

~/.bash_history 文件保存了命令的历史，因此，我们可以使用该文件获取命令的列表统计命令的执行次数。

在统计时，我们只统计命令的名称即可，以不同的参数调用相同的命令也认为是同一个命令。下面的程序用来统计每条命令的出现次数，然后找出出现次数最多的 10 条命令。如下所示：

```shell
In [1]: import os

In [2]: from collections import Counter

In [3]: c = Counter()

In [4]: with open(os.path.expanduser('~/.bash_history')) as f:
   ...:     for line in f:
   ...:         cmd = line.strip().split()
   ...:         if cmd:
   ...:             c[cmd[0]]+=1
   ...:

In [5]: c.most_common(10)
Out[5]:
[('ls', 116),
 ('vi', 55),
 ('cd', 47),
 ('fab', 32),
 ('cat', 25),
 ('python', 13),
 ('ps', 13),
 ('ssh', 11),
 ('pwd', 11),
 ('vim', 11)]
```

## 2.4 案例: 用 Python 来创建 7 种不同的文件格式

!!! info "参考文献"

    [用Python来创建7种不同的文件格式](https://www.yuque.com/fcant/python/ixif7it5bvucmsxy#idYu1)

## 3.查找文件

使用 Python 查找特定类型的文件，包括使用字符串匹配文件名的标准库 fnmatch 和 glob，还有遍历目录树的函数 os.walk。

### 3.1 使用 fnmatch 找到特定的文件

获取文件夹中的文件列表

使用`os.listdir()`函数来获取某个目录中的文件列表：

```python
import os
names = os.listdir('somedir')
```

结果会返回目录中所有文件列表，包括所有文件，子目录，符号链接等等。 如果你需要通过某种方式过滤数据，可以考虑结合 os.path 库中的一些函数来使用列表推导。比如：

```python

import os.path

# Get all regular files
names = [name for name in os.listdir('somedir')
        if os.path.isfile(os.path.join('somedir', name))]

# Get all dirs
dirnames = [name for name in os.listdir('somedir')
        if os.path.isdir(os.path.join('somedir', name))]
```

字符串的`startswith()`和`endswith()`方法对于过滤一个目录的内容也是很有用的。比如：

```python
pyfiles = [name for name in os.listdir('somedir')
            if name.endswith('.py')]
```

对于文件名的匹配,使用 fnmatch 模块。

比如：

```python
from fnmatch import fnmatch
pyfiles = [name for name in os.listdir('somedir')
            if fnmatch(name, '*.py')]
```

Python fnmatch 模块常用函数及功能

| 函数名                                              | 功能                                                                      |
| --------------------------------------------------- | ------------------------------------------------------------------------- |
| fnmatch.filter(names, pattern)                      | 对 names 列表进行过滤，返回 names 列表中匹配 pattern 的文件名组成的子集合 |
| fnmatch.fnmatch(filename, pattern)                  | 判断 filename 文件名，是否和指定 pattern 字符串匹配                       |
| fnmatch.fnmatchcase(filename, pattern) 和 fnmatch() | 函数功能大致相同，只是该函数区分大小写                                    |
| fnmatch.translate(pattern)                          | 将一个 UNIX shell 风格的 pattern 字符串，转换为正则表达式                 |

fnmatch 和 fnmatchcase 的使用

```shell
In [1]: from fnmatch import fnmatch, fnmatchcase

In [2]: fnmatch('foo.txt', '*.txt')
Out[2]: True

In [3]: fnmatch('foo.txt', '?oo.txt')
Out[3]: True

In [4]: fnmatch('Dat45.csv', 'Dat[0-9]*')
Out[4]: True

In [5]: fnmatchcase('foo.txt', '*.TXT')
Out[5]: False

In [6]: addresses = [
   ...:     '5412 N CLARK ST',
   ...:     '1060 W ADDISON ST',
   ...:     '1039 W GRANVILLE AVE',
   ...:     '2122 N CLARK ST',
   ...:     '4802 N BROADWAY',
   ...: ]

In [7]: [addr for addr in addresses if fnmatchcase(addr, '* ST')]
Out[7]: ['5412 N CLARK ST', '1060 W ADDISON ST', '2122 N CLARK ST']

In [8]: [addr for addr in addresses if fnmatchcase(addr, '54[0-9][0-9] *CLARK*')]
Out[8]: ['5412 N CLARK ST']

```

fnmatchcase 举例

```shell
In [1]: !touch {a..b}1.txt {c..d}2.jpg

In [2]: ls
a1.txt  b1.txt  c2.jpg  d2.jpg

In [3]: import os

In [4]: os.listdir('.')
Out[4]: ['c2.jpg', 'b1.txt', 'd2.jpg', 'a1.txt']

In [5]: import fnmatch

In [6]: [ name for name in os.listdir('.') if fnmatch.fnmatch(name, "*.jpg")]
Out[6]: ['c2.jpg', 'd2.jpg']

In [7]: [ name for name in os.listdir('.') if fnmatch.fnmatch(name, '[a-c]*')]
Out[7]: ['c2.jpg', 'b1.txt', 'a1.txt']

In [8]: [ name for name in os.listdir('.') if fnmatch.fnmatch(name, '[a-c]?.txt')]
Out[8]: ['b1.txt', 'a1.txt']

In [9]: [ name for name in os.listdir('.') if fnmatch.fnmatch(name, '[!a-c]*')]
Out[9]: ['d2.jpg']
```

filter 使用举例

```shell
In [1]: import os

In [2]: name = os.listdir('.')

In [3]: name
Out[3]: ['c2.jpg', 'b1.txt', 'd2.jpg', 'a1.txt']

In [4]: from fnmatch import filter

In [5]: filter(name,'[a-c]?.txt')
Out[5]: ['b1.txt', 'a1.txt']

In [6]: filter(name,'[!a-c]*')
Out[6]: ['d2.jpg']

```

!!! info "更多参考文档"

    [fnmatch — Unix-style Glob Pattern Matching](https://pymotw.com/3/fnmatch/index.html)

    [用Shell通配符匹配字符串](https://python3-cookbook.readthedocs.io/zh_CN/latest/c02/p03_match_strings_with_shell_wildcard.html?highlight=fnmatch)

### 3.2 使用 glob 找到特定文件

目前我们要获取到特定类型的文件列表，我们首先通过 os.listdir 获取文件列表，然后通过字符串匹配或者使用 fnmatch 进行文件名模式匹配进行过来，而在 Python 中海油更加简单的方式，即使用标准库的 glob 库。

glob 库的作用相当于 os.listdir 加上 fnmatch。使用 glob 以后，不需要调用 os.listdir 获取文件列表，直接通过模式匹配即可，如下所示

```shell
#!/usr/bin/env python
# -*- coding:utf8 -*-
# auther; 18793
# Date：2020/3/19 20:57
# filename: glob模块.py
"""
使用glob以后，不需要调用os.listdir获取文件列表，直接通过模式匹配即可。
"""
import glob

print(glob.glob("*.txt"))
print(glob.glob("[a-z]?.txt"))
print(glob.glob("[!a-z]?.txt"))

```

如果目录包含以.开头的文件。默认将不会匹配到它们。例如，一个包含 card.gif 和.card.gif 的目录：

```shell
>>> import glob
>>> glob.glob('*.gif')
['card.gif']
>>> glob.glob('.c*')
['.card.gif']
```

可以看到，Python 非常灵活，仅仅是找到目录下特定的文件类型，我们就已经使用了
三种不同的方式来匹配文件，分别是字符串后缀匹配，fnmatch 模式匹配和 glob 模式匹配。

虽然字符串后缀匹配功能有限，但是，由于大部分情况下需求比较简单，Python 工程师也
对 Pythor 的字符串函数比较熟悉，所以成为了使用最广泛的方式。

如果需要更加灵活的匹配文件名方式，可以使用 fnmath 和 glob。

!!! info "更多参考文档"

    [glob — Filename Pattern Matching](https://pymotw.com/3/glob/index.html)

### 3.3 使用 os.walk 遍历目录树

前面的例子都是查找某一个目录下的文件并通过模式匹配去选择自己需要的文件类型。

在实际工作过程中，更有可能遇到的是查找某个目录及其子目录下的所有文件。例如，查找某个目录及其子目录下所有的图片文件，查找某个目录及其子目录下最大的十个文件。

对于这类需求，可以使用 os 模块的 walk 函数。

walk 函数遍历某个目录及其子目录，对于每一个目录，walk 返回一个三元组(dirpath,dirnames,filenames)。

- dirpath 保存的是当前目录

- dirnames 是当前目录下的子目录列表

- filenames 是当前目录下的文件列表。

```python
#!/usr/bin/env python
#-*- coding:utf8 -*-
import os
#os.walk(top, topdown=True, onerror=None, followlinks=False)
'''
   dirpath, dirnames, filenames

    dirpath is a string, the path to the directory.
    dirnames is a list of the names of the subdirectories in dirpath (excluding '.' and '..').
    filenames is a list of the names of the non-directory files in dirpath.
'''
path = r"D:\Cisco_iso"
print("【", path, "】目录下包含的文件和目录：")

for root,dirs,files in os.walk(path,topdown=True):  #遍历指定目录
    for name in dirs:
        print(os.path.join(root, name))      #输出遍历到的目录
    for name in files:
        print('\t', os.path.join(root, name))      #输出遍历到的文件
```

下面的代码演示了 os.walk 函数的用法，使用 os.walk 函数遍历`/tmp/code-sample`目录及其子目录，并找到所有的图片文件：

```python
import os
import fnmatch

images = ['*.png', '*.jpg', '*.jpeg', '*.tif', '*.tiff']

matches = []

for root, dirnames, filenames in os.walk(os.path.expanduser('/tmp/code-sample')):
    for image in images:
        for filenname in fnmatch.filter(filenames, image):
            matches.append(os.path.join(root,filenname))


print(matches)

```

在遍历目录及其子目录时，如果想要忽略掉某一个子目录，可以直接修改三元组中的 dirnames,即从 dirnames 列表中移除需要忽略掉的目录。如下所示：

```python
import os
import fnmatch

images = ['*.png', '*.jpg', '*.jpeg', '*.tif', '*.tiff']

matches = []

for root, dirnames, filenames in os.walk(os.path.expanduser('/tmp/code-sample')):
    # 忽略掉某些目录
    if "aaa" in dirnames:
        dirnames.remove('aaaa')
    .....
```

#### 目录迭代的两种方式

方式 1-采用 os.listdir 递归调用

```python
#!/usr/bin/env python
#-*- coding:utf8 -*-
import os
import os.path

def traverse(pathname):
    for item in os.listdir(pathname):
        fullitem = os.path.join(pathname,item)
        print(fullitem)
        if os.path.isdir(fullitem):
            traverse(fullitem)
traverse("D:\GitHub")
```

方式 2-采用 os.walk 方式

```python
#!/usr/bin/env python
#-*- coding:utf8 -*-
import os
import os.path

def trav_walk(pathname):
    '''
    root:当前目录
    dirs：当前目录下的子目录
    files：目录下的所有文件
    '''
    for root,dirs,files in os.walk(pathname):
        for file in files:
            fname = os.path.abspath(os.path.join(root,file))
            print(fname)

trav_walk("D:\GitHub")
```

#### 案例: 文件属性浏览

- 遍历 path 指定的目录，获取每个子目录的路径。

- 遍历子目录下所有文件，返回文件的属性列表。

- 分解属性列表，对属性列表进行格式化输出

```python
#!/usr/bin/env python
# -*- coding:utf8 -*-
# auther; 18793
# Date：2019/7/20 14:56
# filename: 查看所有文件的属性.py


def ShowFileProperties(path):
    """
    显示文件属性，包括路径、大小、创建日期、最后修改时间、最后访问时间
    :param path:
    :return:
    """
    import os, time
    for root, dirs, files in os.walk(path, True):
        print("位置：" + root)
        for filename in files:
            state = os.stat(os.path.join(root, filename))
            info = "文件名：" + filename + " "
            info = info + "大小：" + ("%d" % state[-4]) + " "
            t = time.strftime("%Y-%m-%d %X", time.localtime(state[-1]))
            info = info + "创建时间：" + t + " "
            t = time.strftime("%Y-%m-%d %X", time.localtime(state[-2]))
            info = info + "修改时间：" + t + " "
            t = time.strftime("%Y-%m-%d %X", time.localtime(state[-3]))
            info = info + "最后访问时间：" + t + " "
            print(info)


if __name__ == '__main__':
    path = r"D:\GitHub\21_staduy_python\13.python文件操作\基本文件操作"
    ShowFileProperties(path)
```

#### 案例: 找到目录下最大最老的十个文件

```python
#!/usr/bin/env python
# -*- coding:utf8 -*-
# auther; 18793
# Date：2020/3/19 21:16
# filename: main.py
import os
import fnmatch
import time


def is_file_match(filename, patterns):
    for pattern in patterns:
        if fnmatch.fnmatch(filename, pattern):
            return True
    return False


def find_specific_files(root, patterns=['*'], exclude_dirs=[]):
    '''
    :param root: 查找的根路径
    :param patterns:匹配的文件模式列表
    :param exclude_dirs:需要排除的目录列表
    :return:
    '''
    for root, dirnames, filenames in os.walk(root):
        for filename in filenames:
            if is_file_match(filename, patterns):
                yield os.path.join(root, filename)
        for d in exclude_dirs:
            if d in dirnames:
                dirnames.remove(d)


if __name__ == '__main__':
    # 查到目录下的所有文件
    for item in find_specific_files("../"):
        print(item)

    # 查找目录下的所有py和txt文件
    patterns = ['*.txt', '*.py']
    for item in find_specific_files("../", patterns):
        print(item)

    # 查找目录下除了dir目录以外其他目录下的所有文件
    patterns = ['*.txt', '*.py']
    exclude_dirs = ['dir']
    for item in find_specific_files("../", patterns, exclude_dirs):
        print(item)

    # 找到某个目录及子目录下最老的十个文件
    files = {name: os.path.getmtime(name) for name in find_specific_files("../")}
    result = sorted(files.items(), key=lambda d: d[1])[:10]
    for i, t in enumerate(result, 1):
        print(i, t[0], time.ctime(t[1]))

    # 找到某个目录及子目录下，所有文件名包含“python”的文件
    file2 = [name for name in find_specific_files("../", patterns=['*python*'])]
    for i, name in enumerate(file2, 1):
        print(i, name)

    # 找到某个目录及子目录下，排除.git子目录以后所有的Python文件
    file3 = [name for name in find_specific_files("../", patterns=['*.py'], exclude_dirs=['.git'])]
    for i, name in enumerate(file3, 1):
        print(i, name)

    # 删除某个目录及子目录下的所有pyc文件
    file4 = [name for name in find_specific_files("../", patterns=['*.pyc'])]
    for name in file4:
        os.remove(name)
```

## 4.高级文件处理接口 shutil

Shutil 模块包括高级文件操作，如复制和归档。

### 4.1 复制文件

#### copyfile 方法

```python
# shutil_copyfile.py
import glob
import shutil

print('BEFORE:', glob.glob('shutil_copyfile.*'))

shutil.copyfile('shutil_copyfile.py', 'shutil_copyfile.py.copy')

print('AFTER:', glob.glob('shutil_copyfile.*'))
```

#### copy 方法

类似于 UNIX 命令行工具 cp,Copy()函数会用同样的方式解释输出名。

如果指定的目标指示一个目录而不是一个文件，则会使用源文件的基名在该目录中创建一个新文件。

```python
# shutil_copy.py
import glob
import os
import shutil

os.mkdir('example')
print('BEFORE:', glob.glob('example/*'))

shutil.copy('shutil_copy.py', 'example')

print('AFTER :', glob.glob('example/*'))
```

#### copy2 方法

copy2()的工作类似于 copy(),不过会在复制到新文件的元数据中包含访问和修改时间。

```python
# shutil_copy2.py
import os
import shutil
import time


def show_file_info(filename):
    stat_info = os.stat(filename)
    print('  Mode    :', oct(stat_info.st_mode))
    print('  Created :', time.ctime(stat_info.st_ctime))
    print('  Accessed:', time.ctime(stat_info.st_atime))
    print('  Modified:', time.ctime(stat_info.st_mtime))


os.mkdir('example')
print('SOURCE:')
show_file_info('shutil_copy2.py')

shutil.copy2('shutil_copy2.py', 'example')

print('DEST:')
show_file_info('example/shutil_copy2.py')
```

#### copymode 方法

默认地，在 UNIX 下创建一个新文件时，它会根据当前用户的 umask 接受权限。

要把权限从一个文件复制到另一个文件，可以使用 copymode()。

```python

# shutil_copymode.py
import os
import shutil
import subprocess

with open('file_to_change.txt', 'wt') as f:
    f.write('content')
os.chmod('file_to_change.txt', 0o444)

print('BEFORE:', oct(os.stat('file_to_change.txt').st_mode))

shutil.copymode('shutil_copymode.py', 'file_to_change.txt')

print('AFTER :', oct(os.stat('file_to_change.txt').st_mode))
```

#### copytree 方法

```shell
# ls
a.py  dir1

In [1]: import shutil

In [2]: shutil.copy('a.py','b.py')
Out[2]: 'b.py'

In [3]: !ls
a.py  b.py  dir1

In [6]: shutil.copytree('dir1','dir2')
Out[6]: 'dir2'

In [7]: !ls
a.py  b.py  dir1  dir2
```

```python
shutil_copytree.py
import glob
import pprint
import shutil

print('BEFORE:')
pprint.pprint(glob.glob('/tmp/example/*'))

shutil.copytree('../shutil', '/tmp/example')

print('\nAFTER:')
pprint.pprint(glob.glob('/tmp/example/*'))
```

### 4.2 move

这个函数等同于 Linux 上的 move。文件和文件夹的移动和改名

```shell

In [1]: import shutil

In [2]:

In [2]: shutil.move("a.py","a1.py")
Out[2]: 'a1.py'

In [3]: !ls
a1.py  dir1

In [4]: shutil.move("a1.py","/tmp/")
Out[4]: '/tmp/a1.py'

In [5]: !ls /tmp/a1.py
/tmp/a1.py

```

### 4.3 删除目录

在 Python 中，如果要删除文件，可以使用 os 模块的 remove 和 unlink 函数，如果要删除目录，可以使用 os 模块的 rmdir 和 removedirs 函数。

那么，为什么 shutil 模块还会提供一个名为 rmtree 的函数呢？

主要是因为 os.rmdir 和 removedirs 都要求被删除的目录非空，不能进行强制删除。

而 shutil.rmtree 不管目录是否非空，都直接删除整个目录。

因此，在笔者的使用过程中一般使用 os.unlink 删除单个文件，使用 shutil.rmtree 删除整个目录。如下所示：

```shell

In [1]: import shutil

In [2]: import os

In [3]: os.unlink('shutil_make_archive.py')

In [4]: !ls
dir1  example.tar.gz

In [5]: os.rmdir('dir1')
---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
<ipython-input-5-fc3e3e614220> in <module>
----> 1 os.rmdir('dir1')

OSError: [Errno 39] Directory not empty: 'dir1'

In [6]: shutil.rmtree('dir1')

In [7]: !ls
example.tar.gz
```

### 4.4 归档压缩

#### 压缩

可以使用 make archive()创建一个新的归档文件。

它的输入被设计为能最好地支持将整个目录及其所有内容递归地归档。

默认地会使用当前工作目录，所以所有文件和子目录出现在归档文件的顶层。

要改变这种行为，可以使用 root dir 参数移至文件系统中的一个新的相对位置，另外可以用 base dir 参数指定一个目录增加到归档。

```python
# shutil_make_archive.py
import logging
import shutil
import sys
import tarfile

# 日志消息将被输出到标准输出流 (sys.stdout) 中，并且日志级别设置为 logging.DEBUG。
logging.basicConfig(
    format='%(message)s',
    stream=sys.stdout,
    level=logging.DEBUG,
)
logger = logging.getLogger('pymotw')

print('Creating archive:')
shutil.make_archive(
    'example', 'gztar',
    root_dir='.',
    base_dir='example',
    logger=logger,
)

print('\nArchive contents:')
with tarfile.open('example.tar.gz', 'r') as t:
    for n in t.getnames():
        print(n)
```

这个例子从示例源文件所在的目录开始，在文件系统中所在目录；然后将这个 example 目录增加到一个 tar 归档，'并用 gzip 压缩。

logging 模块被配置为显示 make_archive()中操作的有关消息。

#### 解压缩

```python
# shutil_unpack_archive.py
import pathlib
import shutil
import sys
import tempfile

with tempfile.TemporaryDirectory() as d:
    print('Unpacking archive:')
    shutil.unpack_archive(
        'example.tar.gz',
        extract_dir=d,
    )

    print('\nCreated:')
    prefix_len = len(d) + 1
    for extracted in pathlib.Path(d).rglob('*'):
        print(str(extracted)[prefix_len:])
```

上面的代码将文件解压到一个临时目录中，该临时目录由`tempfile.TemporaryDirectory()`函数创建。

临时目录是在 with 语句块内部创建的，并且在退出 with 语句块时自动清理和删除。

!!! info "更多参考文档"

    [shutil — High-level File Operations](https://pymotw.com/3/shutil/index.html)

## 5.文件内容管理

使用 filecmp_mkexamples.py 创建一组测试文件。

```python
# -*- coding:utf8 -*-
# @Time    : 2023/8/7 16:49
# @Author  : 18793
# @File    : filecmp_mkexamples.py
# @Software: PyCharm
# @Desc    :
import os


def mkfile(filename, body=None):
    with open(filename, 'w') as f:
        f.write(body or filename)
    return


def make_example_dir(top):
    if not os.path.exists(top):
        os.mkdir(top)
    curdir = os.getcwd()
    os.chdir(top)

    os.mkdir('dir1')
    os.mkdir('dir2')

    mkfile('dir1/file_only_in_dir1')
    mkfile('dir2/file_only_in_dir2')

    os.mkdir('dir1/dir_only_in_dir1')
    os.mkdir('dir2/dir_only_in_dir2')

    os.mkdir('dir1/common_dir')
    os.mkdir('dir2/common_dir')

    mkfile('dir1/common_file', 'this file is the same')
    os.link('dir1/common_file', 'dir2/common_file')

    mkfile('dir1/contents_differ')
    mkfile('dir2/contents_differ')
    # Update the access and modification times so most of the stat
    # results will match.
    st = os.stat('dir1/contents_differ')
    os.utime('dir2/contents_differ', (st.st_atime, st.st_mtime))

    mkfile('dir1/file_in_dir1', 'This is a file in dir1')
    os.mkdir('dir2/file_in_dir1')

    os.chdir(curdir)
    return


if __name__ == '__main__':
    os.chdir(os.path.dirname(__file__) or os.getcwd())
    make_example_dir('example')
    make_example_dir('example/dir1/common_dir')
    make_example_dir('example/dir2/common_dir')

```

运行该脚本会在目录示例下生成一个文件树:

```shell
tree example/
example/
├── dir1
│   ├── common_dir
│   │   ├── dir1
│   │   │   ├── common_dir
│   │   │   ├── common_file
│   │   │   ├── contents_differ
│   │   │   ├── dir_only_in_dir1
│   │   │   ├── file_in_dir1
│   │   │   └── file_only_in_dir1
│   │   └── dir2
│   │       ├── common_dir
│   │       ├── common_file
│   │       ├── contents_differ
│   │       ├── dir_only_in_dir2
│   │       ├── file_in_dir1
│   │       └── file_only_in_dir2
│   ├── common_file
│   ├── contents_differ
│   ├── dir_only_in_dir1
│   ├── file_in_dir1
│   └── file_only_in_dir1
└── dir2
    ├── common_dir
    │   ├── dir1
    │   │   ├── common_dir
    │   │   ├── common_file
    │   │   ├── contents_differ
    │   │   ├── dir_only_in_dir1
    │   │   ├── file_in_dir1
    │   │   └── file_only_in_dir1
    │   └── dir2
    │       ├── common_dir
    │       ├── common_file
    │       ├── contents_differ
    │       ├── dir_only_in_dir2
    │       ├── file_in_dir1
    │       └── file_only_in_dir2
    ├── common_file
    ├── contents_differ
    ├── dir_only_in_dir2
    ├── file_in_dir1
    └── file_only_in_dir2
```

### 5.1 目录和文件比较

#### cmp

cmp 用于比较系统上的两个文件

```python
# filecmp_cmp.py
import filecmp

print('common_file    :', end=' ')
print(filecmp.cmp('example/dir1/common_file',
                  'example/dir2/common_file',
                  shallow=True),
      end=' ')
print(filecmp.cmp('example/dir1/common_file',
                  'example/dir2/common_file',
                  shallow=False))

print('contents_differ:', end=' ')
print(filecmp.cmp('example/dir1/contents_differ',
                  'example/dir2/contents_differ',
                  shallow=True),
      end=' ')
print(filecmp.cmp('example/dir1/contents_differ',
                  'example/dir2/contents_differ',
                  shallow=False))

print('identical      :', end=' ')
print(filecmp.cmp('example/dir1/file_only_in_dir1',
                  'example/dir1/file_only_in_dir1',
                  shallow=True),
      end=' ')
print(filecmp.cmp('example/dir1/file_only_in_dir1',
                  'example/dir1/file_only_in_dir1',
                  shallow=False))
```

shallow 参数告诉 cmp()除了文件的元数据外，是否还要查看文件的内容。默认情
况下，会使用由 0s.stat()得到的信息来完成一个浅比较。

如果结果是一样的，则认为文件相同。

因此，对于同时创建的相同大小的文件，即使它们的内容不同，也会报告为是相同的文件。当 shallow 为 False 时，则要比较文件的内容。

```shell
$ python3 filecmp_cmp.py
common_file    : True True
contents_differ: True False
identical      : True True
```

#### cmpfiles

```python
# filecmp_cmpfiles.py
import filecmp
import os

# Determine the items that exist in both directories
d1_contents = set(os.listdir('example/dir1'))
d2_contents = set(os.listdir('example/dir2'))
common = list(d1_contents & d2_contents)
common_files = [
    f
    for f in common
    if os.path.isfile(os.path.join('example/dir1', f))
]
print('Common files:', common_files)

# Compare the directories
match, mismatch, errors = filecmp.cmpfiles(
    'example/dir1',
    'example/dir2',
    common_files,
)
print('Match       :', match)
print('Mismatch    :', mismatch)
print('Errors      :', errors)
```

cmpfiles()返回 3 个文件名列表，分别包含匹配的文件、不匹配的文件和不能比较的文件（由于权限问题或出于其他原因）。

```shell
$ python3 filecmp_cmpfiles.py
Common files: ['contents_differ', 'file_in_dir1', 'common_file']
Match       : ['contents_differ', 'common_file']
Mismatch    : ['file_in_dir1']
Errors      : []
```

#### dircmp 类

前面介绍的函数适合完成相对简单的比较。对于大目录树的递归比较或者更完整的分析，dircmp 类会更有用。
在最简单的用例中，report()会打印比较两个目录的报告。

```python
# filecmp_dircmp_report.py
import filecmp

dc = filecmp.dircmp('example/dir1', 'example/dir2')
dc.report()
```

```shell
$ python3 filecmp_dircmp_report.py

diff example/dir1 example/dir2
Only in example/dir1 : ['dir_only_in_dir1', 'file_only_in_dir1']
Only in example/dir2 : ['dir_only_in_dir2', 'file_only_in_dir2']
Identical files : ['common_file']
Differing files : ['contents_differ']
Common subdirectories : ['common_dir']
Common funny cases : ['file_in_dir1']
```

为了更多的细节，也为了完成一个递归比较，可以使用 report_full_closure():

```python
import filecmp

dc = filecmp.dircmp('example/dir1', 'example/dir2')
dc.report_full_closure()
```

#### 案例: 文件与目录差异对比方法

Python 的标准库 filecmp 模块可以实现文件、目录、遍历子目录的差异对比功能。

```python
#!/usr/bin/env python
# -*- coding:utf8 -*-
# auther; 18793
# Date：2019/8/17 10:18
# filename: 校验源与备份目录差异.py
import os, sys
import filecmp
import re
import shutil

PWd_path = os.path.abspath(os.path.dirname(__file__))

# 创建一个空列表
holderlist = []


def compareme(dir1, dir2):
    """
    递归获取更新项函数
    :param dir1: source dir
    :param dir2: target dir
    :return:
    """
    dircomp = filecmp.dircmp(dir1, dir2)
    only_in_one = dircomp.left_only  # 源目录新文件或目录
    diff_in_one = dircomp.diff_files  # 不匹配文件，源目录已经发生变化
    dirpath = os.path.abspath(dir1)  # 获取源目录绝对路径
    [holderlist.append(os.path.abspath(os.path.join(dir1, x))) for x in only_in_one]
    [holderlist.append(os.path.abspath(os.path.join(dir1, x))) for x in diff_in_one]
    if len(dircomp.common_dirs) > 0:
        for item in dircomp.common_dirs:
            compareme(os.path.abspath(os.path.join(dir1, item)), \
                      os.path.abspath(os.path.join(dir2, item)))
            return holderlist
    else:
        return holderlist


def main():
    # if len(sys.argv) > 2:
    #     # dir1 = sys.argv[1]
    #     dir1 = "D:/1.学习知识待整理\DevOps自动化运维/https-github.com-yorkoliu-pyauto-master/第二章/filecmp/dir1"
    #     # dir2 = sys.argv[2]
    #     dir2 = "D:/1.学习知识待整理\DevOps自动化运维/https-github.com-yorkoliu-pyauto-master/第二章/filecmp/dir2"
    # else:
    #     print("Usage: ", sys.argv[0], "datadir backupdir")
    #     sys.exit()

    dir1 = PWd_path + "/dir1/"
    dir2 = PWd_path + "/dir2/"
    source_files = compareme(dir1, dir2)

    if not dir2.endswith('/'): dir2 = dir2 + '/'
    dir1 = dir1.replace("\\", "/")
    dir2 = dir2.replace("\\", "/")
    destination_files = []
    createdir_bool = False
    #
    for item in source_files:
        item = item.replace("\\", "/")
        # print(dir1, dir2, item)
        destination_dir = re.sub(dir1, dir2, item)
        destination_files.append(destination_dir)
        # print(destination_files)
        if os.path.isdir(item):
            if not os.path.exists(destination_dir):
                os.makedirs(destination_dir)
                createdir_bool = True

    if createdir_bool:
        destination_files = []
        source_files = []
        source_files = compareme(dir1, dir2)
        for item in source_files:
            destination_dir = re.sub(dir1, dir2, item)
            destination_files.append(destination_dir)

    print("update item:")
    print("---------------------------------------")
    print(source_files)     # 输出更新列表清单
    print("---------------------------------------")

    #
    copy_pair = zip(source_files, destination_files)
    for item in copy_pair:
        if os.path.isfile(item[0]):
            shutil.copyfile(item[0], item[1])


if __name__ == '__main__':
    main()
```

### 5.2 MD5 校验比较

MD5 哈希一般用于检查文件完整性，尤其常用于检测文件传输、磁盘错误或其他情况下文件的正确性。

在 Linux 下计算一个文件的 MD5 校验码，只需要以文件名为参数调用 md5sum 命令即可。如下所示：

```shell
md5sum /etc/passwd
a511925e8fece8970fd45f4c49e4b3a7    /etc/passwd
```

在 Python 中计算文件的 MD5 校验码也非常简单，使用标准库中的 hashlib 模块即可。如下所示：

md5 加密

```python
#!/usr/bin/env python
# -*- coding:utf8 -*-
# auther; 18793
# Date：2020/3/20 10:19
# filename: sample01.py
import hashlib
d = hashlib.md5()

with open("passwd.txt") as f:
    # d.update(f.read().encode("utf-8"))
    for line in f:
        d.update(line.encode("utf-8"))

print(d.hexdigest())
```

获取文件的 MD5

```python
import os
import hashlib

def md5sum(filename):
  """
  用于获取文件的md5值
  :param filename: 文件名
  :return: MD5码
  """
  if not os.path.isfile(filename):  # 如果校验md5的文件不是文件，返回空
    return
  myhash = hashlib.md5()
  f = open(filename, 'rb')
  while True:
    b = f.read(8096)
    if not b:
      break
    myhash.update(b)
  f.close()
  return myhash.hexdigest()
```

sha1 加密

```python
hash = hashlib.sha1()
hash.update('admin'.encode('utf-8'))
print(hash.hexdigest())
# d033e22ae348aeb5660fc2140aec35850c4da997
```

sha256 加密

```python
hash = hashlib.sha256()
hash.update('admin'.encode('utf-8'))
print(hash.hexdigest())
# 8c6976e5b5410415bde908bd4dee15dfb167a9c873fc4bb8a81f6f2ab448a918
```

sha512 加密

```python
hash = hashlib.sha512()
hash.update('admin'.encode('utf-8'))
print(hash.hexdigest())
c7ad44cbad762a5da0a452f9e854fdc1e0e7a52a38015f23f3eab1d80b931dd472634dfac71cd34ebc35d16ab7fb8a90c81f975113d6c7538dc69dd8de9077ec
```

SHA512 和 MD5 的简单比较：

- SHA512：更长、安全，但是慢

- MD5：快，但是现在被反推了

登陆的用户名及密码生成密文

```python

import hashlib

def get_md5(username,password):
    # 加盐
    md5 = hashlib.md5(username.encode('utf-8'))
    # 利用之前的盐与密码生成密文
    md5.update(password.encode('utf-8'))
    # 最终生成密文
    return md5.hexdigest()
```

计算大文件的 md5 值

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import hashlib

def get_file_md5(fname):
    m = hashlib.md5()   #创建md5对象
    with open(fname,'rb') as fobj:
        while True:
            data = fobj.read(4096)
            if not data:
                break
            m.update(data)  #更新md5对象

    return m.hexdigest()    #返回md5对象

reload(sys)
sys.setdefaultencoding('utf-8')

if __name__ == '__main__':
    file_name = "mongodb_us.zip"
    file_md5 = get_file_md5(file_name)
    print(file_md5)     # 0f45cdbf14de54001e82a17c3d199a4b
```

封装成常用库 md5.py

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import hashlib

def get_file_md5(file_name):
    """
    计算文件的md5
    :param file_name:
    :return:
    """
    m = hashlib.md5()   #创建md5对象
    with open(file_name,'rb') as fobj:
        while True:
            data = fobj.read(4096)
            if not data:
                break
            m.update(data)  #更新md5对象

    return m.hexdigest()    #返回md5对象


def get_str_md5(content):
    """
    计算字符串md5
    :param content:
    :return:
    """
    m = hashlib.md5(content) #创建md5对象
    return m.hexdigest()
```

### 5.3 案例: 找到目录下的重复文件

```python
#!/usr/bin/env python
# -*- coding:utf8 -*-
# auther; 18793
# Date：2020/3/20 10:32
# filename: sample02.py
import fnmatch
import os
import hashlib
import sys

CHUNK_SIZE = 8192


def is_file_match(filename, patterns):
    for pattern in patterns:
        if fnmatch.fnmatch(filename, pattern):
            return True
    return False


def find_specific_files(root, patterns=['*'], exclude_dirs=[]):
    '''
    :param root: 查找的根路径
    :param patterns:匹配的文件模式列表
    :param exclude_dirs:需要排除的目录列表
    :return:
    '''
    for root, dirnames, filenames in os.walk(root):
        for filename in filenames:
            if is_file_match(filename, patterns):
                yield os.path.join(root, filename)
        for d in exclude_dirs:
            if d in dirnames:
                dirnames.remove(d)


def get_chunk(filename):
    """
    :param filename: 文件名
    :return:  读取文件，使用while，yield生成器方式读取节省内存
    """
    with open(filename) as f:
        while True:
            chunk = f.read(CHUNK_SIZE)
            if not chunk:
                break
            else:
                yield chunk


def get_file_checksum(filename):
    """
    :param filename: 文件名
    :return: 返回文件的MD5值
    """
    h = hashlib.md5()
    for chunk in get_chunk(filename):
        h.update(chunk)
    return h.hexdigest()


def main():
    # 判断用户输入，捕获用户输入的参数1
    sys.argv.append("")
    directory = sys.argv[1]
    if not os.path.isdir(directory):
        raise SystemExit("{0} is not a directory ".format(directory))

    # 开始校验目录下的文件，将文件MD5值与字典中的key进行比对，如果在字典中者显示重复
    record = {}
    for item in find_specific_files(directory):
        checksum = get_file_checksum(item)
        if checksum in record:
            # 文件已经存在于字典之中
            print("find duplicate file:{0} vs {1}".format(record[checksum], item))
        else:
            # 保存到字典中
            record[checksum] = item


if __name__ == '__main__':
    main()
```

在这个例子中，通过命令行指定需要查找的目录，并在 main 函数中判断用户输人的参数是否为一个正确的目录。

判断完成以后，使用 find_specific files 函数遍历该目录，得到该目录及其子目录下的所有文件。

遍历得到文件列表，并将文件和文件的 MD5 校验码保存到一个字典之中。

这里有一个实现上的小技巧，为了在一个新的文件到来时，判断该文件是否已经存在于字典中，字典的键是文件的 MD5 校验码，字典的值是文件的名称。

通过这种方式就能够快速判断文件是否已经存在于字典之中。

如果文件已经存在于字典之中，则认为当前这个文件和已经存在的某个文件重复，打印这个重复文件。

!!! info "更多参考文档"

    [hashlib — Cryptographic Hashing](https://pymotw.com/3/hashlib/index.html)

## 6.使用 Python 管理压缩包

### 6.1 使用 tarfile 库读取与创建 tar 包

Python 的 tarfile 标准库提供了 tar 命令提供的功能，我们也可以使用它创建一个压缩或非压缩的 tar 包。

Python 向来以简单易用著称，对于一名计算机初学者来说，Python 标准库的 tarfile 模块或许比 Linux 下的 tar 命令更加好用。

#### 1.读取 tar 包

```python
#!/usr/bin/env python
#-*- coding:utf8 -*-
import tarfile
with tarfile.open('example.tar.gz') as t:
    for member_info in t.getmembers():
        print(member_info.name)
```

在这个例子中，我们首先导入 tarfile 库，然后使用默认的读模式打开 tar 包。

tarfile.open 函数会返回一个 TarFile 的对象，用这个对象表示当前打开的 tar 包，我们可以通过这个对象的方法操作和读取 tar 包的内容。

例如，在这个例子中，我们通过 TarFile 对象的 getmembers 方法获取了 tar 包中的文件列表。

tarfile 中有不少函数，其中，最常用的是：

| 方法               | 用途                                                  |
| ------------------ | ----------------------------------------------------- |
| t = tarfile.open() | 打开或新建一个归档文件，返回一个 TarFile 类型的对象 t |
| t.getmembers()     | 获取包内所有成员的信息                                |
| t.add()            | 将指定文件加入包内                                    |
| t.extract()        | 解包指定文件                                          |
| t.extractall()     | 解包所有文件                                          |
| TarFile.close()    | 关闭 TarFile 文件                                     |

#### 2.创建 tar 包

```python
#!/usr/bin/env python
#-*- coding:utf8 -*-
import tarfile
with tarfile.open('tarfile_add.tar',mode='w') as out:
    out.add("shutil_make_archive.py")

```

```python
# 压缩tar.gz
import os
import tarfile
tar = tarfile.open("/tmp/tartest.tar.gz","w:gz")   # 创建压缩包名
for path,dir,files in os.walk("/tmp/tartest"):     # 递归文件目录
    for file in files:
        fullpath = os.path.join(path,file)
        tar.add(fullpath)                          # 创建压缩包
tar.close()

def tar_gz(fname, pwd):
    """
    把当前目录下的fname，打成fname.tar.gz
    :param fname:
    :return:
    """
    t = tarfile.open(fname + ".tar.gz", "w:gz")
    for root, dir, files in os.walk(fname):
        for file in files:
            fullpath = os.path.join(root, file)
            t.add(fullpath)
    t.close()



# 解压tar.gz
import tarfile
tar = tarfile.open("/tmp/tartest.tar.gz")
#tar.extract("/tmp")                               # 全部解压到指定路径
names = tar.getnames()                             # 包内文件名
for name in names:
    tar.extract(name,path="./")                    # 解压指定文件
tar.close()

```

### 6.2 使用 tarfile 读取与创建压缩包

一般情况下，我们创建一个 tar 包的时候都会使用压缩算法进行压缩，以减少数据传输的带宽和磁盘的存储空间。

使用 tarfile 创建和读取压缩包非常简单，只要在打开文件时指定压缩算法即可。

对于 tarfile 的 open 函数，以"打开模式：压缩算法"的形式打开即可。例如：

1）读取一个用 gzip 算法压缩的 tar 包：

```python
with tarfile.open('tarfile_add.tar',mode='r:gz')as out:
```

2)创建一个用 bzip2 算法压缩的 tar 包：

```python
with tarfile.open('tarfile_add.tar',mode='w:bz2')as out:
```

### 6.3 案例: 备份指定的文件到压缩包中

这里还是以备份所有图片为例，将所有图片文件备份到压缩包中，并在压缩包的名称中加入当前时间。如下所示：

```python
#!/usr/bin/env python
#-*- coding:utf8 -*-
import os
import tarfile
import fnmatch
import datetime

def is_file_match(filename,patterns):
    for pattern in patterns:
        if fnmatch.fnmatch(filename,pattern):
            return True
        return False

def find_specific_files(root,patterns=['*'],exclude_dirs=[]):
    '''
    :param root: 查找的根路径
    :param patterns:匹配的文件模式列表
    :param exclude_dirs:需要排除的目录列表
    :return:
    '''
    for root,dirnames,filenames in os.walk(root):
        for finame in filenames:
            if is_file_match(finame,patterns):
                yield os.path.join(root,finame)
        for d in exclude_dirs:
            if d in dirnames:
                dirnames.remove(d)

def main():
    patterns = ['*.jpg','*.jpeg','*.png','*.tif','*.tiff']
    now = datetime.datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
    filename = "all_images_{}.tar.gz".format(now)
    with tarfile.open(filename,"w:gz") as f:
        for item in find_specific_files(".",patterns):
            f.add(item)

if __name__ == '__main__':
    main()
```

我们定义的`find_specific_files`函数十分通用，所以，实现备份指定目录下某一类文件的功能也非常简单。

重点在于将遍历到的文件添加到压缩包中。备份完成以后，会在当前目录下生成一个类似于下面这个文件名的、包含当前时间的压缩包：

```shell
a11_images._2017_03_15_20_43_32.tar.gz
```

### 6.4 使用 zipfile 读取与创建 zip 压缩包

大部分情况下，我们在 Linux 下使用 gzip 或 bzip2 进行压缩，在 Windows 下使用 zip 进行压缩。

#### 压缩 zip

```python
import zipfile,os
f = zipfile.ZipFile('filename.zip', 'w' ,zipfile.ZIP_DEFLATED)    # ZIP_STORE 为默认表不压缩. ZIP_DEFLATED 表压缩
#f.write('file1.txt')                              # 将文件写入压缩包
for path,dir,files in os.walk("tartest"):          # 递归压缩目录
  for file in files:
    f.write(os.path.join(path,file))           # 将文件逐个写入压缩包
f.close()
```

#### 解压 zip

```python
import zipfile
if zipfile.is_zipfile('filename.zip'):             # 判断一个文件是不是zip文件
  f = zipfile.ZipFile('filename.zip')
  for file in f.namelist():                      # 返回文件列表
    f.extract(file, r'/tmp/')                  # 解压指定文件
  #f.extractall()                                # 解压全部
  f.close()
```

封装为函数案例

```python
import zipfile


def unzip_file(zip_path, extract_path):
    """
    解压 ZIP 文件
    :param zip_path: ZIP 文件路径
    :param extract_path: 解压路径
    """
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)


def create_zip(files, zip_path):
    """
    创建 ZIP 文件
    :param files: 要添加到 ZIP 文件中的文件列表
    :param zip_path: ZIP 文件保存路径
    """
    with zipfile.ZipFile(zip_path, 'w') as zip_ref:
        for file in files:
            zip_ref.write(file)


# 示例用法
# 解压 ZIP 文件
unzip_file('path/to/archive.zip', 'path/to/extract')

# 创建 ZIP 文件
files_to_zip = ['file1.txt', 'file2.txt', 'file3.txt']
create_zip(files_to_zip, 'path/to/archive.zip')
```

!!! info "更多参考文档"

    [tarfile — Tar Archive Access](https://pymotw.com/3/tarfile/index.html)
    [zipfile — ZIP Archive Access](https://pymotw.com/3/zipfile/index.html)

### 6.5 案例: 暴力破解 zp 压缩包的密码

将密码本里面的密码逐一尝试输入进行破解

`pojie.py`

```python
import zipfile
import argparse
import os
from os.path import *

def tryZipPwd(zipFile, password, savePath):
    try:
        zipFile.extractall(path=savePath, pwd=password.encode('utf-8'))
        print('[+] Zip File decompression success,password: %s' % (password))
        return True
    except:
        print('[-] Zip File decompression failed,password: %s' % (password))
        return False


def main():
    # 这里用描述创建了 ArgumentParser 对象
    parser = argparse.ArgumentParser(description='Brute Crack Zip')
    # 添加 - H 命令 dest 可以理解为咱们解析时获取 - H 参数后面值的变量名, help 是这个命令的帮助信息
    parser.add_argument('-f', dest='zFile', type=str, help='The zip file path.')
    parser.add_argument('-w', dest='pwdFile', type =str, help='Password dictionary file.')
    zFilePath = None
    pwdFilePath = None
    try:
        options = parser.parse_args()
        zFilePath = options.zFile
        pwdFilePath = options.pwdFile
    except:
        print(parser.parse_args(['-h']))
        exit(0)

    if zFilePath == None or pwdFilePath == None:
        print(parser.parse_args(['-h']))
        exit(0)

    with zipfile.ZipFile(zFilePath) as zFile:
        with open(pwdFilePath) as f:
            for pwd in f.readlines():
                p,f = split(zFilePath)
                dirName = f.split('.')[0]
                dirPath = join(p, dirName)
                try:
                    os.mkdir(dirPath)
                except:
                    pass
                ok = tryZipPwd(zFile, pwd.strip('\n'), dirPath)
                if ok:
                    break
if __name__ == '__main__':
    main()
```

最后我们创建一个用于测试的密码字典 pwd.txt：

```
1256
4345
2323
1234
4556
......
```

```shell
 python3 pojie.py -f 1.zip -w pwd.txt
```

## 7.Python 执行外部命令

### 7.1 subprocess 模块介绍

subprocess 模块最早是在 Python2.4 版本中引入的，正如它名字所反映的，这个模块用于创建和管理子进程。

它提供了高层次的接口，用来替换`os.system()`,`os.spawn*()`,`os.popen*()`,`popen2.*()`和`commands.*`等模块与函数。

subprocess 其实非常简单，它提供了一个名为 Popen 的类来启动和设置子进程的参数。

由于这个类比较复杂，subprocess 还提供了若干便利函数。

这些便利函数都是对 Popen 这个类的封装，以便工程师能够快速启动一个子进程并获取它们的输出结果。

### 7.2 subprocess 的便利函数

#### 1.call

执行命令，并返回状态码，状态码 0 代表命令执行成功，其他的都表示命令执行不成功

```shell
In [1]: import subprocess

In [2]: ret = subprocess.call(["ls", "-l"], shell=False)
total 24
drwxr-xr-x 4 root root 4096 Apr 23 15:47 conf
drwxr-xr-x 6 root root 4096 Apr 23 16:31 data
.....

In [3]: ret
Out[3]: 0

# call函数执行的外部命令以一个字符串列表的形式进行传递，如果设置了shell为True,则可以使用一个字符串命令，而不是一个字符串列表来运行子进程。
# 如果设置了shll为True,Python将先运行一个shell,再用这个shell来解释整个字符串。
In [4]: ret = subprocess.call("ls -l", shell=True)

In [5]: ret
Out[5]: 0

```

#### 2.check_call

执行命令，如果执行状态码是 0，则返回 0，否则抛`subprocess.CalledProcessError`异常

```bash
In [1]: import subprocess

In [2]: subprocess.check_call(["ls", "-l"])
total 24
drwxr-xr-x 4 root root 4096 Apr 23 15:47 conf
drwxr-xr-x 6 root root 4096 Apr 23 16:31 data
-rw-r--r-- 1 root root 1470 May 29 17:25 docker-compose.yml
-rw-r--r-- 1 root root 1120 Apr 23 14:41 Dockerfile
-rw-r--r-- 1 root root  368 Apr 23 14:41 README.md
drwxr-xr-x 2 root root 4096 Apr 23 14:42 scripts
Out[2]: 0

In [3]: subprocess.check_call("exit 1", shell=True)
---------------------------------------------------------------------------
CalledProcessError                        Traceback (most recent call last)
<ipython-input-3-35752273f909> in <module>
----> 1 subprocess.check_call("exit 1", shell=True)

/usr/lib/python3.8/subprocess.py in check_call(*popenargs, **kwargs)
    362         if cmd is None:
    363             cmd = popenargs[0]
--> 364         raise CalledProcessError(retcode, cmd)
    365     return 0
    366

CalledProcessError: Command 'exit 1' returned non-zero exit status 1.

```

#### 3.check_output

执行命令，如果状态码是 0，则返回执行结果，否则抛异常

```shell
# 执行成功就把执行的结果赋值给变量V
>>> V = subprocess.check_output("python -V", shell=True)

# 执行错误的命令就会输出异常
>>> subprocess.check_output("pasas", shell=True)
'pasas' 不是内部或外部命令，也不是可运行的程序
或批处理文件。
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "C:\Python35\lib\subprocess.py", line 629, in check_output
    **kwargs).stdout
  File "C:\Python35\lib\subprocess.py", line 711, in run
    output=stdout, stderr=stderr)
subprocess.CalledProcessError: Command 'pasas' returned non-zero exit status 1
```

以上的三种执行方式在执行命令的时候，shell 默认等于 True，等于 True 的时候，括号内的命令是一行的，

如果 shell 等于 False，那么`[]`内的字符串就是命令的一个元素，执行的时候会把`[]`内的字符串拼接起来执行。

#### 4.call、check_call、check_output

`protest.py`

```python
import subprocess
print('call() test:',subprocess.call(['python','protest.py']))
print('')
print('check_call() test:',subprocess.check_call(['python','protest.py']))
print('')
print('getstatusoutput() test:',subprocess.getstatusoutput(['python','protest.py']))
print('')
print('getoutput() test:',subprocess.getoutput(['python','protest.py']))
print('')
print('check_output() test:',subprocess.check_output(['python','protest.py']))
```

输出结果：

```shell
Hello World!
call() test: 0

Hello World!
check_call() test: 0

getstatusoutput() test: (0, 'Hello World!')

getoutput() test: Hello World!

check_output() test: b'Hello World!\r\n'
```

### 7.3 subprocess 模块的 Popen 类

call()、check_call()、check_output()默认内部调用的都是 subprocess.Popen()，而 subprocess.Popen()则用于执行更复杂的系统命令。

构造函数：

```python
class subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None,
preexec_fn=None, close_fds=True, shell=False, cwd=None, env=None, universal_newlines=False,
startupinfo=None, creationflags=0,restore_signals=True, start_new_session=False, pass_fds=(),
*, encoding=None, errors=None)
```

常用参数：

| 参数                  | 说明                                                                                                                                  |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |
| args                  | shell 命令，可以是字符串或者序列类型（如：list，元组）                                                                                |
| bufsize               | 缓冲区大小。当创建标准流的管道对象时使用，默认-1。 0：不使用缓冲区 1：表示行缓冲，仅当 universal_newlines=True 时可用，也就是文本模式 |
| stdin, stdout, stderr | 分别表示程序的标准输入、输出、错误句柄                                                                                                |
| shell                 | 如果该参数为 True，将通过操作系统的 shell 执行指定的命令。                                                                            |
| cwd                   | 用于设置子进程的当前目录                                                                                                              |
| env                   | 用于指定子进程的环境变量                                                                                                              |

Popen 对象方法:

| 对象                       | 方法                                                       |
| -------------------------- | ---------------------------------------------------------- |
| poll()                     | 检查进程是否终止，如果终止返回 returncode，否则返回 None。 |
| wait(timeout)              | 等待子进程终止。                                           |
| communicate(input,timeout) | 和子进程交互，发送和读取数据。                             |
| send_signal(singnal)       | 发送信号到子进程 。                                        |
| terminate()                | 停止子进程,也就是发送 SIGTERM 信号到子进程                 |
| kill()                     | 杀死子进程。发送 SIGKILL 信号到子进程                      |

其中，使用 communicate 函数可以与子进程进行交互，包括输人数据，获取子命令的
标准输出和错误输出。

#### 1. Popen 执行 shell 命令封装

下面的函数对 Popen 执行 shell 命令进行封装，封装以后，只要将需要执行的 shll 命令传递给该函数即可。

当命令执行成功时，将返回命令的退出状态码和标准输出，当命令执行失败时，将返回退出状态码和错误输出。

```python
import time
import subprocess

def cmd(command):
    subp = subprocess.Popen(command,shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE,encoding="utf-8")
    subp.wait(2)
    if subp.poll() == 0:
        print(subp.communicate()[1])
    else:
        print("失败")
```

```python
def execute_cmd(cmd):
    prcs = subprocess.Popen(cmd,
                            stdin=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE)
    stdout, stderr = prcs.communicate()
    if prcs.returncode != 0:
        return prcs.returncode, stderr

    return (prcs.returncode, prcs.stdout)
```

```python
def exec_cmd(cmd):
    """
    Execute arbitrary commands as sub-processes.
    """
    proc = subprocess.Popen(cmd,
                            stdout=subprocess.PIPE,
                            stdin=subprocess.PIPE,
                            stderr=subprocess.PIPE,
                            universal_newlines=True,
                            shell=True)
    stdout, stderr = proc.communicate()
    return (proc.returncode, stdout, stderr)
```

通过 Python 标准库的 subprocess 模块，可以运行外部程序。

这极大地拓展了 Python 的功能。例如，可以使用 subprocess 在 Python 中执行复杂的 Linux 命令。

python 执行 linux 系统命令的几种方法

1. 使用 os.system

仅仅在一个子终端运行系统命令，而不能获取命令执行后的返回信息

2. 使用 os.popen

该方法不但执行命令还返回执行后的信息对象，好处在于：将返回的结果赋于一变量，便于程序的处理。

```python
cmd = os.popen('df -h').read().split('\n')
```

3. 使用模块 subprocess

[subprocess — Spawning Additional Processes](https://pymotw.com/3/subprocess/index.html)

[执行外部命令并获取它的输出](https://python3-cookbook.readthedocs.io/zh_CN/latest/c13/p06_executing_external_command_and_get_its_output.html?highlight=subprocess)

#### 2. python 执行 shell 实时输出

1.使用 readline 可以实现

```python
import subprocess


def run_shell(shell):
    cmd = subprocess.Popen(shell, stdin=subprocess.PIPE, stderr=subprocess.PIPE,
                           stdout=subprocess.PIPE, universal_newlines=True, shell=True, bufsize=1)
    # 实时输出
    while True:
        line = cmd.stdout.readline()
        print(line, end='')
        if subprocess.Popen.poll(cmd) == 0:  # 判断子进程是否结束
            break

    return cmd.returncode


if __name__ == '__main__':
    print(run_shell("ping www.baidu.com"))
```

2.readline 可能导致卡死，官方推荐使用 communicate，但是如果还是使用 subprocess.PIPE，执行完命令后才能拿到标准输出，替换成 sys.stdout 就能达到实时输出效果，代码附上

```python
import subprocess
import sys


def run_shell(shell):
    cmd = subprocess.Popen(shell, stdin=subprocess.PIPE, stderr=sys.stderr, close_fds=True,
                           stdout=sys.stdout, universal_newlines=True, shell=True, bufsize=1)

    cmd.communicate()
    return cmd.returncode


if __name__ == '__main__':
    print(run_shell("ping www.baidu.com"))
```

## 8.综合案例: 使用 Python 部署 MongoDB

安装包和脚本的目录结构如下

```shell
|__depoly_mongo.py
|__mongodb-linux-x86_64-debian71-3.4.0.tgz
0 directories,2 files
```

MongoDB 是当下最流行的文档数据库，具有很好的易用性。启动一个 MongoDB 数据库实例，只需要执行以下几条 shell 命令即可：

```shell
tar -zxf mongodb-linux-x86_64-debian71-3.4.0.tgz
mv mongodb-linux-x86_64-debian71-3.4.0 mongo
mkdir mongodata
mongo/bin/mongod --fork --logpath mongodata/mongod.log --dbpath mongodata
```

下面的程序是使用 Python 部署 MongoDB 数据库的完整代码包括与路径相关的 os.path 模块，与文件管理相关的 shutil 模块，与压缩包相关的 tarfile 模块以及在 Python 中执行 Shell 命令的 subprocess 模块。

如下所示：

```python
#!/usr/bin/python
#-*- coding: UTF-8 -*-
from __future__ import print_function
import os
import shutil
import tarfile
import subprocess


def execute_cmd(cmd):
    p = subprocess.Popen(cmd,
                         shell=True,
                         stdin=subprocess.PIPE,
                         stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE)
    stdout, stderr = p.communicate()
    if p.returncode != 0:
        return p.returncode, stderr
    return p.returncode, stdout


def unpackage_mongo(package, package_dir):
    unpackage_dir = os.path.splitext(package)[0]
    if os.path.exists(unpackage_dir):
        shutil.rmtree(unpackage_dir)

    if os.path.exists(package_dir):
        shutil.rmtree(package_dir)

    t = tarfile.open(package, 'r:gz')
    t.extractall('.')

    shutil.move(unpackage_dir, package_dir)


def create_datadir(data_dir):
    if os.path.exists(data_dir):
        shutil.rmtree(data_dir)
    os.mkdir(data_dir)


def format_mongod_command(package_dir, data_dir, logfile):
    mongod = os.path.join(package_dir, 'bin', 'mongod')
    mongod_format = """{0} --fork --dbpath {1} --logpath {2}"""
    return mongod_format.format(mongod, data_dir, logfile)


def start_mongod(cmd):
    returncode, out = execute_cmd(cmd)
    if returncode != 0:
        raise SystemExit('execute {0} error :{1}'.format(cmd, out))
    else:
        print("execute command ({0}) successful".format(cmd))



def main():
    #mongo文件名称
    package = "mongodbxxxx.tar.gz"
    #当前路径
    cur_dir = os.path.abspath(".")
    #mongodb的路径
    package_dir = os.path.join(cur_dir,"mongo")
    #mongodb数据目录
    data_dir = os.path.join(cur_dir,"mogodata")
    #mongodb日志目录
    logfile = os.path.join(cur_dir,"mongod.log")
    #如果包不存在，就抛出异常
    if not os.path.exists(package):
        raise SystemExit("{0} not found".format(package))
    #解压mongodb安装包
    unpackage_mongo(package,package_dir)
    #创建安装目录
    create_datadir(data_dir)
    #执行安装
    start_mongod(format_mongod_command(package_dir,data_dir,logfile))

if __name__ == '__main__':
    main()
```

安装完成之后的目录结构如下

```shell
|__depoly_mongo.py
|__mongo
  |_____bin
        |__mongod
|__mongodata
  |_____mongod.log
|__mongodb-linux-x86_64-debian71-3.4.0.tgz
2 directories,2 files
```
